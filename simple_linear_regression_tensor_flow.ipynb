{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Core python libraries\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# External libraries.\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import sklearn\n",
    "import tempfile\n",
    "\n",
    "# Tensorflow and related.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# So you know when this code block finishes.\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171482\n"
     ]
    }
   ],
   "source": [
    "#TODO(Max): make a library that does all this preprocessing\n",
    "data = pandas.read_csv(\"data/train.csv\") # Can read a subset. First nrows of the total.\n",
    "LABEL_COLUMN = \"SalaryNormalized\"\n",
    "\n",
    "TEST_SIZE = .3\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# sklearn.cross_validation has been replaced with model_selection.\n",
    "X_train_index, X_test_index, Y_train, Y_test = sklearn.model_selection.train_test_split(\n",
    "    data.index, data[LABEL_COLUMN], test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Keep train and test as pandas dataframes.\n",
    "X_train = data.iloc[X_train_index]\n",
    "X_test = data.iloc[X_test_index]\n",
    "\n",
    "yb_train = numpy.array(X_train[LABEL_COLUMN].astype(numpy.float32))\n",
    "yb_test= numpy.array(X_test[LABEL_COLUMN].astype(numpy.float32))\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[-1.5666989  -1.21854359 -0.87038828 -0.52223297 -0.17407766  0.17407766\n",
      "  0.52223297  0.87038828  1.21854359  1.5666989 ]\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing input values to mean 0, standard deviation 1.\n",
    "train_mean, train_std = yb_train.mean(), yb_train.std()\n",
    "\n",
    "def normalize_input(input_vector, train_mean, train_std):\n",
    "    return (input_vector - train_mean)/train_std\n",
    "\n",
    "def unnormalize_input(normalized_input_vector, train_mean, train_std):\n",
    "    return (normalized_input_vector * train_std) + train_mean\n",
    "\n",
    "# Move into a unit test.\n",
    "test = numpy.arange(10)\n",
    "test_mean, test_std = test.mean(), test.std()\n",
    "print(test)\n",
    "normed = normalize_input(test, test_mean, test_std)\n",
    "print(normed)\n",
    "unnormed = unnormalize_input(normed, test_mean, test_std)\n",
    "print(unnormed)\n",
    "\n",
    "\n",
    "# Normalize input labels and expectations\n",
    "yb_train = normalize_input(yb_train, train_mean, train_std)\n",
    "yb_test = normalize_input(yb_test, train_mean, train_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17698.3\n",
      "[ 0.89645004 -0.66550416  3.22435188 ..., -0.29010177  0.89645004\n",
      "  0.95295256]\n"
     ]
    }
   ],
   "source": [
    "print(train_std)\n",
    "print(yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_column = \"CompleteJobListingStemmed\"\n",
    "\n",
    "x_train_text = X_train[target_column]\n",
    "x_test_text = X_test[target_column]\n",
    "\n",
    "max_document_length = max([len(x.split(\" \")) for x in x_train_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: 120037, 1368\n",
      "x_test shape: 51445, 1368\n",
      "Total distinct words: 8712\n"
     ]
    }
   ],
   "source": [
    "# Look here for a tutorial https://medium.com/@ilblackdragon/tensorflow-text-classification-615198df9231\n",
    "min_word_frequency = 75\n",
    "\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(\n",
    "    max_document_length, min_frequency=min_word_frequency)\n",
    "x_train = numpy.array(list(vocab_processor.fit_transform(x_train_text)))\n",
    "print(\"x_train shape: %s, %s\" % x_train.shape)\n",
    "x_test = numpy.array(list(vocab_processor.transform(x_test_text)))\n",
    "print(\"x_test shape: %s, %s\" % x_test.shape)\n",
    "n_words = len(vocab_processor.vocabulary_)\n",
    "print(\"Total distinct words: %d\" % n_words)\n",
    "\n",
    "# Try looking at https://github.com/nfmcclure/tensorflow_cookbook/blob/master/07_Natural_Language_Processing/02_Working_with_Bag_of_Words/02_bag_of_words.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137108\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate a training batch.\n",
    "\n",
    "# Are these breaking past a certain point?\n",
    "def generate_batch(batch_size, number_of_batches, input_data, input_labels):\n",
    "    \"\"\"Give me a docstring to explain.\"\"\"\n",
    "    batch = numpy.ndarray(shape=(batch_size, max_document_length),\n",
    "                          dtype=numpy.int32)\n",
    "    labels = numpy.ndarray(shape=(batch_size, 1), dtype=numpy.float32)\n",
    "    \n",
    "    batch_index = 0\n",
    "    while batch_index < number_of_batches:\n",
    "        for element_index in range(batch_size):\n",
    "            # Prevents overflow.\n",
    "            data_index = ((batch_index * batch_size) + element_index) % len(input_data)\n",
    "            batch[element_index] = numpy.array(input_data[data_index])\n",
    "            labels[element_index] = input_labels[data_index]\n",
    "        batch_index += 1\n",
    "        yield batch, labels\n",
    "    \n",
    "\n",
    "def input_fn():\n",
    "    for batch_input, batch_labels in generate_batch(batch_size, number_of_batches,\n",
    "                                                    x_train, yb_train):\n",
    "        yield {x_data: batch_input, y_target: batch_labels}\n",
    "\n",
    "def eval_input_fn():\n",
    "    for batch_input, batch_labels in generate_batch(batch_size, number_of_validation_batches,\n",
    "                                                    x_test, yb_test):\n",
    "        yield {x_data: batch_input, y_target: batch_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woohoo this looks like my bag of words shape :D (32, 8712)\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "learning_rate = .05\n",
    "\n",
    "l1_regularization_coef = 0.01\n",
    "l2_regularization_coef = 0.0\n",
    "\n",
    "momentum = None\n",
    "\n",
    "# Sklearn shuffles after epoch by default.\n",
    "\n",
    "# if not RMSE then MAE.\n",
    "HUBER = True\n",
    "RMSE = False\n",
    "\n",
    "#Implement this by batch.\n",
    "batch_size = 32\n",
    "\n",
    "#Size of input dictionary. Number of distinct words.\n",
    "vocab_size = len(vocab_processor.vocabulary_)\n",
    "\n",
    "def huber_loss(labels, predictions, delta=1.0):\n",
    " residual = tf.abs(predictions - labels)\n",
    " condition = tf.less(residual, delta)\n",
    " small_res = 0.5 * tf.square(residual)\n",
    " large_res = delta * residual - 0.5 * tf.square(delta)\n",
    " return tf.reduce_mean(tf.where(condition, small_res, large_res))\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Setup Index Matrix necessary for one-hot-encoding\n",
    "    identity_mat = tf.diag(tf.ones(shape=[vocab_size]))\n",
    "\n",
    "    # Create variables for regression\n",
    "    A = tf.Variable(tf.random_normal(shape=[vocab_size, 1]))\n",
    "\n",
    "    # Intercept term. A scalar.\n",
    "    b = tf.Variable(tf.random_normal(shape=[1]))\n",
    "\n",
    "    # Initialize data placeholders\n",
    "    x_data = tf.placeholder(shape=[batch_size, max_document_length], dtype=tf.int32)\n",
    "    y_target = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name=\"labels\")\n",
    "\n",
    "    # Text-Vocab Embedding\n",
    "    # x_embed has rows equal to max_document_length, and columns equal to\n",
    "    # The number of distinct word tokens\n",
    "    # This is also an embedding_lookup_sparse function that would create a sparse tensor.\n",
    "    x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "    # Collapse accross the document length dimension. Leaving only the number of tokens.\n",
    "    x_col_sums = tf.reduce_sum(x_embed, 1)\n",
    "    print(\"Woohoo this looks like my bag of words shape :D %s\" % x_col_sums.shape)\n",
    "\n",
    "    # Model output\n",
    "    product = tf.matmul(x_col_sums, A)\n",
    "    model_output = tf.add(product, b, name=\"predictions\")\n",
    "\n",
    "    # TODO(Max) try root mean square error. Should this be merely mean square error?\n",
    "    if HUBER:\n",
    "        loss = huber_loss(y_target, model_output)\n",
    "    elif RMSE:\n",
    "        loss = tf.sqrt(tf.reduce_mean(tf.pow(tf.subtract(y_target, model_output), 2)))\n",
    "    else:\n",
    "        # Mean Absolute Error.\n",
    "        loss = tf.reduce_mean(tf.abs(tf.subtract(y_target, model_output)))\n",
    "    \n",
    "    # If we are using regularization.\n",
    "    if l1_regularization_coef > 0 or l2_regularization_coef > 0:\n",
    "        l1_regularizer = tf.contrib.layers.l1_regularizer(scale=l1_regularization_coef)\n",
    "        l2_regularizer = tf.contrib.layers.l2_regularizer(scale=l2_regularization_coef)\n",
    "    \n",
    "        weights = tf.trainable_variables() # all vars of your graph\n",
    "        regularization_penalty = tf.add(tf.contrib.layers.apply_regularization(l1_regularizer, weights),\n",
    "                                         tf.contrib.layers.apply_regularization(l2_regularizer, weights))\n",
    "        loss = loss + regularization_penalty # this loss needs to be minimized\n",
    "\n",
    "    \n",
    "    # Converts back to original, salary scale.\n",
    "    error_salary_scale = tf.multiply(tf.subtract(y_target, model_output), train_std)\n",
    "    \n",
    "    mean_absolute_error_salary_scale = tf.reduce_mean(\n",
    "        tf.abs(error_salary_scale))\n",
    "\n",
    "    # Log for tensorboard\n",
    "    training_summary = tf.summary.scalar('train_loss', loss)\n",
    "    validation_summary = tf.summary.scalar('validation_loss', loss)\n",
    "    # Add mean absolute errors.\n",
    "    training_mae = tf.summary.scalar('train_mae', mean_absolute_error_salary_scale)\n",
    "    validation_mae = tf.summary.scalar('validation_mae', mean_absolute_error_salary_scale)\n",
    "\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # Declare optimizer\n",
    "    if momentum is None:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    if momentum is not None:\n",
    "       optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    \n",
    "    # This one seems to work better :D\n",
    "    train_op = tf.contrib.layers.optimize_loss(      \n",
    "     loss, tf.contrib.framework.get_global_step(),      \n",
    "     optimizer='Adam'\n",
    "        , learning_rate=learning_rate, clip_gradients=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore from model!\n",
      "INFO:tensorflow:Restoring parameters from logs/bagofwords/2017-06-11-18-06-00-1750\n",
      "Epoch: 0 Training Observation: 3 : Mean Loss: 6.3697 (0.964 sec)\n",
      "[-0.00208002]\n",
      "Epoch: 0 Training Observation: 6 : Mean Loss: 6.4061 (0.940 sec)\n",
      "[ 0.00446413]\n",
      "Epoch: 0 Training Observation: 9 : Mean Loss: 6.5499 (0.960 sec)\n",
      "[-0.00241382]\n",
      "Epoch: 0 Training Observation: 12 : Mean Loss: 6.3353 (1.012 sec)\n",
      "[ 0.00382377]\n",
      "Epoch: 0 Training Observation: 15 : Mean Loss: 6.6694 (0.972 sec)\n",
      "[-0.00334767]\n",
      "Epoch: 0 Training Observation: 18 : Mean Loss: 6.0642 (1.043 sec)\n",
      "[ 0.00306244]\n",
      "Epoch: 0 Training Observation: 21 : Mean Loss: 7.0035 (0.978 sec)\n",
      "[-0.0039469]\n",
      "Epoch: 0 Training Observation: 24 : Mean Loss: 6.2509 (0.970 sec)\n",
      "[ 0.00221835]\n",
      "Epoch: 0 Training Observation: 27 : Mean Loss: 7.0107 (0.962 sec)\n",
      "[-0.00484772]\n",
      "Epoch: 0 Training Observation: 30 : Mean Loss: 6.0442 (1.036 sec)\n",
      "[ 0.00159589]\n",
      "Epoch: 0 Training Observation: 33 : Mean Loss: 6.8936 (0.968 sec)\n",
      "[-0.00514283]\n",
      "Epoch: 0 Training Observation: 36 : Mean Loss: 6.1329 (1.073 sec)\n",
      "[ 0.00174914]\n",
      "Epoch: 0 Training Observation: 39 : Mean Loss: 6.4825 (0.962 sec)\n",
      "[-0.00470237]\n",
      "Epoch: 0 Training Observation: 42 : Mean Loss: 6.3036 (0.974 sec)\n",
      "[ 0.00211569]\n",
      "Epoch: 0 Training Observation: 45 : Mean Loss: 6.3873 (1.018 sec)\n",
      "[-0.00445462]\n",
      "Epoch: 0 Training Observation: 48 : Mean Loss: 6.2966 (1.019 sec)\n",
      "[ 0.00235288]\n",
      "Epoch: 0 Training Observation: 51 : Mean Loss: 6.5271 (1.039 sec)\n",
      "[-0.00403647]\n",
      "Epoch: 0 Training Observation: 54 : Mean Loss: 6.3958 (0.938 sec)\n",
      "[ 0.00303523]\n",
      "Epoch: 0 Training Observation: 57 : Mean Loss: 6.6281 (0.962 sec)\n",
      "[-0.00376069]\n",
      "Epoch: 0 Training Observation: 60 : Mean Loss: 6.0095 (0.964 sec)\n",
      "[ 0.00273916]\n",
      "Epoch: 0 Training Observation: 63 : Mean Loss: 6.6402 (0.962 sec)\n",
      "[-0.00407775]\n",
      "Epoch: 0 Training Observation: 66 : Mean Loss: 6.1743 (1.048 sec)\n",
      "[ 0.00227975]\n",
      "Epoch: 0 Training Observation: 69 : Mean Loss: 6.5435 (1.064 sec)\n",
      "[-0.0047044]\n",
      "Epoch: 0 Training Observation: 72 : Mean Loss: 6.0544 (1.085 sec)\n",
      "[ 0.00215051]\n",
      "Epoch: 0 Training Observation: 75 : Mean Loss: 6.5126 (1.082 sec)\n",
      "[-0.00442933]\n",
      "Epoch: 0 Training Observation: 78 : Mean Loss: 6.4079 (1.076 sec)\n",
      "[ 0.00270657]\n",
      "Epoch: 0 Training Observation: 81 : Mean Loss: 6.6487 (1.104 sec)\n",
      "[-0.00336769]\n",
      "Epoch: 0 Training Observation: 84 : Mean Loss: 6.6706 (0.978 sec)\n",
      "[ 0.00370338]\n",
      "Epoch: 0 Training Observation: 87 : Mean Loss: 6.4077 (1.003 sec)\n",
      "[-0.00315418]\n",
      "Epoch: 0 Training Observation: 90 : Mean Loss: 6.6644 (1.031 sec)\n",
      "[ 0.00354312]\n",
      "Epoch: 0 Training Observation: 93 : Mean Loss: 6.5088 (1.017 sec)\n",
      "[-0.00350723]\n",
      "Epoch: 0 Training Observation: 96 : Mean Loss: 6.2751 (1.038 sec)\n",
      "[ 0.00316391]\n",
      "Epoch: 0 Training Observation: 99 : Mean Loss: 6.4609 (0.986 sec)\n",
      "[-0.00345134]\n",
      "Epoch: 0 Training Observation: 102 : Mean Loss: 6.4941 (0.968 sec)\n",
      "[ 0.00270973]\n",
      "Epoch: 0 Training Observation: 105 : Mean Loss: 6.5062 (0.971 sec)\n",
      "[-0.00425925]\n",
      "Epoch: 0 Training Observation: 108 : Mean Loss: 6.8846 (0.987 sec)\n",
      "[ 0.00230193]\n",
      "Epoch: 0 Training Observation: 111 : Mean Loss: 6.7367 (1.130 sec)\n",
      "[-0.0048143]\n",
      "Epoch: 0 Training Observation: 114 : Mean Loss: 6.4865 (1.032 sec)\n",
      "[ 0.00181891]\n",
      "Epoch: 0 Training Observation: 117 : Mean Loss: 6.5234 (1.062 sec)\n",
      "[-0.00477201]\n",
      "Epoch: 0 Training Observation: 120 : Mean Loss: 6.2711 (1.035 sec)\n",
      "[ 0.00212683]\n",
      "Epoch: 0 Training Observation: 123 : Mean Loss: 6.5694 (1.124 sec)\n",
      "[-0.00460234]\n",
      "Epoch: 0 Training Observation: 126 : Mean Loss: 6.4339 (1.217 sec)\n",
      "[ 0.00167857]\n",
      "Epoch: 0 Training Observation: 129 : Mean Loss: 6.6110 (1.016 sec)\n",
      "[-0.00521717]\n",
      "Epoch: 0 Training Observation: 132 : Mean Loss: 6.2549 (0.988 sec)\n",
      "[ 0.00188742]\n",
      "Epoch: 0 Training Observation: 135 : Mean Loss: 6.6296 (1.003 sec)\n",
      "[-0.00471358]\n",
      "Epoch: 0 Training Observation: 138 : Mean Loss: 6.5843 (0.996 sec)\n",
      "[ 0.00233541]\n",
      "Epoch: 0 Training Observation: 141 : Mean Loss: 6.6366 (1.095 sec)\n",
      "[-0.00443859]\n",
      "Epoch: 0 Training Observation: 144 : Mean Loss: 6.3959 (1.125 sec)\n",
      "[ 0.00209298]\n",
      "Epoch: 0 Training Observation: 147 : Mean Loss: 6.4116 (1.031 sec)\n",
      "[-0.00500677]\n",
      "Epoch: 0 Training Observation: 150 : Mean Loss: 6.4323 (1.011 sec)\n",
      "[ 0.00143321]\n",
      "Epoch: 0 Training Observation: 153 : Mean Loss: 6.6172 (0.941 sec)\n",
      "[-0.00543721]\n",
      "Epoch: 0 Training Observation: 156 : Mean Loss: 6.3176 (0.983 sec)\n",
      "[ 0.00126989]\n",
      "Epoch: 0 Training Observation: 159 : Mean Loss: 6.5325 (0.960 sec)\n",
      "[-0.00546311]\n",
      "Epoch: 0 Training Observation: 162 : Mean Loss: 6.4761 (0.960 sec)\n",
      "[ 0.00122368]\n",
      "Epoch: 0 Training Observation: 165 : Mean Loss: 6.5484 (1.000 sec)\n",
      "[-0.00557212]\n",
      "Epoch: 0 Training Observation: 168 : Mean Loss: 6.4664 (1.152 sec)\n",
      "[ 0.00106351]\n",
      "Epoch: 0 Training Observation: 171 : Mean Loss: 6.1981 (1.010 sec)\n",
      "[-0.00539807]\n",
      "Epoch: 0 Training Observation: 174 : Mean Loss: 6.6442 (0.988 sec)\n",
      "[ 0.00185424]\n",
      "Epoch: 0 Training Observation: 177 : Mean Loss: 6.2338 (1.008 sec)\n",
      "[-0.00390192]\n",
      "Epoch: 0 Training Observation: 180 : Mean Loss: 6.8288 (0.994 sec)\n",
      "[ 0.00346496]\n",
      "Epoch: 0 Training Observation: 183 : Mean Loss: 6.0196 (1.009 sec)\n",
      "[-0.00253525]\n",
      "Epoch: 0 Training Observation: 186 : Mean Loss: 6.9838 (1.075 sec)\n",
      "[ 0.00477734]\n",
      "Epoch: 0 Training Observation: 189 : Mean Loss: 5.8941 (1.098 sec)\n",
      "[-0.00184362]\n",
      "Epoch: 0 Training Observation: 192 : Mean Loss: 6.6744 (1.042 sec)\n",
      "[ 0.00470192]\n",
      "Epoch: 0 Training Observation: 195 : Mean Loss: 6.5236 (0.975 sec)\n",
      "[-0.00277831]\n",
      "Epoch: 0 Training Observation: 198 : Mean Loss: 6.6402 (1.048 sec)\n",
      "[ 0.00321783]\n",
      "Epoch: 0 Training Observation: 201 : Mean Loss: 6.4281 (1.020 sec)\n",
      "[-0.00395778]\n",
      "Epoch: 0 Training Observation: 204 : Mean Loss: 6.6651 (1.034 sec)\n",
      "[ 0.0026101]\n",
      "Epoch: 0 Training Observation: 207 : Mean Loss: 6.3378 (0.942 sec)\n",
      "[-0.00427904]\n",
      "Epoch: 0 Training Observation: 210 : Mean Loss: 6.7785 (0.963 sec)\n",
      "[ 0.00239177]\n",
      "Epoch: 0 Training Observation: 213 : Mean Loss: 6.6520 (1.040 sec)\n",
      "[-0.00436145]\n",
      "Epoch: 0 Training Observation: 216 : Mean Loss: 6.8261 (1.024 sec)\n",
      "[ 0.00211234]\n",
      "Epoch: 0 Training Observation: 219 : Mean Loss: 6.4391 (1.052 sec)\n",
      "[-0.00484997]\n",
      "Epoch: 0 Training Observation: 222 : Mean Loss: 6.3721 (1.016 sec)\n",
      "[ 0.00118438]\n",
      "Epoch: 0 Training Observation: 225 : Mean Loss: 6.7171 (1.073 sec)\n",
      "[-0.00630659]\n",
      "Epoch: 0 Training Observation: 228 : Mean Loss: 6.3445 (1.028 sec)\n",
      "[-0.00035861]\n",
      "Epoch: 0 Training Observation: 231 : Mean Loss: 6.7759 (1.075 sec)\n",
      "[-0.00777937]\n",
      "Epoch: 0 Training Observation: 234 : Mean Loss: 6.0288 (0.995 sec)\n",
      "[-0.00149869]\n",
      "Epoch: 0 Training Observation: 237 : Mean Loss: 7.0839 (1.035 sec)\n",
      "[-0.00814356]\n",
      "Epoch: 0 Training Observation: 240 : Mean Loss: 6.1281 (1.034 sec)\n",
      "[-0.00095857]\n",
      "Epoch: 0 Training Observation: 243 : Mean Loss: 6.9597 (0.971 sec)\n",
      "[-0.00633524]\n",
      "Epoch: 0 Training Observation: 246 : Mean Loss: 6.1040 (1.038 sec)\n",
      "[ 0.00131284]\n",
      "Epoch: 0 Training Observation: 249 : Mean Loss: 6.8416 (0.975 sec)\n",
      "[-0.00465179]\n",
      "Saving at epoch 0 step: 250\n",
      "Epoch: 0 Training Observation: 252 : Mean Loss: 6.4971 (1.024 sec)\n",
      "[ 0.00271025]\n",
      "Epoch: 0 Training Observation: 255 : Mean Loss: 6.7932 (0.971 sec)\n",
      "[-0.00332732]\n",
      "Epoch: 0 Training Observation: 258 : Mean Loss: 6.3662 (0.954 sec)\n",
      "[ 0.00390565]\n",
      "Epoch: 0 Training Observation: 261 : Mean Loss: 6.6424 (0.967 sec)\n",
      "[-0.00261697]\n",
      "Epoch: 0 Training Observation: 264 : Mean Loss: 6.1224 (1.092 sec)\n",
      "[ 0.00439704]\n",
      "Epoch: 0 Training Observation: 267 : Mean Loss: 6.9130 (1.009 sec)\n",
      "[-0.00205425]\n",
      "Epoch: 0 Training Observation: 270 : Mean Loss: 6.2054 (0.954 sec)\n",
      "[ 0.00510899]\n",
      "Epoch: 0 Training Observation: 273 : Mean Loss: 6.4327 (1.029 sec)\n",
      "[-0.00129246]\n",
      "Epoch: 0 Training Observation: 276 : Mean Loss: 6.4525 (1.088 sec)\n",
      "[ 0.00574953]\n",
      "Epoch: 0 Training Observation: 279 : Mean Loss: 6.6586 (1.042 sec)\n",
      "[-0.00062791]\n",
      "Epoch: 0 Training Observation: 282 : Mean Loss: 6.8321 (0.945 sec)\n",
      "[ 0.00662945]\n",
      "Epoch: 0 Training Observation: 285 : Mean Loss: 6.2083 (1.003 sec)\n",
      "[ 0.00028586]\n",
      "Epoch: 0 Training Observation: 288 : Mean Loss: 7.0713 (1.049 sec)\n",
      "[ 0.00739105]\n",
      "Epoch: 0 Training Observation: 291 : Mean Loss: 5.8239 (1.031 sec)\n",
      "[ 0.00108147]\n",
      "Epoch: 0 Training Observation: 294 : Mean Loss: 7.1173 (0.973 sec)\n",
      "[ 0.00765383]\n",
      "Epoch: 0 Training Observation: 297 : Mean Loss: 6.2833 (0.986 sec)\n",
      "[ 0.00082901]\n",
      "Epoch: 0 Training Observation: 300 : Mean Loss: 7.2446 (0.963 sec)\n",
      "[ 0.00741469]\n",
      "Epoch: 0 Training Observation: 303 : Mean Loss: 6.1452 (0.977 sec)\n",
      "[ 0.00062281]\n",
      "Epoch: 0 Training Observation: 306 : Mean Loss: 7.1407 (1.043 sec)\n",
      "[ 0.00682317]\n",
      "Epoch: 0 Training Observation: 309 : Mean Loss: 6.2424 (0.998 sec)\n",
      "[-0.0004849]\n",
      "Epoch: 0 Training Observation: 312 : Mean Loss: 6.9905 (1.021 sec)\n",
      "[ 0.00544698]\n",
      "Epoch: 0 Training Observation: 315 : Mean Loss: 6.2765 (1.076 sec)\n",
      "[-0.0020275]\n",
      "Epoch: 0 Training Observation: 318 : Mean Loss: 6.4400 (0.975 sec)\n",
      "[ 0.0038364]\n",
      "Epoch: 0 Training Observation: 321 : Mean Loss: 6.4747 (0.979 sec)\n",
      "[-0.00362753]\n",
      "Epoch: 0 Training Observation: 324 : Mean Loss: 6.5267 (0.971 sec)\n",
      "[ 0.0027103]\n",
      "Epoch: 0 Training Observation: 327 : Mean Loss: 6.4356 (0.982 sec)\n",
      "[-0.00390583]\n",
      "Epoch: 0 Training Observation: 330 : Mean Loss: 6.4568 (0.968 sec)\n",
      "[ 0.00296153]\n",
      "Epoch: 0 Training Observation: 333 : Mean Loss: 6.5050 (0.993 sec)\n",
      "[-0.00331603]\n",
      "Epoch: 0 Training Observation: 336 : Mean Loss: 6.9757 (0.966 sec)\n",
      "[ 0.00400755]\n",
      "Epoch: 0 Training Observation: 339 : Mean Loss: 6.0737 (1.052 sec)\n",
      "[-0.0021703]\n",
      "Epoch: 0 Training Observation: 342 : Mean Loss: 7.4217 (0.989 sec)\n",
      "[ 0.00455526]\n",
      "Epoch: 0 Training Observation: 345 : Mean Loss: 6.2112 (0.988 sec)\n",
      "[-0.00279013]\n",
      "Epoch: 0 Training Observation: 348 : Mean Loss: 6.7353 (1.052 sec)\n",
      "[ 0.00313232]\n",
      "Epoch: 0 Training Observation: 351 : Mean Loss: 6.4657 (0.969 sec)\n",
      "[-0.00454027]\n",
      "Epoch: 0 Training Observation: 354 : Mean Loss: 6.3439 (1.048 sec)\n",
      "[ 0.00115472]\n",
      "Epoch: 0 Training Observation: 357 : Mean Loss: 6.7657 (0.966 sec)\n",
      "[-0.00605452]\n",
      "Epoch: 0 Training Observation: 360 : Mean Loss: 6.4360 (1.016 sec)\n",
      "[ 0.00053926]\n",
      "Epoch: 0 Training Observation: 363 : Mean Loss: 6.6936 (1.024 sec)\n",
      "[-0.00648484]\n",
      "Epoch: 0 Training Observation: 366 : Mean Loss: 6.2689 (1.003 sec)\n",
      "[ -9.69832763e-05]\n",
      "Epoch: 0 Training Observation: 369 : Mean Loss: 6.6802 (1.036 sec)\n",
      "[-0.00669676]\n",
      "Epoch: 0 Training Observation: 372 : Mean Loss: 6.2163 (0.966 sec)\n",
      "[ -3.78936529e-05]\n",
      "Epoch: 0 Training Observation: 375 : Mean Loss: 7.0447 (0.960 sec)\n",
      "[-0.00610856]\n",
      "Epoch: 0 Training Observation: 378 : Mean Loss: 6.2048 (0.939 sec)\n",
      "[ 0.00119694]\n",
      "Epoch: 0 Training Observation: 381 : Mean Loss: 6.7953 (1.031 sec)\n",
      "[-0.00488479]\n",
      "Epoch: 0 Training Observation: 384 : Mean Loss: 6.4105 (1.002 sec)\n",
      "[ 0.00228677]\n",
      "Epoch: 0 Training Observation: 387 : Mean Loss: 6.6327 (0.986 sec)\n",
      "[-0.00401351]\n",
      "Epoch: 0 Training Observation: 390 : Mean Loss: 6.2763 (1.057 sec)\n",
      "[ 0.00282255]\n",
      "Epoch: 0 Training Observation: 393 : Mean Loss: 6.5934 (1.035 sec)\n",
      "[-0.00402672]\n",
      "Epoch: 0 Training Observation: 396 : Mean Loss: 6.5154 (1.034 sec)\n",
      "[ 0.00282964]\n",
      "Epoch: 0 Training Observation: 399 : Mean Loss: 6.8149 (0.999 sec)\n",
      "[-0.00334766]\n",
      "Epoch: 0 Training Observation: 402 : Mean Loss: 6.6900 (0.983 sec)\n",
      "[ 0.00410676]\n",
      "Epoch: 0 Training Observation: 405 : Mean Loss: 6.4499 (1.041 sec)\n",
      "[-0.00213261]\n",
      "Epoch: 0 Training Observation: 408 : Mean Loss: 6.5769 (0.994 sec)\n",
      "[ 0.00509459]\n",
      "Epoch: 0 Training Observation: 411 : Mean Loss: 6.5541 (1.017 sec)\n",
      "[-0.00162627]\n",
      "Epoch: 0 Training Observation: 414 : Mean Loss: 6.8278 (0.992 sec)\n",
      "[ 0.00483668]\n",
      "Epoch: 0 Training Observation: 417 : Mean Loss: 6.2092 (0.974 sec)\n",
      "[-0.00188976]\n",
      "Epoch: 0 Training Observation: 420 : Mean Loss: 6.7671 (1.037 sec)\n",
      "[ 0.00439064]\n",
      "Epoch: 0 Training Observation: 423 : Mean Loss: 6.7545 (1.079 sec)\n",
      "[-0.00274211]\n",
      "Epoch: 0 Training Observation: 426 : Mean Loss: 6.5692 (1.033 sec)\n",
      "[ 0.00376465]\n",
      "Epoch: 0 Training Observation: 429 : Mean Loss: 6.3971 (0.967 sec)\n",
      "[-0.00273328]\n",
      "Epoch: 0 Training Observation: 432 : Mean Loss: 6.6606 (0.965 sec)\n",
      "[ 0.00439725]\n",
      "Epoch: 0 Training Observation: 435 : Mean Loss: 6.8182 (0.932 sec)\n",
      "[-0.00208976]\n",
      "Epoch: 0 Training Observation: 438 : Mean Loss: 6.7002 (0.938 sec)\n",
      "[ 0.00521336]\n",
      "Epoch: 0 Training Observation: 441 : Mean Loss: 6.2446 (1.046 sec)\n",
      "[-0.00069761]\n",
      "Epoch: 0 Training Observation: 444 : Mean Loss: 6.9290 (1.018 sec)\n",
      "[ 0.00673425]\n",
      "Epoch: 0 Training Observation: 447 : Mean Loss: 6.1570 (0.995 sec)\n",
      "[ 0.00075965]\n",
      "Epoch: 0 Training Observation: 450 : Mean Loss: 7.2670 (1.090 sec)\n",
      "[ 0.00782952]\n",
      "Epoch: 0 Training Observation: 453 : Mean Loss: 6.0992 (0.968 sec)\n",
      "[ 0.00113619]\n",
      "Epoch: 0 Training Observation: 456 : Mean Loss: 7.0953 (0.966 sec)\n",
      "[ 0.0072573]\n",
      "Epoch: 0 Training Observation: 459 : Mean Loss: 6.2571 (1.107 sec)\n",
      "[-0.00079502]\n",
      "Epoch: 0 Training Observation: 462 : Mean Loss: 6.8315 (0.977 sec)\n",
      "[ 0.00477875]\n",
      "Epoch: 0 Training Observation: 465 : Mean Loss: 6.7002 (0.974 sec)\n",
      "[-0.00279652]\n",
      "Epoch: 0 Training Observation: 468 : Mean Loss: 6.8328 (1.021 sec)\n",
      "[ 0.00350732]\n",
      "Epoch: 0 Training Observation: 471 : Mean Loss: 6.6430 (1.047 sec)\n",
      "[-0.00364224]\n",
      "Epoch: 0 Training Observation: 474 : Mean Loss: 6.5015 (0.993 sec)\n",
      "[ 0.00327565]\n",
      "Epoch: 0 Training Observation: 477 : Mean Loss: 6.7172 (0.962 sec)\n",
      "[-0.00312995]\n",
      "Epoch: 0 Training Observation: 480 : Mean Loss: 6.9544 (1.035 sec)\n",
      "[ 0.00411501]\n",
      "Epoch: 0 Training Observation: 483 : Mean Loss: 6.2906 (0.971 sec)\n",
      "[-0.00183361]\n",
      "Epoch: 0 Training Observation: 486 : Mean Loss: 7.2536 (0.938 sec)\n",
      "[ 0.00555233]\n",
      "Epoch: 0 Training Observation: 489 : Mean Loss: 6.3791 (0.934 sec)\n",
      "[-0.000685]\n",
      "Epoch: 0 Training Observation: 492 : Mean Loss: 7.3492 (0.977 sec)\n",
      "[ 0.00659685]\n",
      "Epoch: 0 Training Observation: 495 : Mean Loss: 6.1209 (0.963 sec)\n",
      "[ 0.0006421]\n",
      "Epoch: 0 Training Observation: 498 : Mean Loss: 7.4543 (1.005 sec)\n",
      "[ 0.00734021]\n",
      "Saving at epoch 0 step: 500\n",
      "Epoch: 0 Training Observation: 501 : Mean Loss: 6.0642 (0.945 sec)\n",
      "[ 0.00062775]\n",
      "Epoch: 0 Training Observation: 504 : Mean Loss: 7.5111 (0.974 sec)\n",
      "[ 0.00648498]\n",
      "Epoch: 0 Training Observation: 507 : Mean Loss: 6.3185 (0.964 sec)\n",
      "[-0.00087165]\n",
      "Epoch: 0 Training Observation: 510 : Mean Loss: 7.1216 (0.944 sec)\n",
      "[ 0.00535009]\n",
      "Epoch: 0 Training Observation: 513 : Mean Loss: 6.1839 (1.059 sec)\n",
      "[-0.00188563]\n",
      "Epoch: 0 Training Observation: 516 : Mean Loss: 6.6671 (1.022 sec)\n",
      "[ 0.0041947]\n",
      "Epoch: 0 Training Observation: 519 : Mean Loss: 6.3247 (1.066 sec)\n",
      "[-0.00322623]\n",
      "Epoch: 0 Training Observation: 522 : Mean Loss: 6.8269 (1.005 sec)\n",
      "[ 0.00277179]\n",
      "Epoch: 0 Training Observation: 525 : Mean Loss: 6.7074 (0.992 sec)\n",
      "[-0.00417142]\n",
      "Epoch: 0 Training Observation: 528 : Mean Loss: 6.4869 (0.995 sec)\n",
      "[ 0.0023305]\n",
      "Epoch: 0 Training Observation: 531 : Mean Loss: 7.0501 (0.971 sec)\n",
      "[-0.00449645]\n",
      "Epoch: 0 Training Observation: 534 : Mean Loss: 6.4861 (0.996 sec)\n",
      "[ 0.00231185]\n",
      "Epoch: 0 Training Observation: 537 : Mean Loss: 6.8549 (1.028 sec)\n",
      "[-0.00408718]\n",
      "Epoch: 0 Training Observation: 540 : Mean Loss: 6.6422 (1.055 sec)\n",
      "[ 0.00306057]\n",
      "Epoch: 0 Training Observation: 543 : Mean Loss: 6.6821 (0.967 sec)\n",
      "[-0.00355687]\n",
      "Epoch: 0 Training Observation: 546 : Mean Loss: 6.7099 (0.966 sec)\n",
      "[ 0.00328055]\n",
      "Epoch: 0 Training Observation: 549 : Mean Loss: 6.5700 (0.981 sec)\n",
      "[-0.00325326]\n",
      "Epoch: 0 Training Observation: 552 : Mean Loss: 6.4688 (0.978 sec)\n",
      "[ 0.00354969]\n",
      "Epoch: 0 Training Observation: 555 : Mean Loss: 6.6463 (0.991 sec)\n",
      "[-0.00311392]\n",
      "Epoch: 0 Training Observation: 558 : Mean Loss: 6.5064 (1.001 sec)\n",
      "[ 0.0034882]\n",
      "Epoch: 0 Training Observation: 561 : Mean Loss: 6.7072 (1.050 sec)\n",
      "[-0.00327535]\n",
      "Epoch: 0 Training Observation: 564 : Mean Loss: 6.7684 (0.967 sec)\n",
      "[ 0.00343267]\n",
      "Epoch: 0 Training Observation: 567 : Mean Loss: 6.9059 (0.973 sec)\n",
      "[-0.00335713]\n",
      "Epoch: 0 Training Observation: 570 : Mean Loss: 6.8574 (0.973 sec)\n",
      "[ 0.00325042]\n",
      "Epoch: 0 Training Observation: 573 : Mean Loss: 6.7836 (0.978 sec)\n",
      "[-0.00388395]\n",
      "Epoch: 0 Training Observation: 576 : Mean Loss: 6.8188 (1.003 sec)\n",
      "[ 0.00261988]\n",
      "Epoch: 0 Training Observation: 579 : Mean Loss: 6.5266 (1.006 sec)\n",
      "[-0.00465041]\n",
      "Epoch: 0 Training Observation: 582 : Mean Loss: 6.6894 (0.980 sec)\n",
      "[ 0.00185721]\n",
      "Epoch: 0 Training Observation: 585 : Mean Loss: 6.5749 (1.092 sec)\n",
      "[-0.00478242]\n",
      "Epoch: 0 Training Observation: 588 : Mean Loss: 6.7640 (0.986 sec)\n",
      "[ 0.00185687]\n",
      "Epoch: 0 Training Observation: 591 : Mean Loss: 6.8975 (1.036 sec)\n",
      "[-0.00479804]\n",
      "Epoch: 0 Training Observation: 594 : Mean Loss: 6.6066 (1.004 sec)\n",
      "[ 0.00182596]\n",
      "Epoch: 0 Training Observation: 597 : Mean Loss: 6.8039 (0.990 sec)\n",
      "[-0.00509367]\n",
      "Epoch: 0 Training Observation: 600 : Mean Loss: 6.5683 (0.964 sec)\n",
      "[ 0.00154787]\n",
      "Epoch: 0 Training Observation: 603 : Mean Loss: 6.9003 (0.944 sec)\n",
      "[-0.00530011]\n",
      "Epoch: 0 Training Observation: 606 : Mean Loss: 7.0324 (0.979 sec)\n",
      "[ 0.00120502]\n",
      "Epoch: 0 Training Observation: 609 : Mean Loss: 6.6575 (0.973 sec)\n",
      "[-0.00567643]\n",
      "Epoch: 0 Training Observation: 612 : Mean Loss: 6.7713 (0.976 sec)\n",
      "[ 0.00114891]\n",
      "Epoch: 0 Training Observation: 615 : Mean Loss: 6.4481 (1.023 sec)\n",
      "[-0.00514067]\n",
      "Epoch: 0 Training Observation: 618 : Mean Loss: 6.7366 (1.057 sec)\n",
      "[ 0.00213445]\n",
      "Epoch: 0 Training Observation: 621 : Mean Loss: 6.5303 (1.024 sec)\n",
      "[-0.00425123]\n",
      "Epoch: 0 Training Observation: 624 : Mean Loss: 6.7272 (1.027 sec)\n",
      "[ 0.00244493]\n",
      "Epoch: 0 Training Observation: 627 : Mean Loss: 6.2698 (0.982 sec)\n",
      "[-0.00418216]\n",
      "Epoch: 0 Training Observation: 630 : Mean Loss: 6.9784 (0.967 sec)\n",
      "[ 0.00265574]\n",
      "Epoch: 0 Training Observation: 633 : Mean Loss: 6.3453 (0.977 sec)\n",
      "[-0.00391058]\n",
      "Epoch: 0 Training Observation: 636 : Mean Loss: 6.8627 (1.013 sec)\n",
      "[ 0.00321154]\n",
      "Epoch: 0 Training Observation: 639 : Mean Loss: 6.2489 (0.984 sec)\n",
      "[-0.00306938]\n",
      "Epoch: 0 Training Observation: 642 : Mean Loss: 7.2170 (0.969 sec)\n",
      "[ 0.00384566]\n",
      "Epoch: 0 Training Observation: 645 : Mean Loss: 6.3786 (0.941 sec)\n",
      "[-0.00251129]\n",
      "Epoch: 0 Training Observation: 648 : Mean Loss: 7.4235 (1.040 sec)\n",
      "[ 0.00408112]\n",
      "Epoch: 0 Training Observation: 651 : Mean Loss: 6.3409 (1.032 sec)\n",
      "[-0.00258526]\n",
      "Epoch: 0 Training Observation: 654 : Mean Loss: 6.8143 (1.048 sec)\n",
      "[ 0.00381945]\n",
      "Epoch: 0 Training Observation: 657 : Mean Loss: 6.5069 (0.955 sec)\n",
      "[-0.00285203]\n",
      "Epoch: 0 Training Observation: 660 : Mean Loss: 7.0874 (1.001 sec)\n",
      "[ 0.00386848]\n",
      "Epoch: 0 Training Observation: 663 : Mean Loss: 6.5691 (0.981 sec)\n",
      "[-0.00305909]\n",
      "Epoch: 0 Training Observation: 666 : Mean Loss: 7.4337 (0.988 sec)\n",
      "[ 0.00395528]\n",
      "Epoch: 0 Training Observation: 669 : Mean Loss: 6.1153 (0.991 sec)\n",
      "[-0.00238507]\n",
      "Epoch: 0 Training Observation: 672 : Mean Loss: 7.0880 (0.987 sec)\n",
      "[ 0.00487215]\n",
      "Epoch: 0 Training Observation: 675 : Mean Loss: 6.0296 (0.965 sec)\n",
      "[-0.0012261]\n",
      "Epoch: 0 Training Observation: 678 : Mean Loss: 7.0731 (0.945 sec)\n",
      "[ 0.00559141]\n",
      "Epoch: 0 Training Observation: 681 : Mean Loss: 6.2611 (0.983 sec)\n",
      "[-0.00135414]\n",
      "Epoch: 0 Training Observation: 684 : Mean Loss: 7.0334 (0.999 sec)\n",
      "[ 0.00478314]\n",
      "Epoch: 0 Training Observation: 687 : Mean Loss: 6.8775 (1.012 sec)\n",
      "[-0.00295786]\n",
      "Epoch: 0 Training Observation: 690 : Mean Loss: 6.8288 (0.988 sec)\n",
      "[ 0.00255814]\n",
      "Epoch: 0 Training Observation: 693 : Mean Loss: 6.8638 (0.949 sec)\n",
      "[-0.00527885]\n",
      "Epoch: 0 Training Observation: 696 : Mean Loss: 6.5054 (0.975 sec)\n",
      "[ 0.00053511]\n",
      "Epoch: 0 Training Observation: 699 : Mean Loss: 7.2069 (1.003 sec)\n",
      "[-0.00647276]\n",
      "Epoch: 0 Training Observation: 702 : Mean Loss: 6.5896 (0.965 sec)\n",
      "[ 0.00051298]\n",
      "Epoch: 0 Training Observation: 705 : Mean Loss: 7.1068 (0.975 sec)\n",
      "[-0.00552554]\n",
      "Epoch: 0 Training Observation: 708 : Mean Loss: 7.0256 (0.960 sec)\n",
      "[ 0.00188358]\n",
      "Epoch: 0 Training Observation: 711 : Mean Loss: 6.6317 (0.963 sec)\n",
      "[-0.00444594]\n",
      "Epoch: 0 Training Observation: 714 : Mean Loss: 6.8238 (1.022 sec)\n",
      "[ 0.00294845]\n",
      "Epoch: 0 Training Observation: 717 : Mean Loss: 6.1192 (1.018 sec)\n",
      "[-0.00317665]\n",
      "Epoch: 0 Training Observation: 720 : Mean Loss: 7.1987 (1.032 sec)\n",
      "[ 0.00389134]\n",
      "Epoch: 0 Training Observation: 723 : Mean Loss: 6.1790 (1.057 sec)\n",
      "[-0.00246563]\n",
      "Epoch: 0 Training Observation: 726 : Mean Loss: 7.5132 (1.062 sec)\n",
      "[ 0.00467905]\n",
      "Epoch: 0 Training Observation: 729 : Mean Loss: 6.0819 (1.021 sec)\n",
      "[-0.00164918]\n",
      "Epoch: 0 Training Observation: 732 : Mean Loss: 7.4154 (1.025 sec)\n",
      "[ 0.00486476]\n",
      "Epoch: 0 Training Observation: 735 : Mean Loss: 6.1839 (1.015 sec)\n",
      "[-0.00200268]\n",
      "Epoch: 0 Training Observation: 738 : Mean Loss: 7.0241 (0.971 sec)\n",
      "[ 0.00444066]\n",
      "Epoch: 0 Training Observation: 741 : Mean Loss: 6.3040 (0.996 sec)\n",
      "[-0.00236715]\n",
      "Epoch: 0 Training Observation: 744 : Mean Loss: 7.2076 (0.973 sec)\n",
      "[ 0.0039889]\n",
      "Epoch: 0 Training Observation: 747 : Mean Loss: 6.6030 (0.996 sec)\n",
      "[-0.00324677]\n",
      "Epoch: 0 Training Observation: 750 : Mean Loss: 6.9938 (1.039 sec)\n",
      "[ 0.00326896]\n",
      "Saving at epoch 0 step: 750\n",
      "Epoch: 0 Training Observation: 753 : Mean Loss: 6.5271 (1.006 sec)\n",
      "[-0.00362278]\n",
      "Epoch: 0 Training Observation: 756 : Mean Loss: 6.9034 (1.006 sec)\n",
      "[ 0.00267309]\n",
      "Epoch: 0 Training Observation: 759 : Mean Loss: 6.7281 (1.046 sec)\n",
      "[-0.0045099]\n",
      "Epoch: 0 Training Observation: 762 : Mean Loss: 6.9614 (0.964 sec)\n",
      "[ 0.00186353]\n",
      "Epoch: 0 Training Observation: 765 : Mean Loss: 6.7161 (0.967 sec)\n",
      "[-0.00517298]\n",
      "Epoch: 0 Training Observation: 768 : Mean Loss: 6.9625 (1.032 sec)\n",
      "[ 0.00107203]\n",
      "Epoch: 0 Training Observation: 771 : Mean Loss: 6.6790 (1.030 sec)\n",
      "[-0.00634021]\n",
      "Epoch: 0 Training Observation: 774 : Mean Loss: 6.8755 (1.061 sec)\n",
      "[ -7.16887880e-05]\n",
      "Epoch: 0 Training Observation: 777 : Mean Loss: 7.2060 (0.965 sec)\n",
      "[-0.00675476]\n",
      "Epoch: 0 Training Observation: 780 : Mean Loss: 6.5263 (1.004 sec)\n",
      "[ -4.14713286e-05]\n",
      "Epoch: 0 Training Observation: 783 : Mean Loss: 7.0653 (1.007 sec)\n",
      "[-0.0065323]\n",
      "Epoch: 0 Training Observation: 786 : Mean Loss: 7.0363 (1.000 sec)\n",
      "[ 0.00050205]\n",
      "Epoch: 0 Training Observation: 789 : Mean Loss: 6.5978 (0.980 sec)\n",
      "[-0.00591339]\n",
      "Epoch: 0 Training Observation: 792 : Mean Loss: 6.9322 (1.046 sec)\n",
      "[ 0.00082908]\n",
      "Epoch: 0 Training Observation: 795 : Mean Loss: 7.1905 (0.975 sec)\n",
      "[-0.00589083]\n",
      "Epoch: 0 Training Observation: 798 : Mean Loss: 6.7519 (0.997 sec)\n",
      "[ 0.00067503]\n",
      "Epoch: 0 Training Observation: 801 : Mean Loss: 6.8766 (1.076 sec)\n",
      "[-0.00609171]\n",
      "Epoch: 0 Training Observation: 804 : Mean Loss: 6.7199 (1.018 sec)\n",
      "[ 0.00059315]\n",
      "Epoch: 0 Training Observation: 807 : Mean Loss: 7.0686 (1.015 sec)\n",
      "[-0.00619778]\n",
      "Epoch: 0 Training Observation: 810 : Mean Loss: 6.7303 (1.071 sec)\n",
      "[ 0.00023205]\n",
      "Epoch: 0 Training Observation: 813 : Mean Loss: 7.0722 (1.006 sec)\n",
      "[-0.00711554]\n",
      "Epoch: 0 Training Observation: 816 : Mean Loss: 6.4361 (0.965 sec)\n",
      "[-0.00054815]\n",
      "Epoch: 0 Training Observation: 819 : Mean Loss: 7.0886 (1.065 sec)\n",
      "[-0.00692117]\n",
      "Epoch: 0 Training Observation: 822 : Mean Loss: 6.8175 (0.973 sec)\n",
      "[ -2.83862464e-05]\n",
      "Epoch: 0 Training Observation: 825 : Mean Loss: 6.9539 (0.965 sec)\n",
      "[-0.00614728]\n",
      "Epoch: 0 Training Observation: 828 : Mean Loss: 7.0113 (0.973 sec)\n",
      "[ 0.00101224]\n",
      "Epoch: 0 Training Observation: 831 : Mean Loss: 7.0639 (0.968 sec)\n",
      "[-0.00555161]\n",
      "Epoch: 0 Training Observation: 834 : Mean Loss: 6.5142 (0.970 sec)\n",
      "[ 0.0012709]\n",
      "Epoch: 0 Training Observation: 837 : Mean Loss: 7.1371 (0.964 sec)\n",
      "[-0.00547201]\n",
      "Epoch: 0 Training Observation: 840 : Mean Loss: 6.7640 (0.989 sec)\n",
      "[ 0.00130027]\n",
      "Epoch: 0 Training Observation: 843 : Mean Loss: 6.9204 (0.966 sec)\n",
      "[-0.00498598]\n",
      "Epoch: 0 Training Observation: 846 : Mean Loss: 7.0777 (1.030 sec)\n",
      "[ 0.00246926]\n",
      "Epoch: 0 Training Observation: 849 : Mean Loss: 6.8956 (1.029 sec)\n",
      "[-0.00387795]\n",
      "Epoch: 0 Training Observation: 852 : Mean Loss: 7.3672 (0.993 sec)\n",
      "[ 0.00325122]\n",
      "Epoch: 0 Training Observation: 855 : Mean Loss: 6.7939 (0.987 sec)\n",
      "[-0.0034471]\n",
      "Epoch: 0 Training Observation: 858 : Mean Loss: 7.3011 (0.988 sec)\n",
      "[ 0.00333963]\n",
      "Epoch: 0 Training Observation: 861 : Mean Loss: 6.4115 (1.039 sec)\n",
      "[-0.00281202]\n",
      "Epoch: 0 Training Observation: 864 : Mean Loss: 7.3818 (0.963 sec)\n",
      "[ 0.00434433]\n",
      "Epoch: 0 Training Observation: 867 : Mean Loss: 6.2609 (1.032 sec)\n",
      "[-0.0019171]\n",
      "Epoch: 0 Training Observation: 870 : Mean Loss: 7.1904 (1.034 sec)\n",
      "[ 0.00492593]\n",
      "Epoch: 0 Training Observation: 873 : Mean Loss: 6.6751 (1.045 sec)\n",
      "[-0.0015033]\n",
      "Epoch: 0 Training Observation: 876 : Mean Loss: 7.7180 (1.044 sec)\n",
      "[ 0.00568065]\n",
      "Epoch: 0 Training Observation: 879 : Mean Loss: 6.5499 (1.101 sec)\n",
      "[-0.00107493]\n",
      "Epoch: 0 Training Observation: 882 : Mean Loss: 7.3249 (1.046 sec)\n",
      "[ 0.00511886]\n",
      "Epoch: 0 Training Observation: 885 : Mean Loss: 6.5316 (1.022 sec)\n",
      "[-0.00213983]\n",
      "Epoch: 0 Training Observation: 888 : Mean Loss: 6.8111 (1.112 sec)\n",
      "[ 0.00379223]\n",
      "Epoch: 0 Training Observation: 891 : Mean Loss: 7.0206 (1.050 sec)\n",
      "[-0.00341121]\n",
      "Epoch: 0 Training Observation: 894 : Mean Loss: 7.1352 (1.078 sec)\n",
      "[ 0.00328879]\n",
      "Epoch: 0 Training Observation: 897 : Mean Loss: 6.8432 (0.982 sec)\n",
      "[-0.00354195]\n",
      "Epoch: 0 Training Observation: 900 : Mean Loss: 6.4778 (1.023 sec)\n",
      "[ 0.00283222]\n",
      "Epoch: 0 Training Observation: 903 : Mean Loss: 6.8872 (1.042 sec)\n",
      "[-0.00370525]\n",
      "Epoch: 0 Training Observation: 906 : Mean Loss: 6.5653 (0.950 sec)\n",
      "[ 0.00293677]\n",
      "Epoch: 0 Training Observation: 909 : Mean Loss: 6.8383 (0.941 sec)\n",
      "[-0.0037336]\n",
      "Epoch: 0 Training Observation: 912 : Mean Loss: 6.7698 (0.969 sec)\n",
      "[ 0.00291699]\n",
      "Epoch: 0 Training Observation: 915 : Mean Loss: 7.0081 (0.995 sec)\n",
      "[-0.00421012]\n",
      "Epoch: 0 Training Observation: 918 : Mean Loss: 6.7371 (0.970 sec)\n",
      "[ 0.00215169]\n",
      "Epoch: 0 Training Observation: 921 : Mean Loss: 7.2707 (1.047 sec)\n",
      "[-0.00445067]\n",
      "Epoch: 0 Training Observation: 924 : Mean Loss: 6.7826 (1.075 sec)\n",
      "[ 0.00260249]\n",
      "Epoch: 0 Training Observation: 927 : Mean Loss: 7.1844 (0.969 sec)\n",
      "[-0.00403666]\n",
      "Epoch: 0 Training Observation: 930 : Mean Loss: 6.8464 (0.975 sec)\n",
      "[ 0.00257789]\n",
      "Epoch: 0 Training Observation: 933 : Mean Loss: 6.8526 (0.977 sec)\n",
      "[-0.00429824]\n",
      "Epoch: 0 Training Observation: 936 : Mean Loss: 7.1872 (0.982 sec)\n",
      "[ 0.00248551]\n",
      "Epoch: 0 Training Observation: 939 : Mean Loss: 6.7752 (1.141 sec)\n",
      "[-0.00439318]\n",
      "Epoch: 0 Training Observation: 942 : Mean Loss: 6.7639 (1.032 sec)\n",
      "[ 0.00199426]\n",
      "Epoch: 0 Training Observation: 945 : Mean Loss: 6.9904 (0.997 sec)\n",
      "[-0.00541221]\n",
      "Epoch: 0 Training Observation: 948 : Mean Loss: 6.4305 (1.024 sec)\n",
      "[ 0.00044581]\n",
      "Epoch: 0 Training Observation: 951 : Mean Loss: 7.2738 (0.987 sec)\n",
      "[-0.00696451]\n",
      "Epoch: 0 Training Observation: 954 : Mean Loss: 6.6952 (1.015 sec)\n",
      "[-0.00080244]\n",
      "Epoch: 0 Training Observation: 957 : Mean Loss: 7.4594 (1.018 sec)\n",
      "[-0.00760112]\n",
      "Epoch: 0 Training Observation: 960 : Mean Loss: 6.3701 (0.999 sec)\n",
      "[-0.00077864]\n",
      "Epoch: 0 Training Observation: 963 : Mean Loss: 7.4912 (0.939 sec)\n",
      "[-0.00688086]\n",
      "Epoch: 0 Training Observation: 966 : Mean Loss: 6.3193 (0.970 sec)\n",
      "[ 0.00023539]\n",
      "Epoch: 0 Training Observation: 969 : Mean Loss: 7.2726 (0.937 sec)\n",
      "[-0.00619729]\n",
      "Epoch: 0 Training Observation: 972 : Mean Loss: 6.6333 (0.969 sec)\n",
      "[ 0.00109692]\n",
      "Epoch: 0 Training Observation: 975 : Mean Loss: 7.3577 (0.983 sec)\n",
      "[-0.00530222]\n",
      "Epoch: 0 Training Observation: 978 : Mean Loss: 6.6348 (1.016 sec)\n",
      "[ 0.00156753]\n",
      "Epoch: 0 Training Observation: 981 : Mean Loss: 7.3672 (1.036 sec)\n",
      "[-0.00532356]\n",
      "Epoch: 0 Training Observation: 984 : Mean Loss: 6.7775 (0.956 sec)\n",
      "[ 0.00146232]\n",
      "Epoch: 0 Training Observation: 987 : Mean Loss: 7.4734 (0.961 sec)\n",
      "[-0.00522925]\n",
      "Epoch: 0 Training Observation: 990 : Mean Loss: 6.2013 (0.949 sec)\n",
      "[ 0.00157384]\n",
      "Epoch: 0 Training Observation: 993 : Mean Loss: 7.1276 (0.973 sec)\n",
      "[-0.00519341]\n",
      "Epoch: 0 Training Observation: 996 : Mean Loss: 6.3594 (0.976 sec)\n",
      "[ 0.0015576]\n",
      "Epoch: 0 Training Observation: 999 : Mean Loss: 7.2173 (0.973 sec)\n",
      "[-0.00496372]\n",
      "Saving at epoch 0 step: 1000\n",
      "Epoch: 0 Training Observation: 1002 : Mean Loss: 6.4273 (1.052 sec)\n",
      "[ 0.00207511]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ff962a0e98d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of\n",
    "number_of_epochs = 10\n",
    "batches_per_epoch = len(x_train_text)/batch_size\n",
    "number_of_batches = math.ceil(len(x_train_text)/batch_size)\n",
    "number_of_validation_batches = number_of_batches\n",
    "\n",
    "logs_dir = \"logs/bagofwords\"\n",
    "\n",
    "checkpoint_frequency = 250\n",
    "\n",
    "reporting_frequency = 3\n",
    "\n",
    "total_loss = 0\n",
    "validation_loss = 0\n",
    "validation_batch_average_window = 100\n",
    "\n",
    "model_path = os.path.join(logs_dir, time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "ckpt = None\n",
    "ckpt = tf.train.get_checkpoint_state(logs_dir)                                     \n",
    "\n",
    "if ckpt:\n",
    "    restore_from_model = True\n",
    "    print(\"Restore from model!\")\n",
    "else:\n",
    "    restore_from_model = False\n",
    "\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "    summaries = tf.summary.merge_all()                                                       \n",
    "    writer = tf.summary.FileWriter(model_path,\n",
    "        graph=session.graph)                  \n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables()) \n",
    "                                                                                                  \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    if restore_from_model:\n",
    "        saver.restore(session, ckpt.model_checkpoint_path)\n",
    "        \n",
    "    for epoch in range(number_of_epochs):\n",
    "        eval_feed_generator = eval_input_fn()\n",
    "\n",
    "        for step, feed_dict in enumerate(input_fn()):\n",
    "            start_time = time.time()\n",
    "\n",
    "            _, temp_loss = session.run([train_op, loss], feed_dict=feed_dict)\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            total_loss += temp_loss\n",
    "            if (step + 1) % reporting_frequency == 0:\n",
    "                print(\"Epoch: %s Training Observation: %s : Mean Loss: %.4f (%.3f sec)\" % (epoch, (step + 1), total_loss/reporting_frequency, duration))\n",
    "                print(b.eval())\n",
    "                total_loss = 0\n",
    "                train_summ, train_mae = session.run([training_summary, training_mae], feed_dict=feed_dict)\n",
    "                writer.add_summary(train_summ, step)\n",
    "                writer.add_summary(train_mae, step)\n",
    "\n",
    "                _, valid_summ, valid_mae = session.run(\n",
    "                    [loss, validation_summary, validation_mae],\n",
    "                    feed_dict=next(eval_feed_generator))\n",
    "                writer.add_summary(valid_summ, step)\n",
    "                writer.add_summary(valid_mae, step)\n",
    "                \n",
    "                writer.flush()                \n",
    "\n",
    "            if ((step + 1) % checkpoint_frequency == 0) or (step + 1 == number_of_batches):\n",
    "                print(\"Saving at epoch %s step: %s\" % (epoch, step + 1))\n",
    "                saver.save(session, model_path, global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from logs/bagofwords/2017-06-11-18-50-07-2750\n",
      "[[ 7.62809706]\n",
      " [ 5.58852959]\n",
      " [ 5.59177494]\n",
      " [ 4.19827127]\n",
      " [ 4.77808237]\n",
      " [ 4.40655136]\n",
      " [ 5.71067286]\n",
      " [ 5.22041607]\n",
      " [ 6.01734018]\n",
      " [ 5.10449934]\n",
      " [ 5.30105305]\n",
      " [ 3.81013751]\n",
      " [ 6.34175777]\n",
      " [ 5.82009935]\n",
      " [ 3.93765473]\n",
      " [ 5.24715519]\n",
      " [ 4.14017725]\n",
      " [ 5.00824213]\n",
      " [ 2.93639183]\n",
      " [ 9.80047035]\n",
      " [ 5.68838787]\n",
      " [ 5.69848299]\n",
      " [ 4.90348387]\n",
      " [ 4.14938688]\n",
      " [ 0.48562685]\n",
      " [ 6.66180992]\n",
      " [ 6.97311687]\n",
      " [ 5.20588207]\n",
      " [ 5.91129065]\n",
      " [ 5.41713524]\n",
      " [ 5.55389643]\n",
      " [ 4.1693902 ]]\n",
      "[[ 4.40772581]\n",
      " [ 4.85887718]\n",
      " [ 5.63510847]\n",
      " [ 4.16571617]\n",
      " [ 3.0416162 ]\n",
      " [ 5.06451511]\n",
      " [ 7.68068266]\n",
      " [ 8.1142025 ]\n",
      " [ 4.6945343 ]\n",
      " [ 2.70778513]\n",
      " [ 2.93298984]\n",
      " [ 5.79860401]\n",
      " [ 4.44708443]\n",
      " [ 6.07296944]\n",
      " [ 5.85468292]\n",
      " [ 3.97273922]\n",
      " [ 5.29035854]\n",
      " [ 5.34177971]\n",
      " [ 4.53326225]\n",
      " [ 5.20281601]\n",
      " [ 3.1871531 ]\n",
      " [ 5.94475555]\n",
      " [ 3.72513795]\n",
      " [ 1.50133336]\n",
      " [ 7.20599651]\n",
      " [ 3.39951134]\n",
      " [ 2.5661459 ]\n",
      " [ 3.28695846]\n",
      " [ 5.98905182]\n",
      " [ 2.79651403]\n",
      " [ 8.67771339]\n",
      " [ 6.48588419]]\n",
      "[[ 5.03654671]\n",
      " [ 4.21111345]\n",
      " [ 3.05965567]\n",
      " [ 6.02850819]\n",
      " [ 4.91266918]\n",
      " [ 5.18668461]\n",
      " [ 5.123703  ]\n",
      " [ 5.31476974]\n",
      " [ 4.97812223]\n",
      " [ 5.05777311]\n",
      " [ 7.00302553]\n",
      " [ 5.62938738]\n",
      " [ 6.30599642]\n",
      " [ 5.82964468]\n",
      " [ 4.69699574]\n",
      " [ 7.79879951]\n",
      " [ 4.85689402]\n",
      " [ 5.45765972]\n",
      " [ 6.31098461]\n",
      " [ 6.52507114]\n",
      " [ 5.77845621]\n",
      " [ 5.32330036]\n",
      " [ 6.06034184]\n",
      " [ 7.5296073 ]\n",
      " [ 8.68961239]\n",
      " [ 4.71343184]\n",
      " [ 4.50584984]\n",
      " [ 5.7076869 ]\n",
      " [ 5.42471552]\n",
      " [ 4.54559708]\n",
      " [ 4.56745911]\n",
      " [ 3.69797444]]\n",
      "[[ 1.61007655]\n",
      " [ 4.24999142]\n",
      " [ 6.4610796 ]\n",
      " [ 6.50738907]\n",
      " [ 4.58459234]\n",
      " [ 3.96176934]\n",
      " [ 3.5536325 ]\n",
      " [ 5.47843933]\n",
      " [ 1.59505355]\n",
      " [ 5.40553522]\n",
      " [ 2.63772726]\n",
      " [ 4.80988932]\n",
      " [ 6.24600792]\n",
      " [ 4.01552534]\n",
      " [ 7.35194111]\n",
      " [ 5.65605068]\n",
      " [ 5.88657951]\n",
      " [ 2.9257443 ]\n",
      " [ 7.02493429]\n",
      " [ 4.68978453]\n",
      " [ 4.90490532]\n",
      " [ 3.39246726]\n",
      " [ 5.60365486]\n",
      " [ 5.37645006]\n",
      " [ 5.95102978]\n",
      " [ 6.31377649]\n",
      " [ 6.65525723]\n",
      " [ 3.82785106]\n",
      " [ 2.44830418]\n",
      " [ 4.29850674]\n",
      " [ 6.02770472]\n",
      " [ 4.81553173]]\n",
      "[[ 8.27385998]\n",
      " [ 6.0850873 ]\n",
      " [ 5.19585752]\n",
      " [ 6.1372962 ]\n",
      " [ 5.91317081]\n",
      " [ 3.07738876]\n",
      " [ 3.83809805]\n",
      " [ 2.09505057]\n",
      " [ 5.83425808]\n",
      " [ 3.59003162]\n",
      " [ 4.89274025]\n",
      " [ 5.85088587]\n",
      " [ 4.06004238]\n",
      " [ 4.27935505]\n",
      " [ 5.01458549]\n",
      " [ 5.30685472]\n",
      " [ 4.29633999]\n",
      " [ 4.04783344]\n",
      " [ 5.63558388]\n",
      " [ 5.94133949]\n",
      " [ 2.89638495]\n",
      " [ 4.67368317]\n",
      " [ 5.1564846 ]\n",
      " [ 4.70594311]\n",
      " [ 5.25351   ]\n",
      " [ 4.11492538]\n",
      " [ 5.23559809]\n",
      " [ 5.7780571 ]\n",
      " [ 1.35698938]\n",
      " [ 5.63180256]\n",
      " [ 6.529037  ]\n",
      " [ 5.99990225]]\n",
      "[[ 6.29515123]\n",
      " [ 4.23459339]\n",
      " [ 3.45276785]\n",
      " [ 5.73211288]\n",
      " [ 5.61424971]\n",
      " [ 3.74092579]\n",
      " [ 4.54996586]\n",
      " [ 4.1652174 ]\n",
      " [ 4.48240709]\n",
      " [ 5.4833684 ]\n",
      " [ 6.25335169]\n",
      " [ 5.70569134]\n",
      " [ 5.75435066]\n",
      " [ 4.41109848]\n",
      " [ 3.85117817]\n",
      " [ 3.80028343]\n",
      " [ 5.6527257 ]\n",
      " [ 1.1272105 ]\n",
      " [ 3.94181204]\n",
      " [ 5.1471138 ]\n",
      " [ 8.23260593]\n",
      " [ 4.55187988]\n",
      " [ 5.10041714]\n",
      " [ 2.54840112]\n",
      " [ 4.62970877]\n",
      " [ 5.02999306]\n",
      " [ 3.25746608]\n",
      " [ 7.39204121]\n",
      " [ 1.91655552]\n",
      " [ 5.37849283]\n",
      " [ 5.96280479]\n",
      " [ 5.89183426]]\n",
      "[[ 4.37084913]\n",
      " [ 4.97720671]\n",
      " [ 4.65870714]\n",
      " [ 4.15974188]\n",
      " [ 3.71765351]\n",
      " [ 3.86664009]\n",
      " [ 5.37563467]\n",
      " [ 6.4794445 ]\n",
      " [ 4.67042065]\n",
      " [ 4.93007708]\n",
      " [ 6.35662079]\n",
      " [ 4.27621317]\n",
      " [ 4.37107134]\n",
      " [ 4.0020628 ]\n",
      " [ 3.60496664]\n",
      " [ 5.67511463]\n",
      " [ 5.45855474]\n",
      " [ 3.79042125]\n",
      " [ 3.90491891]\n",
      " [ 3.61870432]\n",
      " [ 5.0100565 ]\n",
      " [ 5.47197151]\n",
      " [ 5.93049765]\n",
      " [ 5.78568888]\n",
      " [ 4.46045065]\n",
      " [ 6.82631111]\n",
      " [ 3.34790874]\n",
      " [ 3.81506157]\n",
      " [ 4.94083643]\n",
      " [ 5.94702911]\n",
      " [ 4.69028378]\n",
      " [ 3.95176935]]\n",
      "[[ 4.75923824]\n",
      " [ 7.02136374]\n",
      " [ 3.43547964]\n",
      " [ 5.74032784]\n",
      " [ 4.54512501]\n",
      " [ 5.11826849]\n",
      " [ 5.54076385]\n",
      " [ 5.94236279]\n",
      " [ 8.03635693]\n",
      " [ 3.39260888]\n",
      " [ 4.44898129]\n",
      " [ 3.61111116]\n",
      " [ 3.1670661 ]\n",
      " [ 4.78964376]\n",
      " [ 6.52083349]\n",
      " [ 4.49386215]\n",
      " [ 2.11523318]\n",
      " [ 4.0754962 ]\n",
      " [ 7.28068352]\n",
      " [ 7.07103872]\n",
      " [ 6.68833017]\n",
      " [ 4.81398773]\n",
      " [ 5.69657087]\n",
      " [ 6.02505112]\n",
      " [ 5.23356771]\n",
      " [ 1.42444575]\n",
      " [ 4.70580578]\n",
      " [ 6.25994635]\n",
      " [ 5.56994581]\n",
      " [ 5.1424098 ]\n",
      " [ 5.25140429]\n",
      " [ 6.35475206]]\n",
      "[[ 5.2341485 ]\n",
      " [ 8.42911053]\n",
      " [ 7.09398556]\n",
      " [ 4.00184727]\n",
      " [ 5.70075035]\n",
      " [ 5.11719036]\n",
      " [ 5.21713686]\n",
      " [ 5.06899595]\n",
      " [ 4.76356077]\n",
      " [ 5.11938381]\n",
      " [ 2.74134278]\n",
      " [ 5.66293526]\n",
      " [ 5.30960703]\n",
      " [ 5.22589445]\n",
      " [ 6.28157377]\n",
      " [ 4.25784397]\n",
      " [ 3.27670741]\n",
      " [ 6.11859703]\n",
      " [ 6.12180805]\n",
      " [ 3.2501781 ]\n",
      " [ 4.82214212]\n",
      " [ 6.48604965]\n",
      " [ 2.06116867]\n",
      " [ 3.08556461]\n",
      " [ 5.89005804]\n",
      " [ 4.98703909]\n",
      " [ 4.67541981]\n",
      " [ 5.17365932]\n",
      " [ 9.19201183]\n",
      " [ 4.69008112]\n",
      " [ 3.92940307]\n",
      " [ 9.62516975]]\n",
      "[[ 5.63703251]\n",
      " [ 4.78207016]\n",
      " [ 3.09466195]\n",
      " [ 7.19077444]\n",
      " [ 4.58700371]\n",
      " [ 5.54692268]\n",
      " [ 4.88514185]\n",
      " [ 5.5216217 ]\n",
      " [ 4.9088316 ]\n",
      " [ 6.09807014]\n",
      " [ 6.20546675]\n",
      " [ 3.62623286]\n",
      " [ 6.69764137]\n",
      " [ 4.87057734]\n",
      " [ 4.72167873]\n",
      " [ 3.60360265]\n",
      " [ 4.81661892]\n",
      " [ 5.25403452]\n",
      " [ 7.11412811]\n",
      " [ 4.81941032]\n",
      " [ 4.8808465 ]\n",
      " [ 3.03796792]\n",
      " [ 5.83560133]\n",
      " [ 5.29350138]\n",
      " [ 7.37229156]\n",
      " [ 4.2364006 ]\n",
      " [ 5.14970827]\n",
      " [ 3.47919178]\n",
      " [ 3.6890645 ]\n",
      " [ 5.36623287]\n",
      " [ 4.83947182]\n",
      " [ 3.90211225]]\n",
      "[[ 5.15719938]\n",
      " [ 3.9711597 ]\n",
      " [ 6.6112361 ]\n",
      " [ 5.19056797]\n",
      " [ 4.35617876]\n",
      " [ 3.41260648]\n",
      " [ 6.6405859 ]\n",
      " [ 5.74423122]\n",
      " [ 5.876472  ]\n",
      " [ 4.38145018]\n",
      " [ 5.56353045]\n",
      " [ 4.830832  ]\n",
      " [ 4.93518066]\n",
      " [ 5.12647629]\n",
      " [ 1.12551808]\n",
      " [ 3.27862072]\n",
      " [ 4.78555441]\n",
      " [ 4.88695669]\n",
      " [ 3.23096108]\n",
      " [ 7.36539078]\n",
      " [ 1.51820767]\n",
      " [ 5.71259642]\n",
      " [ 4.59456444]\n",
      " [ 4.5777216 ]\n",
      " [ 4.78297138]\n",
      " [ 5.85856915]\n",
      " [ 4.54926252]\n",
      " [ 4.52693796]\n",
      " [ 5.96791744]\n",
      " [ 4.75290203]\n",
      " [ 1.56740689]\n",
      " [ 4.80905628]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-94913b7c20c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(model_output.eval(eval_feed_dict))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(valid_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# How much data to evaluate\n",
    "#number_of_batches = len(x_train_text)/batch_size\n",
    "number_of_validation_batches = len(x_test_text)/batch_size\n",
    "ckpt = tf.train.get_checkpoint_state(logs_dir)                                     \n",
    "\n",
    "\n",
    "# Write TF Model Evaluation Code here. \n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables()) \n",
    "                                                                                                  \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver.restore(session, ckpt.model_checkpoint_path)\n",
    "\n",
    "    \n",
    "    total_loss = 0\n",
    "    for step, eval_feed_dict in enumerate(eval_input_fn()):\n",
    "        #print(model_output.eval(eval_feed_dict))\n",
    "    \n",
    "        valid_loss, check = session.run([loss, model_output], feed_dict=eval_feed_dict)\n",
    "        #print(valid_loss)\n",
    "        print(check)\n",
    "        #total_loss += valid_loss[0]\n",
    "    print (total_loss/step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-72254d444db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "#model_output.eval()\n",
    "eval_generator = eval_input_fn()\n",
    "\n",
    "with sess:\n",
    "    saver = tf.train.Saver(tf.global_variables())                                                                                               \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model_output, feed_dict=next(eval_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:335: calling LinearRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Couldn't find trained model at /tmp/tmpc4vvis3j.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-923d676c9ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-923d676c9ea3>\u001b[0m in \u001b[0;36mprint_results\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLABEL_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m               func.__module__, arg_name, arg_value, date, instructions)\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    337\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m               func.__module__, arg_name, arg_value, date, instructions)\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    337\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[1;32m    755\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m           as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    758\u001b[0m     return super(LinearRegressor, self).predict(\n\u001b[1;32m    759\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m               func.__module__, arg_name, arg_value, date, instructions)\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    337\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\u001b[0m in \u001b[0;36mpredict_scores\u001b[0;34m(self, x, input_fn, batch_size, as_iterable)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    793\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_as_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    283\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mfeed_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_infer_model\u001b[0;34m(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       raise NotFittedError(\"Couldn't find trained model at %s.\"\n\u001b[0;32m--> 851\u001b[0;31m                            % self._model_dir)\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Couldn't find trained model at /tmp/tmpc4vvis3j."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def print_results(model):\n",
    "    y_vals = [value for value in model.predict(input_fn=eval_input_fn)]\n",
    "    x_vals = X_test[LABEL_COLUMN]\n",
    "\n",
    "\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "    plt.show()\n",
    "\n",
    "    print(x_vals-y_vals)\n",
    "    #print(sorted([set(y_vals)]))\n",
    "\n",
    "    print(\"Mean absolute error: %s\" % \n",
    "          mean_absolute_error_salary_scale(y_vals, x_vals))\n",
    "    \n",
    "    \n",
    "print_results(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
