{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Core python libraries\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# External libraries.\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import sklearn\n",
    "import tempfile\n",
    "\n",
    "# Tensorflow and related.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imp\n",
    "\n",
    "import tf_utils\n",
    "tf_utils = imp.reload(tf_utils)\n",
    "\n",
    "# So you know when this code block finishes.\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171482\n"
     ]
    }
   ],
   "source": [
    "#TODO(Max): make a library that does all this preprocessing\n",
    "data = pandas.read_csv(\"data/train.csv\") # Can read a subset. First nrows of the total.\n",
    "LABEL_COLUMN = \"SalaryNormalized\"\n",
    "\n",
    "TEST_SIZE = .3\n",
    "\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# sklearn.cross_validation has been replaced with model_selection.\n",
    "X_train_index, X_test_index, Y_train, Y_test = sklearn.model_selection.train_test_split(\n",
    "    data.index, data[LABEL_COLUMN], test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Keep train and test as pandas dataframes.\n",
    "X_train = data.iloc[X_train_index]\n",
    "X_test = data.iloc[X_test_index]\n",
    "\n",
    "y_train = numpy.array(X_train[LABEL_COLUMN].astype(numpy.float32))\n",
    "y_test = numpy.array(X_test[LABEL_COLUMN].astype(numpy.float32))\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalizing input values to mean 0, standard deviation 1.\n",
    "train_mean, train_std = y_train.mean(), y_train.std()\n",
    "\n",
    "# Normalize input labels and expectations\n",
    "y_train = tf_utils.normalize_input(y_train, train_mean, train_std)\n",
    "y_test = tf_utils.normalize_input(y_test, train_mean, train_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17698.3\n",
      "[ 0.89645004 -0.66550416  3.22435188 ..., -0.29010177  0.89645004\n",
      "  0.95295256]\n"
     ]
    }
   ],
   "source": [
    "print(train_std)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_column = \"CompleteJobListingStemmed\"\n",
    "\n",
    "x_train_text = X_train[target_column]\n",
    "x_test_text = X_test[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: 120037, 8762\n",
      "x_test shape: 51445, 8762\n",
      "Total distinct words: 8762\n"
     ]
    }
   ],
   "source": [
    "min_word_frequency = 59\n",
    "\n",
    "sklearn_bow = True # Otherwise we use Tensorflow BOW.\n",
    "\n",
    "if sklearn_bow:\n",
    "    # Gives 7600 unique words with min frequency 75 and stopwords removed.\n",
    "    # 7797 if we leave stopwords in.\n",
    "\n",
    "    count_vect = sklearn.feature_extraction.text.CountVectorizer(\n",
    "        min_df=min_word_frequency, decode_error='ignore')\n",
    "\n",
    "    # Transform BOW test set.\n",
    "    x_train = count_vect.fit_transform(x_train_text)\n",
    "    x_test = count_vect.transform(x_test_text)\n",
    "    n_words = x_train.shape[1]\n",
    "    max_document_length = n_words\n",
    "\n",
    "else:\n",
    "    # Look here for a tutorial https://medium.com/@ilblackdragon/tensorflow-text-classification-615198df9231\n",
    "    # Gives 8712 unique words with min word frequency of 75\n",
    "    vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(\n",
    "        max_document_length, min_frequency=min_word_frequency)\n",
    "    x_train = numpy.array(list(vocab_processor.fit_transform(x_train_text)))\n",
    "    x_test = numpy.array(list(vocab_processor.transform(x_test_text)))\n",
    "    n_words = len(vocab_processor.vocabulary_)\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_train_text])\n",
    "    \n",
    "print(\"x_train shape: %s, %s\" % x_train.shape)\n",
    "print(\"x_test shape: %s, %s\" % x_test.shape)\n",
    "print(\"Total distinct words: %d\" % n_words)\n",
    "print(\"Number of training rows: %d\" % len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define data nput functions. These have to be done here as the \n",
    "# functions take no arguments. Also the dict labels are specific to \n",
    "# the model.\n",
    "max_document_length = n_words\n",
    "\n",
    "def input_fn():\n",
    "    for batch_input, batch_labels in tf_utils.generate_batch(\n",
    "        batch_size, number_of_batches, max_document_length,\n",
    "                                                    x_train, y_train):\n",
    "        yield {x_data: batch_input, y_target: batch_labels}\n",
    "\n",
    "def eval_input_fn():\n",
    "    for batch_input, batch_labels in tf_utils.generate_batch(\n",
    "        batch_size, number_of_validation_batches, max_document_length,\n",
    "                                                    x_test, y_test):\n",
    "        yield {x_data: batch_input, y_target: batch_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "learning_rate = .01\n",
    "\n",
    "l1_regularization_coef = 0.01\n",
    "l2_regularization_coef = 0.01\n",
    "\n",
    "# if not RMSE then MAE.\n",
    "HUBER = False\n",
    "RMSE = True\n",
    "\n",
    "#Implement this by batch.\n",
    "batch_size = 1024\n",
    "\n",
    "\"\"\"\n",
    "def huber_loss(labels, predictions, delta=1.0):\n",
    " residual = tf.abs(predictions - labels)\n",
    " condition = tf.less(residual, delta)\n",
    " small_res = 0.5 * tf.square(residual)\n",
    " large_res = delta * residual - 0.5 * tf.square(delta)\n",
    " return tf.reduce_mean(tf.where(condition, small_res, large_res))\n",
    "\"\"\"\n",
    "with graph.as_default():\n",
    "\n",
    "    with tf.name_scope(\"data\"):\n",
    "        # Initialize data placeholders\n",
    "        x_data = tf.placeholder(shape=[batch_size, max_document_length], dtype=tf.float32)\n",
    "        y_target = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name=\"labels\")\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"bag_of_words\"):\n",
    "        with tf.device('/cpu:0'):\n",
    "            identity_mat = tf.diag(tf.ones(shape=[n_words]))\n",
    "            # This is also an embedding_lookup_sparse function that would create a sparse tensor.\n",
    "            x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "            # Collapse across the document length dimension. Leaving only the number of tokens.\n",
    "            bag_of_words = tf.reduce_sum(x_embed, 1)\n",
    "\n",
    "            print(\"Woohoo this looks like my bag of words shape :D %s\" % bag_of_words.shape)\n",
    "    \"\"\"\n",
    "    # Create variables for regression\n",
    "    A = tf.Variable(tf.zeros(shape=[n_words, 1]))\n",
    "    b = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "    # A = tf.Variable(tf.random_normal(shape=[vocab_size, 1], stddev=.05))\n",
    "    # Intercept term. A scalar.\n",
    "    # b = tf.Variable(tf.random_normal(shape=[1], stddev=.05))\n",
    "\n",
    "    # Model output\n",
    "    with tf.device('/gpu:0'):\n",
    "\n",
    "        product = tf.matmul(x_data, A)\n",
    "        model_output = tf.add(product, b, name=\"predictions\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "\n",
    "        # TODO(Max) try root mean square error. Should this be merely mean square error?\n",
    "        if HUBER:\n",
    "            loss = huber_loss(y_target, model_output)\n",
    "        elif RMSE:\n",
    "            loss = tf.sqrt(tf.reduce_mean(tf.pow(tf.subtract(y_target, model_output), 2)))\n",
    "        else:\n",
    "            # Mean Absolute Error.\n",
    "            loss = tf.reduce_mean(tf.abs(tf.subtract(y_target, model_output)))\n",
    "\n",
    "        # If we are using regularization.\n",
    "        if l1_regularization_coef > 0 or l2_regularization_coef > 0:\n",
    "            l1_regularizer = tf.contrib.layers.l1_regularizer(scale=l1_regularization_coef)\n",
    "            l2_regularizer = tf.contrib.layers.l2_regularizer(scale=l2_regularization_coef)\n",
    "\n",
    "            weights = tf.trainable_variables() # all vars of your graph\n",
    "            regularization_penalty = tf.add(tf.contrib.layers.apply_regularization(l1_regularizer, weights),\n",
    "                                             tf.contrib.layers.apply_regularization(l2_regularizer, weights))\n",
    "            loss = loss + regularization_penalty # this loss needs to be minimized\n",
    "\n",
    "    with tf.name_scope(\"reporting\"):\n",
    "        # Converts back to original, salary scale.\n",
    "        error_salary_scale = tf.multiply(tf.subtract(y_target, model_output), train_std)\n",
    "\n",
    "        mean_absolute_error_salary_scale = tf.reduce_mean(\n",
    "            tf.abs(error_salary_scale))\n",
    "\n",
    "        # Log for tensorboard\n",
    "        training_summary = tf.summary.scalar('train_loss', loss)\n",
    "        validation_summary = tf.summary.scalar('validation_loss', loss)\n",
    "        # Add mean absolute errors.\n",
    "        training_mae = tf.summary.scalar('train_mae', mean_absolute_error_salary_scale)\n",
    "        validation_mae = tf.summary.scalar('validation_mae', mean_absolute_error_salary_scale)\n",
    "\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # Declare optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "    \n",
    "    # This one seems to work better :D\n",
    "    train_op = tf.contrib.layers.optimize_loss(      \n",
    "     loss, tf.contrib.framework.get_global_step(),      \n",
    "     optimizer='Adam'\n",
    "        , learning_rate=learning_rate, clip_gradients=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of\n",
    "number_of_epochs = 50\n",
    "batches_per_epoch = len(x_train_text)/batch_size\n",
    "number_of_batches = math.ceil(len(x_train_text)/batch_size)\n",
    "number_of_validation_batches = number_of_batches\n",
    "\n",
    "logs_dir = \"logs/bagofwords\"\n",
    "\n",
    "checkpoint_frequency = 500\n",
    "\n",
    "reporting_frequency = 3\n",
    "\n",
    "total_loss = 0\n",
    "validation_loss = 0\n",
    "validation_batch_average_window = 100\n",
    "\n",
    "ckpt = None\n",
    "ckpt = tf.train.get_checkpoint_state(logs_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object input_fn at 0x7f4a9ca09a98>\n",
      "Batch 1 Enqueue Duration: 7.1514\n",
      "<generator object input_fn at 0x7f4a9e63a5c8>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-eace65db0800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mthing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menqueue_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch %s Enqueue Duration: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "QUEUE_LIMIT = 500000\n",
    "\n",
    "# Try me out\n",
    "#batch_size = 256\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    queue = tf.RandomShuffleQueue(\n",
    "        capacity=QUEUE_LIMIT, min_after_dequeue=batch_size,\n",
    "        dtypes=[tf.float32, tf.float32],\n",
    "        shapes = [(n_words,), (1,)],\n",
    "        seed=1999)\n",
    "\n",
    "    with tf.name_scope(\"preprocess_data\"):\n",
    "        with tf.device('/cpu:0'):\n",
    "\n",
    "            # Initialize data placeholders\n",
    "            x_data = tf.placeholder(shape=[batch_size, max_document_length], dtype=tf.int32)\n",
    "            y_target = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name=\"labels\")\n",
    "            #with tf.device('/cpu:0'):\n",
    "            identity_mat = tf.diag(tf.ones(shape=[vocab_size]))\n",
    "            # This is also an embedding_lookup_sparse function that would create a sparse tensor.\n",
    "            x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "            # Collapse across the document length dimension. Leaving only the number of tokens.\n",
    "            example = tf.reduce_sum(x_embed, 1)\n",
    "\n",
    "            enqueue_op = queue.enqueue_many((example, y_target))\n",
    "\n",
    "        # Dequeue our data. Use dequeue_many(batch_size) later.\n",
    "        dequeue_op = queue.dequeue_many(batch_size)\n",
    "\n",
    "# Create 8 threads.\n",
    "#qr = tf.train.QueueRunner(queue, [enqueue_op] * 8)\n",
    "# Launch the graph.\n",
    "with tf.Session(graph=graph) as session:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "\n",
    "#sess = tf.Session()\n",
    "    #enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in range(10): # do to 100 iterations\n",
    "        #if coord.should_stop():\n",
    "        #    break\n",
    "        #print(feed_dict)\n",
    "        start_time = time.time()\n",
    "        feed_dict = input_fn()\n",
    "        #print(feed_dict)\n",
    "        thing = session.run([enqueue_op], feed_dict=next(feed_dict))\n",
    "        duration = time.time() - start_time\n",
    "        print(\"Batch %s Enqueue Duration: %.4f\" % (step +1, duration))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"data/Placeholder\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1368\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"data/labels\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"bag_of_words/ones\"\n",
      "  op: \"Const\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 8712\n",
      "          }\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"bag_of_words/Diag\"\n",
      "  op: \"Diag\"\n",
      "  input: \"bag_of_words/ones\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"bag_of_words/embedding_lookup\"\n",
      "  op: \"Gather\"\n",
      "  input: \"bag_of_words/Diag\"\n",
      "  input: \"data/Placeholder\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"Tindices\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tparams\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@bag_of_words/Diag\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_indices\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"bag_of_words/Sum/reduction_indices\"\n",
      "  op: \"Const\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"bag_of_words/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"bag_of_words/embedding_lookup\"\n",
      "  input: \"bag_of_words/Sum/reduction_indices\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"zeros\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 8712\n",
      "          }\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 8712\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"Variable\"\n",
      "  input: \"zeros\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"Variable\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"zeros_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable_1\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable_1/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"Variable_1\"\n",
      "  input: \"zeros_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable_1/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"Variable_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"bag_of_words/Sum\"\n",
      "  input: \"Variable/read\"\n",
      "  device: \"/device:GPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"predictions\"\n",
      "  op: \"Add\"\n",
      "  input: \"MatMul\"\n",
      "  input: \"Variable_1/read\"\n",
      "  device: \"/device:GPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Sub\"\n",
      "  op: \"Sub\"\n",
      "  input: \"data/labels\"\n",
      "  input: \"predictions\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Pow/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 2.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Pow\"\n",
      "  op: \"Pow\"\n",
      "  input: \"loss/Sub\"\n",
      "  input: \"loss/Pow/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Mean\"\n",
      "  op: \"Mean\"\n",
      "  input: \"loss/Pow\"\n",
      "  input: \"loss/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Sqrt\"\n",
      "  op: \"Sqrt\"\n",
      "  input: \"loss/Mean\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty/Const_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty\"\n",
      "  op: \"AddN\"\n",
      "  input: \"loss/get_regularization_penalty/Const\"\n",
      "  input: \"loss/get_regularization_penalty/Const_1\"\n",
      "  attr {\n",
      "    key: \"N\"\n",
      "    value {\n",
      "      i: 2\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1/l2_regularizer/scale\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0010000000474974513\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1/l2_regularizer/L2Loss\"\n",
      "  op: \"L2Loss\"\n",
      "  input: \"Variable/read\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1/l2_regularizer\"\n",
      "  op: \"Mul\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer/scale\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer/L2Loss\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1/l2_regularizer_1/scale\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0010000000474974513\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss\"\n",
      "  op: \"L2Loss\"\n",
      "  input: \"Variable_1/read\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1/l2_regularizer_1\"\n",
      "  op: \"Mul\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer_1/scale\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/get_regularization_penalty_1\"\n",
      "  op: \"AddN\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer_1\"\n",
      "  attr {\n",
      "    key: \"N\"\n",
      "    value {\n",
      "      i: 2\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/Add\"\n",
      "  op: \"Add\"\n",
      "  input: \"loss/get_regularization_penalty\"\n",
      "  input: \"loss/get_regularization_penalty_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"loss/add\"\n",
      "  op: \"Add\"\n",
      "  input: \"loss/Sqrt\"\n",
      "  input: \"loss/Add\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/Sub\"\n",
      "  op: \"Sub\"\n",
      "  input: \"data/labels\"\n",
      "  input: \"predictions\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/Mul/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 17698.341796875\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/Mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"reporting/Sub\"\n",
      "  input: \"reporting/Mul/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/Abs\"\n",
      "  op: \"Abs\"\n",
      "  input: \"reporting/Mul\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/Mean\"\n",
      "  op: \"Mean\"\n",
      "  input: \"reporting/Abs\"\n",
      "  input: \"reporting/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/train_loss/tags\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_STRING\n",
      "        tensor_shape {\n",
      "        }\n",
      "        string_val: \"reporting/train_loss\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/train_loss\"\n",
      "  op: \"ScalarSummary\"\n",
      "  input: \"reporting/train_loss/tags\"\n",
      "  input: \"loss/add\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/validation_loss/tags\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_STRING\n",
      "        tensor_shape {\n",
      "        }\n",
      "        string_val: \"reporting/validation_loss\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/validation_loss\"\n",
      "  op: \"ScalarSummary\"\n",
      "  input: \"reporting/validation_loss/tags\"\n",
      "  input: \"loss/add\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/train_mae/tags\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_STRING\n",
      "        tensor_shape {\n",
      "        }\n",
      "        string_val: \"reporting/train_mae\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/train_mae\"\n",
      "  op: \"ScalarSummary\"\n",
      "  input: \"reporting/train_mae/tags\"\n",
      "  input: \"reporting/Mean\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/validation_mae/tags\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_STRING\n",
      "        tensor_shape {\n",
      "        }\n",
      "        string_val: \"reporting/validation_mae\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"reporting/validation_mae\"\n",
      "  op: \"ScalarSummary\"\n",
      "  input: \"reporting/validation_mae/tags\"\n",
      "  input: \"reporting/Mean\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"global_step/initial_value\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"global_step\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"global_step/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"global_step\"\n",
      "  input: \"global_step/initial_value\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@global_step\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"global_step/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"global_step\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@global_step\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/learning_rate/Initializer/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/learning_rate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.009999999776482582\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/learning_rate\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/learning_rate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/learning_rate/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/learning_rate\"\n",
      "  input: \"OptimizeLoss/learning_rate/Initializer/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/learning_rate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/learning_rate/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/learning_rate\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/learning_rate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/Fill\"\n",
      "  op: \"Fill\"\n",
      "  input: \"OptimizeLoss/gradients/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/Fill\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/Fill\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Sum_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/add_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/add_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/add_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/add_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/add_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/add_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sqrt_grad/SqrtGrad\"\n",
      "  op: \"SqrtGrad\"\n",
      "  input: \"loss/Sqrt\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Sum_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Add_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Add_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Add_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Add_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Add_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Add_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Add_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Reshape/shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\001\\000\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sqrt_grad/SqrtGrad\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Reshape/shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Tile/multiples\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\001\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Tile\"\n",
      "  op: \"Tile\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Tile/multiples\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tmultiples\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\001\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Prod\"\n",
      "  op: \"Prod\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Const_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Prod_1\"\n",
      "  op: \"Prod\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Shape_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Const_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Maximum/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Maximum\"\n",
      "  op: \"Maximum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Prod_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Maximum/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/floordiv\"\n",
      "  op: \"FloorDiv\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Prod\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Maximum\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/Cast\"\n",
      "  op: \"Cast\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/floordiv\"\n",
      "  attr {\n",
      "    key: \"DstT\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"SrcT\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Mean_grad/truediv\"\n",
      "  op: \"RealDiv\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Tile\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/Cast\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Add_grad/tuple/control_dependency_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/tuple/control_dependency_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Add_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Add_grad/tuple/control_dependency_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Add_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\001\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/truediv\"\n",
      "  input: \"loss/Pow/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/sub/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/sub\"\n",
      "  op: \"Sub\"\n",
      "  input: \"loss/Pow/y\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/sub/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Pow\"\n",
      "  op: \"Pow\"\n",
      "  input: \"loss/Sub\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/sub\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/mul_1\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Pow\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/mul_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"loss/Sub\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Log\"\n",
      "  op: \"Log\"\n",
      "  input: \"loss/Sub\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/zeros_like\"\n",
      "  op: \"ZerosLike\"\n",
      "  input: \"loss/Sub\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Select\"\n",
      "  op: \"Select\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Greater\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Log\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/zeros_like\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/mul_2\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Mean_grad/truediv\"\n",
      "  input: \"loss/Pow\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/mul_3\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/mul_2\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Select\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/mul_3\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Sum_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Pow_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Pow_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Pow_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Pow_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Pow_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Pow_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Pow_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/control_dependency\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer/L2Loss\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/mul_1\"\n",
      "  op: \"Mul\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer/scale\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/control_dependency\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/mul_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Sum_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/control_dependency_1\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/mul\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/mul_1\"\n",
      "  op: \"Mul\"\n",
      "  input: \"loss/get_regularization_penalty_1/l2_regularizer_1/scale\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1_grad/tuple/control_dependency_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/mul_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Sum_1\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\001\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\001\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/tuple/control_dependency\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Pow_grad/tuple/control_dependency\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Neg\"\n",
      "  op: \"Neg\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Sum_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Neg\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Sub_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Sub_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Sub_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Sub_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/Sub_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/loss/Sub_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/Sub_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer/L2Loss_grad/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"Variable/read\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_grad/tuple/control_dependency_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss_grad/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"Variable_1/read\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1_grad/tuple/control_dependency_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/Shape\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\001\\000\\000\\001\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/Shape_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        int_val: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/BroadcastGradientArgs\"\n",
      "  op: \"BroadcastGradientArgs\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Shape\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/tuple/control_dependency_1\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/BroadcastGradientArgs\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/Reshape\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Shape\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/Sum_1\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/gradients/loss/Sub_grad/tuple/control_dependency_1\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/BroadcastGradientArgs:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/Reshape_1\"\n",
      "  op: \"Reshape\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Sum_1\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Shape_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tshape\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/predictions_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/predictions_grad/Reshape_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Reshape\"\n",
      "  input: \"^OptimizeLoss/gradients/predictions_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/predictions_grad/Reshape\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/predictions_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/Reshape_1\"\n",
      "  input: \"^OptimizeLoss/gradients/predictions_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/predictions_grad/Reshape_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/MatMul_grad/MatMul\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/tuple/control_dependency\"\n",
      "  input: \"Variable/read\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/MatMul_grad/MatMul_1\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"bag_of_words/Sum\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/tuple/control_dependency\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/MatMul_grad/tuple/group_deps\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/gradients/MatMul_grad/MatMul\"\n",
      "  input: \"^OptimizeLoss/gradients/MatMul_grad/MatMul_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/MatMul_grad/tuple/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/MatMul_grad/MatMul\"\n",
      "  input: \"^OptimizeLoss/gradients/MatMul_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/MatMul_grad/MatMul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/MatMul_grad/tuple/control_dependency_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/gradients/MatMul_grad/MatMul_1\"\n",
      "  input: \"^OptimizeLoss/gradients/MatMul_grad/tuple/group_deps\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/MatMul_grad/MatMul_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/AddN\"\n",
      "  op: \"AddN\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss_grad/mul\"\n",
      "  input: \"OptimizeLoss/gradients/predictions_grad/tuple/control_dependency_1\"\n",
      "  attr {\n",
      "    key: \"N\"\n",
      "    value {\n",
      "      i: 2\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/gradients/AddN_1\"\n",
      "  op: \"AddN\"\n",
      "  input: \"OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer/L2Loss_grad/mul\"\n",
      "  input: \"OptimizeLoss/gradients/MatMul_grad/tuple/control_dependency_1\"\n",
      "  attr {\n",
      "    key: \"N\"\n",
      "    value {\n",
      "      i: 2\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/L2Loss\"\n",
      "  op: \"L2Loss\"\n",
      "  input: \"OptimizeLoss/gradients/AddN_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/L2Loss_1\"\n",
      "  op: \"L2Loss\"\n",
      "  input: \"OptimizeLoss/gradients/AddN\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/stack\"\n",
      "  op: \"Pack\"\n",
      "  input: \"OptimizeLoss/global_norm/L2Loss\"\n",
      "  input: \"OptimizeLoss/global_norm/L2Loss_1\"\n",
      "  attr {\n",
      "    key: \"N\"\n",
      "    value {\n",
      "      i: 2\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"axis\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"OptimizeLoss/global_norm/stack\"\n",
      "  input: \"OptimizeLoss/global_norm/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/Const_1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 2.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/global_norm/Sum\"\n",
      "  input: \"OptimizeLoss/global_norm/Const_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/global_norm/global_norm\"\n",
      "  op: \"Sqrt\"\n",
      "  input: \"OptimizeLoss/global_norm/mul\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/truediv/x\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/truediv\"\n",
      "  op: \"RealDiv\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/truediv/x\"\n",
      "  input: \"OptimizeLoss/global_norm/global_norm\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/truediv_1/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/truediv_1\"\n",
      "  op: \"RealDiv\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/Const\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/truediv_1/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/Minimum\"\n",
      "  op: \"Minimum\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/truediv\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/truediv_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/mul/x\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/mul/x\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/Minimum\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/mul_1\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/AddN_1\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/mul\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/mul_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/mul_2\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/gradients/AddN\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/mul\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/mul_2\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@OptimizeLoss/gradients/loss/get_regularization_penalty_1/l2_regularizer_1/L2Loss_grad/mul\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/loss/tags\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_STRING\n",
      "        tensor_shape {\n",
      "        }\n",
      "        string_val: \"OptimizeLoss/loss\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/loss\"\n",
      "  op: \"ScalarSummary\"\n",
      "  input: \"OptimizeLoss/loss/tags\"\n",
      "  input: \"loss/add\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta1_power/initial_value\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.8999999761581421\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta1_power\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta1_power/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/beta1_power\"\n",
      "  input: \"OptimizeLoss/beta1_power/initial_value\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta1_power/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/beta1_power\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta2_power/initial_value\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.9990000128746033\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta2_power\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta2_power/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/beta2_power\"\n",
      "  input: \"OptimizeLoss/beta2_power/initial_value\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/beta2_power/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/beta2_power\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam/Initializer/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 8712\n",
      "          }\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 8712\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/Variable/Adam\"\n",
      "  input: \"OptimizeLoss/Variable/Adam/Initializer/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/Variable/Adam\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam_1/Initializer/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 8712\n",
      "          }\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam_1\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 8712\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam_1/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/Variable/Adam_1\"\n",
      "  input: \"OptimizeLoss/Variable/Adam_1/Initializer/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable/Adam_1/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/Variable/Adam_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam/Initializer/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam/Initializer/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam_1/Initializer/Const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam_1\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam_1/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam_1\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam_1/Initializer/Const\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/Variable_1/Adam_1/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/beta1\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.8999999761581421\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/beta2\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.9990000128746033\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/epsilon\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 9.99999993922529e-09\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/update_Variable/ApplyAdam\"\n",
      "  op: \"ApplyAdam\"\n",
      "  input: \"Variable\"\n",
      "  input: \"OptimizeLoss/Variable/Adam\"\n",
      "  input: \"OptimizeLoss/Variable/Adam_1\"\n",
      "  input: \"OptimizeLoss/beta1_power/read\"\n",
      "  input: \"OptimizeLoss/beta2_power/read\"\n",
      "  input: \"OptimizeLoss/learning_rate/read\"\n",
      "  input: \"OptimizeLoss/train/beta1\"\n",
      "  input: \"OptimizeLoss/train/beta2\"\n",
      "  input: \"OptimizeLoss/train/epsilon\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/update_Variable_1/ApplyAdam\"\n",
      "  op: \"ApplyAdam\"\n",
      "  input: \"Variable_1\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam\"\n",
      "  input: \"OptimizeLoss/Variable_1/Adam_1\"\n",
      "  input: \"OptimizeLoss/beta1_power/read\"\n",
      "  input: \"OptimizeLoss/beta2_power/read\"\n",
      "  input: \"OptimizeLoss/learning_rate/read\"\n",
      "  input: \"OptimizeLoss/train/beta1\"\n",
      "  input: \"OptimizeLoss/train/beta2\"\n",
      "  input: \"OptimizeLoss/train/epsilon\"\n",
      "  input: \"OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable_1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/beta1_power/read\"\n",
      "  input: \"OptimizeLoss/train/beta1\"\n",
      "  input: \"^OptimizeLoss/train/update_Variable/ApplyAdam\"\n",
      "  input: \"^OptimizeLoss/train/update_Variable_1/ApplyAdam\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/beta1_power\"\n",
      "  input: \"OptimizeLoss/train/mul\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/mul_1\"\n",
      "  op: \"Mul\"\n",
      "  input: \"OptimizeLoss/beta2_power/read\"\n",
      "  input: \"OptimizeLoss/train/beta2\"\n",
      "  input: \"^OptimizeLoss/train/update_Variable/ApplyAdam\"\n",
      "  input: \"^OptimizeLoss/train/update_Variable_1/ApplyAdam\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/Assign_1\"\n",
      "  op: \"Assign\"\n",
      "  input: \"OptimizeLoss/beta2_power\"\n",
      "  input: \"OptimizeLoss/train/mul_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/update\"\n",
      "  op: \"NoOp\"\n",
      "  input: \"^OptimizeLoss/train/update_Variable/ApplyAdam\"\n",
      "  input: \"^OptimizeLoss/train/update_Variable_1/ApplyAdam\"\n",
      "  input: \"^OptimizeLoss/train/Assign\"\n",
      "  input: \"^OptimizeLoss/train/Assign_1\"\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train/value\"\n",
      "  op: \"Const\"\n",
      "  input: \"^OptimizeLoss/train/update\"\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@global_step\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/train\"\n",
      "  op: \"AssignAdd\"\n",
      "  input: \"global_step\"\n",
      "  input: \"OptimizeLoss/train/value\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@global_step\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"OptimizeLoss/control_dependency\"\n",
      "  op: \"Identity\"\n",
      "  input: \"loss/add\"\n",
      "  input: \"^OptimizeLoss/train\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@loss/add\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_shuffle_queue\"\n",
      "  op: \"RandomShuffleQueueV2\"\n",
      "  attr {\n",
      "    key: \"capacity\"\n",
      "    value {\n",
      "      i: 500000\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"component_types\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_FLOAT\n",
      "        type: DT_FLOAT\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"min_after_dequeue\"\n",
      "    value {\n",
      "      i: 256\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed\"\n",
      "    value {\n",
      "      i: 87654321\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed2\"\n",
      "    value {\n",
      "      i: 1999\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 256\n",
      "          }\n",
      "          dim {\n",
      "            size: 8712\n",
      "          }\n",
      "        }\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 256\n",
      "          }\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/Placeholder\"\n",
      "  op: \"Placeholder\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1368\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/labels\"\n",
      "  op: \"Placeholder\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/ones\"\n",
      "  op: \"Const\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 8712\n",
      "          }\n",
      "        }\n",
      "        float_val: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/Diag\"\n",
      "  op: \"Diag\"\n",
      "  input: \"preprocess_data/ones\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/embedding_lookup\"\n",
      "  op: \"Gather\"\n",
      "  input: \"preprocess_data/Diag\"\n",
      "  input: \"preprocess_data/Placeholder\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"Tindices\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tparams\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@preprocess_data/Diag\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_indices\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/Sum/reduction_indices\"\n",
      "  op: \"Const\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/Sum\"\n",
      "  op: \"Sum\"\n",
      "  input: \"preprocess_data/embedding_lookup\"\n",
      "  input: \"preprocess_data/Sum/reduction_indices\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tidx\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"keep_dims\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/random_shuffle_queue_enqueue\"\n",
      "  op: \"QueueEnqueueV2\"\n",
      "  input: \"random_shuffle_queue\"\n",
      "  input: \"preprocess_data/Sum\"\n",
      "  input: \"preprocess_data/labels\"\n",
      "  device: \"/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"Tcomponents\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_FLOAT\n",
      "        type: DT_FLOAT\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"timeout_ms\"\n",
      "    value {\n",
      "      i: -1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"preprocess_data/random_shuffle_queue_Dequeue\"\n",
      "  op: \"QueueDequeueV2\"\n",
      "  input: \"random_shuffle_queue\"\n",
      "  attr {\n",
      "    key: \"component_types\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_FLOAT\n",
      "        type: DT_FLOAT\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"timeout_ms\"\n",
      "    value {\n",
      "      i: -1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_shuffle_queue_Size\"\n",
      "  op: \"QueueSizeV2\"\n",
      "  input: \"random_shuffle_queue\"\n",
      "}\n",
      "versions {\n",
      "  producer: 21\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    print(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    #enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in range(10): # do to 100 iterations\n",
    "        #if coord.should_stop():\n",
    "        #    break\n",
    "        #print(feed_dict)\n",
    "        data, label = session.run([dequeue_op])\n",
    "        print(data)\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "Tensor(\"data/Placeholder:0\", shape=(1024, 8762), dtype=float32)\n",
      "Tensor(\"data/labels:0\", shape=(1024, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tf_utils\n",
    "tf_utils = imp.reload(tf_utils)\n",
    "\n",
    "print(type(x_train))\n",
    "for a, b in input_fn():\n",
    "    print(a)\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore from model!\n",
      "INFO:tensorflow:Restoring parameters from logs/bagofwords/2017-06-27-20-43-59-32819\n",
      "Epoch: 0 Iteration: 5 : Loss: 0.9814 (0.021 sec)\n",
      "Epoch: 0 Iteration: 10 : Loss: 1.0438 (0.018 sec)\n",
      "Epoch: 0 Iteration: 15 : Loss: 0.9693 (0.020 sec)\n",
      "Epoch: 0 Iteration: 20 : Loss: 1.0008 (0.018 sec)\n",
      "Epoch: 0 Iteration: 25 : Loss: 1.0250 (0.018 sec)\n",
      "Epoch: 0 Iteration: 30 : Loss: 1.0122 (0.018 sec)\n",
      "Epoch: 0 Iteration: 35 : Loss: 0.9932 (0.018 sec)\n",
      "Epoch: 0 Iteration: 40 : Loss: 1.0112 (0.018 sec)\n",
      "Epoch: 0 Iteration: 45 : Loss: 0.9558 (0.018 sec)\n",
      "Epoch: 0 Iteration: 50 : Loss: 0.9573 (0.018 sec)\n",
      "Epoch: 0 Iteration: 55 : Loss: 0.9766 (0.018 sec)\n",
      "Epoch: 0 Iteration: 60 : Loss: 1.0086 (0.017 sec)\n",
      "Epoch: 0 Iteration: 65 : Loss: 1.0192 (0.018 sec)\n",
      "Epoch: 0 Iteration: 70 : Loss: 0.9899 (0.018 sec)\n",
      "Epoch: 0 Iteration: 75 : Loss: 0.9895 (0.018 sec)\n",
      "Epoch: 0 Iteration: 80 : Loss: 0.9920 (0.017 sec)\n",
      "Epoch: 0 Iteration: 85 : Loss: 0.9983 (0.018 sec)\n",
      "Epoch: 0 Iteration: 90 : Loss: 1.0129 (0.018 sec)\n",
      "Epoch: 0 Iteration: 95 : Loss: 0.9317 (0.018 sec)\n",
      "Epoch: 0 Iteration: 100 : Loss: 0.9644 (0.018 sec)\n",
      "Epoch: 0 Iteration: 105 : Loss: 1.0445 (0.018 sec)\n",
      "Epoch: 0 Iteration: 110 : Loss: 0.9690 (0.018 sec)\n",
      "Epoch: 0 Iteration: 115 : Loss: 0.9832 (0.018 sec)\n",
      "Saving at epoch 0 step: 118\n",
      "Epoch: 1 Iteration: 2 : Loss: 1.0988 (0.017 sec)\n",
      "Epoch: 1 Iteration: 7 : Loss: 0.9772 (0.018 sec)\n",
      "Epoch: 1 Iteration: 12 : Loss: 0.9752 (0.017 sec)\n",
      "Epoch: 1 Iteration: 17 : Loss: 1.0273 (0.018 sec)\n",
      "Epoch: 1 Iteration: 22 : Loss: 0.9514 (0.018 sec)\n",
      "Epoch: 1 Iteration: 27 : Loss: 0.9292 (0.020 sec)\n",
      "Epoch: 1 Iteration: 32 : Loss: 1.0032 (0.018 sec)\n",
      "Epoch: 1 Iteration: 37 : Loss: 1.0131 (0.018 sec)\n",
      "Epoch: 1 Iteration: 42 : Loss: 1.0015 (0.018 sec)\n",
      "Epoch: 1 Iteration: 47 : Loss: 0.9786 (0.019 sec)\n",
      "Epoch: 1 Iteration: 52 : Loss: 0.9695 (0.022 sec)\n",
      "Epoch: 1 Iteration: 57 : Loss: 0.9612 (0.019 sec)\n",
      "Epoch: 1 Iteration: 62 : Loss: 0.9962 (0.019 sec)\n",
      "Epoch: 1 Iteration: 67 : Loss: 1.0121 (0.018 sec)\n",
      "Epoch: 1 Iteration: 72 : Loss: 1.0053 (0.021 sec)\n",
      "Epoch: 1 Iteration: 77 : Loss: 0.9319 (0.022 sec)\n",
      "Epoch: 1 Iteration: 82 : Loss: 0.9949 (0.020 sec)\n",
      "Epoch: 1 Iteration: 87 : Loss: 1.0360 (0.018 sec)\n",
      "Epoch: 1 Iteration: 92 : Loss: 1.0003 (0.018 sec)\n",
      "Epoch: 1 Iteration: 97 : Loss: 1.0222 (0.018 sec)\n",
      "Epoch: 1 Iteration: 102 : Loss: 1.0282 (0.018 sec)\n",
      "Epoch: 1 Iteration: 107 : Loss: 0.9928 (0.018 sec)\n",
      "Epoch: 1 Iteration: 112 : Loss: 1.0166 (0.018 sec)\n",
      "Epoch: 1 Iteration: 117 : Loss: 1.0500 (0.022 sec)\n",
      "Epoch: 2 Iteration: 4 : Loss: 0.9605 (0.021 sec)\n",
      "Epoch: 2 Iteration: 9 : Loss: 0.9914 (0.018 sec)\n",
      "Epoch: 2 Iteration: 14 : Loss: 0.9610 (0.020 sec)\n",
      "Epoch: 2 Iteration: 19 : Loss: 0.9846 (0.019 sec)\n",
      "Epoch: 2 Iteration: 24 : Loss: 1.0062 (0.017 sec)\n",
      "Epoch: 2 Iteration: 29 : Loss: 1.0625 (0.022 sec)\n",
      "Epoch: 2 Iteration: 34 : Loss: 1.0157 (0.019 sec)\n",
      "Epoch: 2 Iteration: 39 : Loss: 1.0321 (0.018 sec)\n",
      "Epoch: 2 Iteration: 44 : Loss: 0.9903 (0.021 sec)\n",
      "Epoch: 2 Iteration: 49 : Loss: 0.9687 (0.020 sec)\n",
      "Epoch: 2 Iteration: 54 : Loss: 0.9915 (0.020 sec)\n",
      "Epoch: 2 Iteration: 59 : Loss: 0.9869 (0.021 sec)\n",
      "Epoch: 2 Iteration: 64 : Loss: 1.0129 (0.023 sec)\n",
      "Epoch: 2 Iteration: 69 : Loss: 0.9168 (0.021 sec)\n",
      "Epoch: 2 Iteration: 74 : Loss: 1.0347 (0.021 sec)\n",
      "Epoch: 2 Iteration: 79 : Loss: 1.0213 (0.018 sec)\n",
      "Epoch: 2 Iteration: 84 : Loss: 1.0302 (0.020 sec)\n",
      "Epoch: 2 Iteration: 89 : Loss: 1.0063 (0.018 sec)\n",
      "Epoch: 2 Iteration: 94 : Loss: 0.9457 (0.019 sec)\n",
      "Epoch: 2 Iteration: 99 : Loss: 0.9798 (0.019 sec)\n",
      "Epoch: 2 Iteration: 104 : Loss: 0.9955 (0.024 sec)\n",
      "Epoch: 2 Iteration: 109 : Loss: 0.9260 (0.021 sec)\n",
      "Epoch: 2 Iteration: 114 : Loss: 0.9442 (0.018 sec)\n",
      "Epoch: 3 Iteration: 1 : Loss: 0.9551 (0.017 sec)\n",
      "Epoch: 3 Iteration: 6 : Loss: 0.9453 (0.021 sec)\n",
      "Epoch: 3 Iteration: 11 : Loss: 1.0080 (0.018 sec)\n",
      "Epoch: 3 Iteration: 16 : Loss: 0.9588 (0.018 sec)\n",
      "Epoch: 3 Iteration: 21 : Loss: 0.9891 (0.018 sec)\n",
      "Epoch: 3 Iteration: 26 : Loss: 0.9592 (0.018 sec)\n",
      "Epoch: 3 Iteration: 31 : Loss: 0.9804 (0.018 sec)\n",
      "Epoch: 3 Iteration: 36 : Loss: 0.9825 (0.019 sec)\n",
      "Epoch: 3 Iteration: 41 : Loss: 0.9962 (0.021 sec)\n",
      "Epoch: 3 Iteration: 46 : Loss: 0.9638 (0.018 sec)\n",
      "Epoch: 3 Iteration: 51 : Loss: 0.9521 (0.018 sec)\n",
      "Epoch: 3 Iteration: 56 : Loss: 1.0595 (0.020 sec)\n",
      "Epoch: 3 Iteration: 61 : Loss: 0.9904 (0.018 sec)\n",
      "Epoch: 3 Iteration: 66 : Loss: 1.0366 (0.020 sec)\n",
      "Epoch: 3 Iteration: 71 : Loss: 0.9541 (0.022 sec)\n",
      "Epoch: 3 Iteration: 76 : Loss: 1.0048 (0.024 sec)\n",
      "Epoch: 3 Iteration: 81 : Loss: 0.9843 (0.018 sec)\n",
      "Epoch: 3 Iteration: 86 : Loss: 1.0401 (0.018 sec)\n",
      "Epoch: 3 Iteration: 91 : Loss: 0.9792 (0.018 sec)\n",
      "Epoch: 3 Iteration: 96 : Loss: 0.9695 (0.021 sec)\n",
      "Epoch: 3 Iteration: 101 : Loss: 0.9787 (0.018 sec)\n",
      "Epoch: 3 Iteration: 106 : Loss: 1.0371 (0.023 sec)\n",
      "Epoch: 3 Iteration: 111 : Loss: 0.9946 (0.018 sec)\n",
      "Epoch: 3 Iteration: 116 : Loss: 0.9629 (0.017 sec)\n",
      "Epoch: 4 Iteration: 3 : Loss: 0.9391 (0.030 sec)\n",
      "Epoch: 4 Iteration: 8 : Loss: 0.9706 (0.018 sec)\n",
      "Epoch: 4 Iteration: 13 : Loss: 0.9974 (0.019 sec)\n",
      "Epoch: 4 Iteration: 18 : Loss: 1.0378 (0.018 sec)\n",
      "Epoch: 4 Iteration: 23 : Loss: 1.0286 (0.018 sec)\n",
      "Epoch: 4 Iteration: 28 : Loss: 1.0086 (0.017 sec)\n",
      "Saving at epoch 4 step: 28\n",
      "Epoch: 4 Iteration: 33 : Loss: 0.9892 (0.018 sec)\n",
      "Epoch: 4 Iteration: 38 : Loss: 0.9599 (0.018 sec)\n",
      "Epoch: 4 Iteration: 43 : Loss: 0.9790 (0.018 sec)\n",
      "Epoch: 4 Iteration: 48 : Loss: 1.0207 (0.018 sec)\n",
      "Epoch: 4 Iteration: 53 : Loss: 1.0165 (0.018 sec)\n",
      "Epoch: 4 Iteration: 58 : Loss: 0.9813 (0.018 sec)\n",
      "Epoch: 4 Iteration: 63 : Loss: 0.9420 (0.018 sec)\n",
      "Epoch: 4 Iteration: 68 : Loss: 0.9508 (0.018 sec)\n",
      "Epoch: 4 Iteration: 73 : Loss: 0.9748 (0.018 sec)\n",
      "Epoch: 4 Iteration: 78 : Loss: 0.9681 (0.020 sec)\n",
      "Epoch: 4 Iteration: 83 : Loss: 1.0091 (0.021 sec)\n",
      "Epoch: 4 Iteration: 88 : Loss: 1.0256 (0.020 sec)\n",
      "Epoch: 4 Iteration: 93 : Loss: 0.9402 (0.022 sec)\n",
      "Epoch: 4 Iteration: 98 : Loss: 1.0103 (0.019 sec)\n",
      "Epoch: 4 Iteration: 103 : Loss: 0.9881 (0.024 sec)\n",
      "Epoch: 4 Iteration: 108 : Loss: 0.9917 (0.024 sec)\n",
      "Epoch: 4 Iteration: 113 : Loss: 0.9941 (0.023 sec)\n",
      "Epoch: 4 Iteration: 118 : Loss: 1.0303 (0.022 sec)\n",
      "Epoch: 5 Iteration: 5 : Loss: 1.0170 (0.018 sec)\n",
      "Epoch: 5 Iteration: 10 : Loss: 1.0510 (0.019 sec)\n",
      "Epoch: 5 Iteration: 15 : Loss: 1.0070 (0.018 sec)\n",
      "Epoch: 5 Iteration: 20 : Loss: 1.0111 (0.019 sec)\n",
      "Epoch: 5 Iteration: 25 : Loss: 0.9226 (0.022 sec)\n",
      "Epoch: 5 Iteration: 30 : Loss: 1.0132 (0.020 sec)\n",
      "Epoch: 5 Iteration: 35 : Loss: 0.9707 (0.018 sec)\n",
      "Epoch: 5 Iteration: 40 : Loss: 1.0119 (0.018 sec)\n",
      "Epoch: 5 Iteration: 45 : Loss: 1.0189 (0.018 sec)\n",
      "Epoch: 5 Iteration: 50 : Loss: 1.0245 (0.020 sec)\n",
      "Epoch: 5 Iteration: 55 : Loss: 0.9551 (0.021 sec)\n",
      "Epoch: 5 Iteration: 60 : Loss: 0.9802 (0.022 sec)\n",
      "Epoch: 5 Iteration: 65 : Loss: 1.0620 (0.018 sec)\n",
      "Epoch: 5 Iteration: 70 : Loss: 1.0054 (0.019 sec)\n",
      "Epoch: 5 Iteration: 75 : Loss: 1.0347 (0.019 sec)\n",
      "Epoch: 5 Iteration: 80 : Loss: 0.9793 (0.020 sec)\n",
      "Epoch: 5 Iteration: 85 : Loss: 1.0342 (0.021 sec)\n",
      "Epoch: 5 Iteration: 90 : Loss: 0.9798 (0.024 sec)\n",
      "Epoch: 5 Iteration: 95 : Loss: 0.9404 (0.018 sec)\n",
      "Epoch: 5 Iteration: 100 : Loss: 0.9579 (0.018 sec)\n",
      "Epoch: 5 Iteration: 105 : Loss: 0.9883 (0.019 sec)\n",
      "Epoch: 5 Iteration: 110 : Loss: 0.9884 (0.019 sec)\n",
      "Epoch: 5 Iteration: 115 : Loss: 0.9183 (0.023 sec)\n",
      "Epoch: 6 Iteration: 2 : Loss: 0.9674 (0.018 sec)\n",
      "Epoch: 6 Iteration: 7 : Loss: 0.9421 (0.021 sec)\n",
      "Epoch: 6 Iteration: 12 : Loss: 0.9865 (0.023 sec)\n",
      "Epoch: 6 Iteration: 17 : Loss: 1.0021 (0.023 sec)\n",
      "Epoch: 6 Iteration: 22 : Loss: 1.0185 (0.023 sec)\n",
      "Epoch: 6 Iteration: 27 : Loss: 0.9850 (0.023 sec)\n",
      "Epoch: 6 Iteration: 32 : Loss: 1.0164 (0.021 sec)\n",
      "Epoch: 6 Iteration: 37 : Loss: 0.9639 (0.017 sec)\n",
      "Epoch: 6 Iteration: 42 : Loss: 0.9451 (0.020 sec)\n",
      "Epoch: 6 Iteration: 47 : Loss: 1.0076 (0.022 sec)\n",
      "Epoch: 6 Iteration: 52 : Loss: 0.9559 (0.018 sec)\n",
      "Epoch: 6 Iteration: 57 : Loss: 0.9364 (0.022 sec)\n",
      "Epoch: 6 Iteration: 62 : Loss: 0.9721 (0.021 sec)\n",
      "Epoch: 6 Iteration: 67 : Loss: 0.9987 (0.019 sec)\n",
      "Epoch: 6 Iteration: 72 : Loss: 0.9407 (0.018 sec)\n",
      "Epoch: 6 Iteration: 77 : Loss: 1.0150 (0.018 sec)\n",
      "Epoch: 6 Iteration: 82 : Loss: 0.9781 (0.024 sec)\n",
      "Epoch: 6 Iteration: 87 : Loss: 1.0044 (0.019 sec)\n",
      "Epoch: 6 Iteration: 92 : Loss: 1.0207 (0.024 sec)\n",
      "Epoch: 6 Iteration: 97 : Loss: 0.9909 (0.019 sec)\n",
      "Epoch: 6 Iteration: 102 : Loss: 0.9961 (0.018 sec)\n",
      "Epoch: 6 Iteration: 107 : Loss: 1.0355 (0.018 sec)\n",
      "Epoch: 6 Iteration: 112 : Loss: 0.9670 (0.018 sec)\n",
      "Epoch: 6 Iteration: 117 : Loss: 0.9018 (0.018 sec)\n",
      "Epoch: 7 Iteration: 4 : Loss: 1.0027 (0.018 sec)\n",
      "Epoch: 7 Iteration: 9 : Loss: 0.9714 (0.024 sec)\n",
      "Epoch: 7 Iteration: 14 : Loss: 0.9690 (0.019 sec)\n",
      "Epoch: 7 Iteration: 19 : Loss: 0.9058 (0.021 sec)\n",
      "Epoch: 7 Iteration: 24 : Loss: 1.0099 (0.022 sec)\n",
      "Epoch: 7 Iteration: 29 : Loss: 0.9000 (0.018 sec)\n",
      "Epoch: 7 Iteration: 34 : Loss: 0.9564 (0.020 sec)\n",
      "Epoch: 7 Iteration: 39 : Loss: 1.0022 (0.019 sec)\n",
      "Epoch: 7 Iteration: 44 : Loss: 0.9285 (0.021 sec)\n",
      "Epoch: 7 Iteration: 49 : Loss: 1.0014 (0.018 sec)\n",
      "Epoch: 7 Iteration: 54 : Loss: 1.0216 (0.022 sec)\n",
      "Epoch: 7 Iteration: 59 : Loss: 0.9835 (0.022 sec)\n",
      "Epoch: 7 Iteration: 64 : Loss: 1.0620 (0.022 sec)\n",
      "Epoch: 7 Iteration: 69 : Loss: 0.9649 (0.022 sec)\n",
      "Epoch: 7 Iteration: 74 : Loss: 0.9225 (0.019 sec)\n",
      "Epoch: 7 Iteration: 79 : Loss: 0.9620 (0.018 sec)\n",
      "Epoch: 7 Iteration: 84 : Loss: 0.9911 (0.022 sec)\n",
      "Epoch: 7 Iteration: 89 : Loss: 0.9666 (0.019 sec)\n",
      "Epoch: 7 Iteration: 94 : Loss: 0.9884 (0.022 sec)\n",
      "Epoch: 7 Iteration: 99 : Loss: 0.9798 (0.022 sec)\n",
      "Epoch: 7 Iteration: 104 : Loss: 0.9956 (0.018 sec)\n",
      "Epoch: 7 Iteration: 109 : Loss: 0.9747 (0.021 sec)\n",
      "Epoch: 7 Iteration: 114 : Loss: 0.9840 (0.020 sec)\n",
      "Epoch: 8 Iteration: 1 : Loss: 1.0057 (0.019 sec)\n",
      "Epoch: 8 Iteration: 6 : Loss: 0.9675 (0.020 sec)\n",
      "Epoch: 8 Iteration: 11 : Loss: 0.9766 (0.020 sec)\n",
      "Epoch: 8 Iteration: 16 : Loss: 0.9783 (0.022 sec)\n",
      "Epoch: 8 Iteration: 21 : Loss: 1.0889 (0.021 sec)\n",
      "Epoch: 8 Iteration: 26 : Loss: 0.9942 (0.019 sec)\n",
      "Epoch: 8 Iteration: 31 : Loss: 1.0062 (0.020 sec)\n",
      "Epoch: 8 Iteration: 36 : Loss: 0.9663 (0.019 sec)\n",
      "Epoch: 8 Iteration: 41 : Loss: 0.9564 (0.019 sec)\n",
      "Epoch: 8 Iteration: 46 : Loss: 0.9694 (0.018 sec)\n",
      "Epoch: 8 Iteration: 51 : Loss: 0.9728 (0.025 sec)\n",
      "Epoch: 8 Iteration: 56 : Loss: 0.9824 (0.020 sec)\n",
      "Saving at epoch 8 step: 56\n",
      "Epoch: 8 Iteration: 61 : Loss: 1.0288 (0.020 sec)\n",
      "Epoch: 8 Iteration: 66 : Loss: 0.9402 (0.018 sec)\n",
      "Epoch: 8 Iteration: 71 : Loss: 1.0138 (0.021 sec)\n",
      "Epoch: 8 Iteration: 76 : Loss: 0.9880 (0.021 sec)\n",
      "Epoch: 8 Iteration: 81 : Loss: 1.0012 (0.018 sec)\n",
      "Epoch: 8 Iteration: 86 : Loss: 0.9719 (0.022 sec)\n",
      "Epoch: 8 Iteration: 91 : Loss: 0.9385 (0.018 sec)\n",
      "Epoch: 8 Iteration: 96 : Loss: 0.9818 (0.018 sec)\n",
      "Epoch: 8 Iteration: 101 : Loss: 0.9891 (0.018 sec)\n",
      "Epoch: 8 Iteration: 106 : Loss: 0.9313 (0.020 sec)\n",
      "Epoch: 8 Iteration: 111 : Loss: 1.0307 (0.022 sec)\n",
      "Epoch: 8 Iteration: 116 : Loss: 0.9916 (0.018 sec)\n",
      "Epoch: 9 Iteration: 3 : Loss: 0.9223 (0.017 sec)\n",
      "Epoch: 9 Iteration: 8 : Loss: 0.9970 (0.019 sec)\n",
      "Epoch: 9 Iteration: 13 : Loss: 0.9611 (0.022 sec)\n",
      "Epoch: 9 Iteration: 18 : Loss: 0.9787 (0.026 sec)\n",
      "Epoch: 9 Iteration: 23 : Loss: 0.9611 (0.019 sec)\n",
      "Epoch: 9 Iteration: 28 : Loss: 1.0148 (0.018 sec)\n",
      "Epoch: 9 Iteration: 33 : Loss: 0.9920 (0.018 sec)\n",
      "Epoch: 9 Iteration: 38 : Loss: 1.0192 (0.020 sec)\n",
      "Epoch: 9 Iteration: 43 : Loss: 1.0019 (0.018 sec)\n",
      "Epoch: 9 Iteration: 48 : Loss: 1.0433 (0.018 sec)\n",
      "Epoch: 9 Iteration: 53 : Loss: 1.0375 (0.017 sec)\n",
      "Epoch: 9 Iteration: 58 : Loss: 0.9238 (0.018 sec)\n",
      "Epoch: 9 Iteration: 63 : Loss: 0.9878 (0.018 sec)\n",
      "Epoch: 9 Iteration: 68 : Loss: 0.9383 (0.018 sec)\n",
      "Epoch: 9 Iteration: 73 : Loss: 0.9750 (0.019 sec)\n",
      "Epoch: 9 Iteration: 78 : Loss: 0.9611 (0.018 sec)\n",
      "Epoch: 9 Iteration: 83 : Loss: 0.9591 (0.024 sec)\n",
      "Epoch: 9 Iteration: 88 : Loss: 1.0553 (0.018 sec)\n",
      "Epoch: 9 Iteration: 93 : Loss: 1.0305 (0.024 sec)\n",
      "Epoch: 9 Iteration: 98 : Loss: 0.9893 (0.019 sec)\n",
      "Epoch: 9 Iteration: 103 : Loss: 1.0058 (0.018 sec)\n",
      "Epoch: 9 Iteration: 108 : Loss: 0.9472 (0.021 sec)\n",
      "Epoch: 9 Iteration: 113 : Loss: 0.9710 (0.020 sec)\n",
      "Epoch: 9 Iteration: 118 : Loss: 1.0227 (0.022 sec)\n",
      "Epoch: 10 Iteration: 5 : Loss: 0.9564 (0.022 sec)\n",
      "Epoch: 10 Iteration: 10 : Loss: 0.9765 (0.021 sec)\n",
      "Epoch: 10 Iteration: 15 : Loss: 0.9594 (0.024 sec)\n",
      "Epoch: 10 Iteration: 20 : Loss: 0.9636 (0.020 sec)\n",
      "Epoch: 10 Iteration: 25 : Loss: 0.9750 (0.020 sec)\n",
      "Epoch: 10 Iteration: 30 : Loss: 0.9528 (0.019 sec)\n",
      "Epoch: 10 Iteration: 35 : Loss: 0.9863 (0.018 sec)\n",
      "Epoch: 10 Iteration: 40 : Loss: 1.0351 (0.018 sec)\n",
      "Epoch: 10 Iteration: 45 : Loss: 0.9638 (0.020 sec)\n",
      "Epoch: 10 Iteration: 50 : Loss: 0.9585 (0.018 sec)\n",
      "Epoch: 10 Iteration: 55 : Loss: 0.9884 (0.018 sec)\n",
      "Epoch: 10 Iteration: 60 : Loss: 1.0200 (0.024 sec)\n",
      "Epoch: 10 Iteration: 65 : Loss: 0.9512 (0.020 sec)\n",
      "Epoch: 10 Iteration: 70 : Loss: 0.9679 (0.018 sec)\n",
      "Epoch: 10 Iteration: 75 : Loss: 0.9893 (0.018 sec)\n",
      "Epoch: 10 Iteration: 80 : Loss: 0.9684 (0.018 sec)\n",
      "Epoch: 10 Iteration: 85 : Loss: 0.9486 (0.019 sec)\n",
      "Epoch: 10 Iteration: 90 : Loss: 0.9343 (0.018 sec)\n",
      "Epoch: 10 Iteration: 95 : Loss: 0.9305 (0.018 sec)\n",
      "Epoch: 10 Iteration: 100 : Loss: 0.9629 (0.019 sec)\n",
      "Epoch: 10 Iteration: 105 : Loss: 1.0152 (0.021 sec)\n",
      "Epoch: 10 Iteration: 110 : Loss: 0.9877 (0.018 sec)\n",
      "Epoch: 10 Iteration: 115 : Loss: 0.9696 (0.020 sec)\n",
      "Epoch: 11 Iteration: 2 : Loss: 1.0289 (0.025 sec)\n",
      "Epoch: 11 Iteration: 7 : Loss: 0.9359 (0.020 sec)\n",
      "Epoch: 11 Iteration: 12 : Loss: 0.9889 (0.018 sec)\n",
      "Epoch: 11 Iteration: 17 : Loss: 1.0472 (0.018 sec)\n",
      "Epoch: 11 Iteration: 22 : Loss: 1.0116 (0.024 sec)\n",
      "Epoch: 11 Iteration: 27 : Loss: 0.9501 (0.020 sec)\n",
      "Epoch: 11 Iteration: 32 : Loss: 1.0192 (0.022 sec)\n",
      "Epoch: 11 Iteration: 37 : Loss: 1.0378 (0.018 sec)\n",
      "Epoch: 11 Iteration: 42 : Loss: 0.9441 (0.024 sec)\n",
      "Epoch: 11 Iteration: 47 : Loss: 0.9760 (0.020 sec)\n",
      "Epoch: 11 Iteration: 52 : Loss: 0.9966 (0.018 sec)\n",
      "Epoch: 11 Iteration: 57 : Loss: 1.0450 (0.025 sec)\n",
      "Epoch: 11 Iteration: 62 : Loss: 0.9960 (0.019 sec)\n",
      "Epoch: 11 Iteration: 67 : Loss: 0.9620 (0.019 sec)\n",
      "Epoch: 11 Iteration: 72 : Loss: 0.9410 (0.020 sec)\n",
      "Epoch: 11 Iteration: 77 : Loss: 0.9577 (0.022 sec)\n",
      "Epoch: 11 Iteration: 82 : Loss: 0.9536 (0.018 sec)\n",
      "Epoch: 11 Iteration: 87 : Loss: 0.9305 (0.022 sec)\n",
      "Epoch: 11 Iteration: 92 : Loss: 0.9652 (0.021 sec)\n",
      "Epoch: 11 Iteration: 97 : Loss: 0.9538 (0.020 sec)\n",
      "Epoch: 11 Iteration: 102 : Loss: 0.9619 (0.020 sec)\n",
      "Epoch: 11 Iteration: 107 : Loss: 0.9826 (0.018 sec)\n",
      "Epoch: 11 Iteration: 112 : Loss: 0.9772 (0.018 sec)\n",
      "Epoch: 11 Iteration: 117 : Loss: 0.9341 (0.019 sec)\n",
      "Epoch: 12 Iteration: 4 : Loss: 0.9562 (0.020 sec)\n",
      "Epoch: 12 Iteration: 9 : Loss: 1.0331 (0.024 sec)\n",
      "Epoch: 12 Iteration: 14 : Loss: 1.0070 (0.018 sec)\n",
      "Epoch: 12 Iteration: 19 : Loss: 0.9797 (0.020 sec)\n",
      "Epoch: 12 Iteration: 24 : Loss: 1.0003 (0.019 sec)\n",
      "Epoch: 12 Iteration: 29 : Loss: 1.0112 (0.022 sec)\n",
      "Epoch: 12 Iteration: 34 : Loss: 0.9802 (0.020 sec)\n",
      "Epoch: 12 Iteration: 39 : Loss: 0.9866 (0.023 sec)\n",
      "Epoch: 12 Iteration: 44 : Loss: 1.0093 (0.022 sec)\n",
      "Epoch: 12 Iteration: 49 : Loss: 0.9738 (0.018 sec)\n",
      "Epoch: 12 Iteration: 54 : Loss: 0.9687 (0.019 sec)\n",
      "Epoch: 12 Iteration: 59 : Loss: 0.9731 (0.018 sec)\n",
      "Epoch: 12 Iteration: 64 : Loss: 0.9966 (0.018 sec)\n",
      "Epoch: 12 Iteration: 69 : Loss: 0.9474 (0.018 sec)\n",
      "Epoch: 12 Iteration: 74 : Loss: 0.9716 (0.019 sec)\n",
      "Epoch: 12 Iteration: 79 : Loss: 1.0204 (0.018 sec)\n",
      "Epoch: 12 Iteration: 84 : Loss: 1.0082 (0.017 sec)\n",
      "Saving at epoch 12 step: 84\n",
      "Epoch: 12 Iteration: 89 : Loss: 0.9745 (0.021 sec)\n",
      "Epoch: 12 Iteration: 94 : Loss: 0.9898 (0.018 sec)\n",
      "Epoch: 12 Iteration: 99 : Loss: 1.0055 (0.022 sec)\n",
      "Epoch: 12 Iteration: 104 : Loss: 1.0595 (0.021 sec)\n",
      "Epoch: 12 Iteration: 109 : Loss: 1.0077 (0.023 sec)\n",
      "Epoch: 12 Iteration: 114 : Loss: 0.9539 (0.021 sec)\n",
      "Epoch: 13 Iteration: 1 : Loss: 0.9201 (0.019 sec)\n",
      "Epoch: 13 Iteration: 6 : Loss: 1.0243 (0.022 sec)\n",
      "Epoch: 13 Iteration: 11 : Loss: 1.0148 (0.018 sec)\n",
      "Epoch: 13 Iteration: 16 : Loss: 0.9687 (0.021 sec)\n",
      "Epoch: 13 Iteration: 21 : Loss: 0.9726 (0.019 sec)\n",
      "Epoch: 13 Iteration: 26 : Loss: 0.9618 (0.018 sec)\n",
      "Epoch: 13 Iteration: 31 : Loss: 1.0205 (0.024 sec)\n",
      "Epoch: 13 Iteration: 36 : Loss: 0.9856 (0.022 sec)\n",
      "Epoch: 13 Iteration: 41 : Loss: 0.9657 (0.022 sec)\n",
      "Epoch: 13 Iteration: 46 : Loss: 0.9244 (0.022 sec)\n",
      "Epoch: 13 Iteration: 51 : Loss: 1.0206 (0.018 sec)\n",
      "Epoch: 13 Iteration: 56 : Loss: 1.0247 (0.022 sec)\n",
      "Epoch: 13 Iteration: 61 : Loss: 0.9415 (0.018 sec)\n",
      "Epoch: 13 Iteration: 66 : Loss: 0.9846 (0.021 sec)\n",
      "Epoch: 13 Iteration: 71 : Loss: 1.0208 (0.021 sec)\n",
      "Epoch: 13 Iteration: 76 : Loss: 0.9297 (0.028 sec)\n",
      "Epoch: 13 Iteration: 81 : Loss: 1.0210 (0.025 sec)\n",
      "Epoch: 13 Iteration: 86 : Loss: 0.9806 (0.021 sec)\n",
      "Epoch: 13 Iteration: 91 : Loss: 1.0161 (0.020 sec)\n",
      "Epoch: 13 Iteration: 96 : Loss: 1.0372 (0.023 sec)\n",
      "Epoch: 13 Iteration: 101 : Loss: 0.9965 (0.018 sec)\n",
      "Epoch: 13 Iteration: 106 : Loss: 0.9704 (0.019 sec)\n",
      "Epoch: 13 Iteration: 111 : Loss: 0.9223 (0.023 sec)\n",
      "Epoch: 13 Iteration: 116 : Loss: 0.9980 (0.019 sec)\n",
      "Epoch: 14 Iteration: 3 : Loss: 1.0182 (0.018 sec)\n",
      "Epoch: 14 Iteration: 8 : Loss: 0.9268 (0.018 sec)\n",
      "Epoch: 14 Iteration: 13 : Loss: 0.9517 (0.018 sec)\n",
      "Epoch: 14 Iteration: 18 : Loss: 0.9421 (0.018 sec)\n",
      "Epoch: 14 Iteration: 23 : Loss: 0.9202 (0.018 sec)\n",
      "Epoch: 14 Iteration: 28 : Loss: 0.9776 (0.018 sec)\n",
      "Epoch: 14 Iteration: 33 : Loss: 0.9985 (0.018 sec)\n",
      "Epoch: 14 Iteration: 38 : Loss: 0.9435 (0.018 sec)\n",
      "Epoch: 14 Iteration: 43 : Loss: 0.9977 (0.020 sec)\n",
      "Epoch: 14 Iteration: 48 : Loss: 0.9821 (0.020 sec)\n",
      "Epoch: 14 Iteration: 53 : Loss: 0.9488 (0.018 sec)\n",
      "Epoch: 14 Iteration: 58 : Loss: 1.0138 (0.019 sec)\n",
      "Epoch: 14 Iteration: 63 : Loss: 1.0692 (0.024 sec)\n",
      "Epoch: 14 Iteration: 68 : Loss: 0.9869 (0.020 sec)\n",
      "Epoch: 14 Iteration: 73 : Loss: 0.9252 (0.024 sec)\n",
      "Epoch: 14 Iteration: 78 : Loss: 0.9442 (0.022 sec)\n",
      "Epoch: 14 Iteration: 83 : Loss: 0.9787 (0.018 sec)\n",
      "Epoch: 14 Iteration: 88 : Loss: 0.9757 (0.020 sec)\n",
      "Epoch: 14 Iteration: 93 : Loss: 0.9689 (0.021 sec)\n",
      "Epoch: 14 Iteration: 98 : Loss: 1.0521 (0.022 sec)\n",
      "Epoch: 14 Iteration: 103 : Loss: 0.9489 (0.020 sec)\n",
      "Epoch: 14 Iteration: 108 : Loss: 0.9793 (0.021 sec)\n",
      "Epoch: 14 Iteration: 113 : Loss: 0.9960 (0.019 sec)\n",
      "Epoch: 14 Iteration: 118 : Loss: 0.9738 (0.019 sec)\n",
      "Epoch: 15 Iteration: 5 : Loss: 0.9724 (0.018 sec)\n",
      "Epoch: 15 Iteration: 10 : Loss: 0.9860 (0.018 sec)\n",
      "Epoch: 15 Iteration: 15 : Loss: 1.0191 (0.018 sec)\n",
      "Epoch: 15 Iteration: 20 : Loss: 0.9844 (0.019 sec)\n",
      "Epoch: 15 Iteration: 25 : Loss: 0.9972 (0.018 sec)\n",
      "Epoch: 15 Iteration: 30 : Loss: 0.9780 (0.019 sec)\n",
      "Epoch: 15 Iteration: 35 : Loss: 0.9817 (0.019 sec)\n",
      "Epoch: 15 Iteration: 40 : Loss: 1.0419 (0.022 sec)\n",
      "Epoch: 15 Iteration: 45 : Loss: 1.0149 (0.020 sec)\n",
      "Epoch: 15 Iteration: 50 : Loss: 1.0018 (0.023 sec)\n",
      "Epoch: 15 Iteration: 55 : Loss: 1.0350 (0.024 sec)\n",
      "Epoch: 15 Iteration: 60 : Loss: 1.0428 (0.019 sec)\n",
      "Epoch: 15 Iteration: 65 : Loss: 0.9389 (0.023 sec)\n",
      "Epoch: 15 Iteration: 70 : Loss: 0.9808 (0.020 sec)\n",
      "Epoch: 15 Iteration: 75 : Loss: 0.9842 (0.021 sec)\n",
      "Epoch: 15 Iteration: 80 : Loss: 1.0233 (0.021 sec)\n",
      "Epoch: 15 Iteration: 85 : Loss: 1.0722 (0.020 sec)\n",
      "Epoch: 15 Iteration: 90 : Loss: 0.9813 (0.020 sec)\n",
      "Epoch: 15 Iteration: 95 : Loss: 1.0134 (0.022 sec)\n",
      "Epoch: 15 Iteration: 100 : Loss: 1.0275 (0.020 sec)\n",
      "Epoch: 15 Iteration: 105 : Loss: 0.9460 (0.018 sec)\n",
      "Epoch: 15 Iteration: 110 : Loss: 0.9523 (0.026 sec)\n",
      "Epoch: 15 Iteration: 115 : Loss: 0.9706 (0.018 sec)\n",
      "Epoch: 16 Iteration: 2 : Loss: 0.9185 (0.023 sec)\n",
      "Epoch: 16 Iteration: 7 : Loss: 1.0002 (0.023 sec)\n",
      "Epoch: 16 Iteration: 12 : Loss: 0.9830 (0.024 sec)\n",
      "Epoch: 16 Iteration: 17 : Loss: 0.9419 (0.018 sec)\n",
      "Epoch: 16 Iteration: 22 : Loss: 1.0258 (0.018 sec)\n",
      "Epoch: 16 Iteration: 27 : Loss: 0.9383 (0.019 sec)\n",
      "Epoch: 16 Iteration: 32 : Loss: 0.9881 (0.018 sec)\n",
      "Epoch: 16 Iteration: 37 : Loss: 0.9851 (0.018 sec)\n",
      "Epoch: 16 Iteration: 42 : Loss: 0.9849 (0.019 sec)\n",
      "Epoch: 16 Iteration: 47 : Loss: 0.9592 (0.021 sec)\n",
      "Epoch: 16 Iteration: 52 : Loss: 1.0485 (0.018 sec)\n",
      "Epoch: 16 Iteration: 57 : Loss: 0.9333 (0.018 sec)\n",
      "Epoch: 16 Iteration: 62 : Loss: 0.9678 (0.022 sec)\n",
      "Epoch: 16 Iteration: 67 : Loss: 0.9828 (0.024 sec)\n",
      "Epoch: 16 Iteration: 72 : Loss: 0.9663 (0.018 sec)\n",
      "Epoch: 16 Iteration: 77 : Loss: 0.9156 (0.019 sec)\n",
      "Epoch: 16 Iteration: 82 : Loss: 1.0198 (0.018 sec)\n",
      "Epoch: 16 Iteration: 87 : Loss: 1.0567 (0.018 sec)\n",
      "Epoch: 16 Iteration: 92 : Loss: 0.9816 (0.019 sec)\n",
      "Epoch: 16 Iteration: 97 : Loss: 0.9598 (0.020 sec)\n",
      "Epoch: 16 Iteration: 102 : Loss: 1.0082 (0.019 sec)\n",
      "Epoch: 16 Iteration: 107 : Loss: 1.0140 (0.021 sec)\n",
      "Epoch: 16 Iteration: 112 : Loss: 0.9927 (0.020 sec)\n",
      "Saving at epoch 16 step: 112\n",
      "Epoch: 16 Iteration: 117 : Loss: 1.0071 (0.020 sec)\n",
      "Epoch: 17 Iteration: 4 : Loss: 1.0186 (0.021 sec)\n",
      "Epoch: 17 Iteration: 9 : Loss: 0.9994 (0.019 sec)\n",
      "Epoch: 17 Iteration: 14 : Loss: 1.0079 (0.026 sec)\n",
      "Epoch: 17 Iteration: 19 : Loss: 0.9215 (0.019 sec)\n",
      "Epoch: 17 Iteration: 24 : Loss: 1.0041 (0.021 sec)\n",
      "Epoch: 17 Iteration: 29 : Loss: 0.9283 (0.018 sec)\n",
      "Epoch: 17 Iteration: 34 : Loss: 0.9333 (0.021 sec)\n",
      "Epoch: 17 Iteration: 39 : Loss: 1.0213 (0.020 sec)\n",
      "Epoch: 17 Iteration: 44 : Loss: 1.0268 (0.019 sec)\n",
      "Epoch: 17 Iteration: 49 : Loss: 0.9752 (0.018 sec)\n",
      "Epoch: 17 Iteration: 54 : Loss: 0.9372 (0.018 sec)\n",
      "Epoch: 17 Iteration: 59 : Loss: 1.0225 (0.022 sec)\n",
      "Epoch: 17 Iteration: 64 : Loss: 1.0191 (0.019 sec)\n",
      "Epoch: 17 Iteration: 69 : Loss: 1.0105 (0.021 sec)\n",
      "Epoch: 17 Iteration: 74 : Loss: 0.9932 (0.020 sec)\n",
      "Epoch: 17 Iteration: 79 : Loss: 0.9950 (0.022 sec)\n",
      "Epoch: 17 Iteration: 84 : Loss: 1.0029 (0.018 sec)\n",
      "Epoch: 17 Iteration: 89 : Loss: 0.9614 (0.022 sec)\n",
      "Epoch: 17 Iteration: 94 : Loss: 1.0005 (0.020 sec)\n",
      "Epoch: 17 Iteration: 99 : Loss: 0.9419 (0.018 sec)\n",
      "Epoch: 17 Iteration: 104 : Loss: 0.9640 (0.018 sec)\n",
      "Epoch: 17 Iteration: 109 : Loss: 0.9330 (0.018 sec)\n",
      "Epoch: 17 Iteration: 114 : Loss: 0.9768 (0.019 sec)\n",
      "Epoch: 18 Iteration: 1 : Loss: 1.0178 (0.020 sec)\n",
      "Epoch: 18 Iteration: 6 : Loss: 0.9986 (0.018 sec)\n",
      "Epoch: 18 Iteration: 11 : Loss: 0.9552 (0.019 sec)\n",
      "Epoch: 18 Iteration: 16 : Loss: 0.9451 (0.022 sec)\n",
      "Epoch: 18 Iteration: 21 : Loss: 0.9703 (0.018 sec)\n",
      "Epoch: 18 Iteration: 26 : Loss: 1.0712 (0.021 sec)\n",
      "Epoch: 18 Iteration: 31 : Loss: 0.9611 (0.018 sec)\n",
      "Epoch: 18 Iteration: 36 : Loss: 0.9654 (0.018 sec)\n",
      "Epoch: 18 Iteration: 41 : Loss: 0.9596 (0.019 sec)\n",
      "Epoch: 18 Iteration: 46 : Loss: 0.9707 (0.018 sec)\n",
      "Epoch: 18 Iteration: 51 : Loss: 0.9347 (0.022 sec)\n",
      "Epoch: 18 Iteration: 56 : Loss: 0.9784 (0.020 sec)\n",
      "Epoch: 18 Iteration: 61 : Loss: 1.0218 (0.018 sec)\n",
      "Epoch: 18 Iteration: 66 : Loss: 0.9529 (0.022 sec)\n",
      "Epoch: 18 Iteration: 71 : Loss: 1.0027 (0.018 sec)\n",
      "Epoch: 18 Iteration: 76 : Loss: 1.0574 (0.018 sec)\n",
      "Epoch: 18 Iteration: 81 : Loss: 0.9527 (0.018 sec)\n",
      "Epoch: 18 Iteration: 86 : Loss: 0.9873 (0.020 sec)\n",
      "Epoch: 18 Iteration: 91 : Loss: 0.9790 (0.018 sec)\n",
      "Epoch: 18 Iteration: 96 : Loss: 0.9915 (0.018 sec)\n",
      "Epoch: 18 Iteration: 101 : Loss: 0.9865 (0.018 sec)\n",
      "Epoch: 18 Iteration: 106 : Loss: 0.9421 (0.018 sec)\n",
      "Epoch: 18 Iteration: 111 : Loss: 0.9471 (0.026 sec)\n",
      "Epoch: 18 Iteration: 116 : Loss: 0.9719 (0.018 sec)\n",
      "Epoch: 19 Iteration: 3 : Loss: 0.9588 (0.020 sec)\n",
      "Epoch: 19 Iteration: 8 : Loss: 0.9630 (0.025 sec)\n",
      "Epoch: 19 Iteration: 13 : Loss: 1.0091 (0.020 sec)\n",
      "Epoch: 19 Iteration: 18 : Loss: 0.9871 (0.018 sec)\n",
      "Epoch: 19 Iteration: 23 : Loss: 0.9805 (0.018 sec)\n",
      "Epoch: 19 Iteration: 28 : Loss: 0.9861 (0.018 sec)\n",
      "Epoch: 19 Iteration: 33 : Loss: 0.9535 (0.018 sec)\n",
      "Epoch: 19 Iteration: 38 : Loss: 0.9995 (0.023 sec)\n",
      "Epoch: 19 Iteration: 43 : Loss: 0.9474 (0.020 sec)\n",
      "Epoch: 19 Iteration: 48 : Loss: 0.9654 (0.019 sec)\n",
      "Epoch: 19 Iteration: 53 : Loss: 1.0375 (0.018 sec)\n",
      "Epoch: 19 Iteration: 58 : Loss: 0.9495 (0.018 sec)\n",
      "Epoch: 19 Iteration: 63 : Loss: 1.0329 (0.018 sec)\n",
      "Epoch: 19 Iteration: 68 : Loss: 0.9544 (0.018 sec)\n",
      "Epoch: 19 Iteration: 73 : Loss: 0.9405 (0.018 sec)\n",
      "Epoch: 19 Iteration: 78 : Loss: 0.9914 (0.018 sec)\n",
      "Epoch: 19 Iteration: 83 : Loss: 0.9678 (0.018 sec)\n",
      "Epoch: 19 Iteration: 88 : Loss: 0.9455 (0.023 sec)\n",
      "Epoch: 19 Iteration: 93 : Loss: 0.9375 (0.018 sec)\n",
      "Epoch: 19 Iteration: 98 : Loss: 0.9442 (0.021 sec)\n",
      "Epoch: 19 Iteration: 103 : Loss: 0.9562 (0.023 sec)\n",
      "Epoch: 19 Iteration: 108 : Loss: 0.9514 (0.023 sec)\n",
      "Epoch: 19 Iteration: 113 : Loss: 1.0467 (0.023 sec)\n",
      "Epoch: 19 Iteration: 118 : Loss: 0.9266 (0.022 sec)\n",
      "Epoch: 20 Iteration: 5 : Loss: 0.9591 (0.018 sec)\n",
      "Epoch: 20 Iteration: 10 : Loss: 0.9958 (0.020 sec)\n",
      "Epoch: 20 Iteration: 15 : Loss: 0.9809 (0.019 sec)\n",
      "Epoch: 20 Iteration: 20 : Loss: 0.9548 (0.020 sec)\n",
      "Epoch: 20 Iteration: 25 : Loss: 1.0493 (0.021 sec)\n",
      "Epoch: 20 Iteration: 30 : Loss: 0.9933 (0.021 sec)\n",
      "Epoch: 20 Iteration: 35 : Loss: 0.9786 (0.019 sec)\n",
      "Epoch: 20 Iteration: 40 : Loss: 0.9779 (0.019 sec)\n",
      "Epoch: 20 Iteration: 45 : Loss: 1.0042 (0.019 sec)\n",
      "Epoch: 20 Iteration: 50 : Loss: 1.0138 (0.020 sec)\n",
      "Epoch: 20 Iteration: 55 : Loss: 0.9304 (0.019 sec)\n",
      "Epoch: 20 Iteration: 60 : Loss: 0.9549 (0.021 sec)\n",
      "Epoch: 20 Iteration: 65 : Loss: 0.9985 (0.022 sec)\n",
      "Epoch: 20 Iteration: 70 : Loss: 1.0199 (0.020 sec)\n",
      "Epoch: 20 Iteration: 75 : Loss: 1.0180 (0.024 sec)\n",
      "Epoch: 20 Iteration: 80 : Loss: 0.9781 (0.018 sec)\n",
      "Epoch: 20 Iteration: 85 : Loss: 0.9777 (0.022 sec)\n",
      "Epoch: 20 Iteration: 90 : Loss: 0.9773 (0.021 sec)\n",
      "Epoch: 20 Iteration: 95 : Loss: 1.0967 (0.021 sec)\n",
      "Epoch: 20 Iteration: 100 : Loss: 0.8749 (0.018 sec)\n",
      "Epoch: 20 Iteration: 105 : Loss: 0.9735 (0.018 sec)\n",
      "Epoch: 20 Iteration: 110 : Loss: 1.0028 (0.018 sec)\n",
      "Epoch: 20 Iteration: 115 : Loss: 0.9666 (0.018 sec)\n",
      "Epoch: 21 Iteration: 2 : Loss: 0.9679 (0.017 sec)\n",
      "Epoch: 21 Iteration: 7 : Loss: 1.0352 (0.018 sec)\n",
      "Epoch: 21 Iteration: 12 : Loss: 0.9600 (0.018 sec)\n",
      "Epoch: 21 Iteration: 17 : Loss: 0.9399 (0.021 sec)\n",
      "Epoch: 21 Iteration: 22 : Loss: 0.9627 (0.018 sec)\n",
      "Saving at epoch 21 step: 22\n",
      "Epoch: 21 Iteration: 27 : Loss: 0.9814 (0.018 sec)\n",
      "Epoch: 21 Iteration: 32 : Loss: 1.0258 (0.018 sec)\n",
      "Epoch: 21 Iteration: 37 : Loss: 0.9313 (0.018 sec)\n",
      "Epoch: 21 Iteration: 42 : Loss: 1.0026 (0.018 sec)\n",
      "Epoch: 21 Iteration: 47 : Loss: 0.9672 (0.018 sec)\n",
      "Epoch: 21 Iteration: 52 : Loss: 1.0036 (0.018 sec)\n",
      "Epoch: 21 Iteration: 57 : Loss: 0.9529 (0.018 sec)\n",
      "Epoch: 21 Iteration: 62 : Loss: 0.9687 (0.018 sec)\n",
      "Epoch: 21 Iteration: 67 : Loss: 1.0119 (0.017 sec)\n",
      "Epoch: 21 Iteration: 72 : Loss: 0.9993 (0.018 sec)\n",
      "Epoch: 21 Iteration: 77 : Loss: 0.9723 (0.017 sec)\n",
      "Epoch: 21 Iteration: 82 : Loss: 0.9894 (0.018 sec)\n",
      "Epoch: 21 Iteration: 87 : Loss: 0.9853 (0.018 sec)\n",
      "Epoch: 21 Iteration: 92 : Loss: 1.0443 (0.019 sec)\n",
      "Epoch: 21 Iteration: 97 : Loss: 0.9731 (0.018 sec)\n",
      "Epoch: 21 Iteration: 102 : Loss: 0.9663 (0.022 sec)\n",
      "Epoch: 21 Iteration: 107 : Loss: 1.0098 (0.017 sec)\n",
      "Epoch: 21 Iteration: 112 : Loss: 0.9478 (0.018 sec)\n",
      "Epoch: 21 Iteration: 117 : Loss: 1.0320 (0.021 sec)\n",
      "Epoch: 22 Iteration: 4 : Loss: 0.9385 (0.021 sec)\n",
      "Epoch: 22 Iteration: 9 : Loss: 0.9498 (0.018 sec)\n",
      "Epoch: 22 Iteration: 14 : Loss: 0.9521 (0.022 sec)\n",
      "Epoch: 22 Iteration: 19 : Loss: 0.9901 (0.021 sec)\n",
      "Epoch: 22 Iteration: 24 : Loss: 1.0276 (0.018 sec)\n",
      "Epoch: 22 Iteration: 29 : Loss: 0.9546 (0.019 sec)\n",
      "Epoch: 22 Iteration: 34 : Loss: 0.9868 (0.018 sec)\n",
      "Epoch: 22 Iteration: 39 : Loss: 0.9190 (0.018 sec)\n",
      "Epoch: 22 Iteration: 44 : Loss: 1.0140 (0.024 sec)\n",
      "Epoch: 22 Iteration: 49 : Loss: 1.0132 (0.019 sec)\n",
      "Epoch: 22 Iteration: 54 : Loss: 0.9834 (0.018 sec)\n",
      "Epoch: 22 Iteration: 59 : Loss: 0.9672 (0.019 sec)\n",
      "Epoch: 22 Iteration: 64 : Loss: 1.0093 (0.018 sec)\n",
      "Epoch: 22 Iteration: 69 : Loss: 0.9574 (0.018 sec)\n",
      "Epoch: 22 Iteration: 74 : Loss: 0.9817 (0.018 sec)\n",
      "Epoch: 22 Iteration: 79 : Loss: 0.9652 (0.018 sec)\n",
      "Epoch: 22 Iteration: 84 : Loss: 1.0264 (0.023 sec)\n",
      "Epoch: 22 Iteration: 89 : Loss: 0.9714 (0.026 sec)\n",
      "Epoch: 22 Iteration: 94 : Loss: 0.9729 (0.022 sec)\n",
      "Epoch: 22 Iteration: 99 : Loss: 1.0284 (0.018 sec)\n",
      "Epoch: 22 Iteration: 104 : Loss: 0.9379 (0.018 sec)\n",
      "Epoch: 22 Iteration: 109 : Loss: 1.0025 (0.018 sec)\n",
      "Epoch: 22 Iteration: 114 : Loss: 0.9529 (0.018 sec)\n",
      "Epoch: 23 Iteration: 1 : Loss: 0.9811 (0.019 sec)\n",
      "Epoch: 23 Iteration: 6 : Loss: 0.9649 (0.017 sec)\n",
      "Epoch: 23 Iteration: 11 : Loss: 0.9878 (0.018 sec)\n",
      "Epoch: 23 Iteration: 16 : Loss: 0.9745 (0.018 sec)\n",
      "Epoch: 23 Iteration: 21 : Loss: 0.9647 (0.022 sec)\n",
      "Epoch: 23 Iteration: 26 : Loss: 1.0185 (0.018 sec)\n",
      "Epoch: 23 Iteration: 31 : Loss: 0.9653 (0.018 sec)\n",
      "Epoch: 23 Iteration: 36 : Loss: 0.9855 (0.018 sec)\n",
      "Epoch: 23 Iteration: 41 : Loss: 0.9329 (0.018 sec)\n",
      "Epoch: 23 Iteration: 46 : Loss: 0.9616 (0.018 sec)\n",
      "Epoch: 23 Iteration: 51 : Loss: 1.0013 (0.018 sec)\n",
      "Epoch: 23 Iteration: 56 : Loss: 1.0630 (0.020 sec)\n",
      "Epoch: 23 Iteration: 61 : Loss: 0.9510 (0.020 sec)\n",
      "Epoch: 23 Iteration: 66 : Loss: 0.9859 (0.021 sec)\n",
      "Epoch: 23 Iteration: 71 : Loss: 0.9889 (0.022 sec)\n",
      "Epoch: 23 Iteration: 76 : Loss: 0.9704 (0.018 sec)\n",
      "Epoch: 23 Iteration: 81 : Loss: 0.9673 (0.018 sec)\n",
      "Epoch: 23 Iteration: 86 : Loss: 0.9692 (0.018 sec)\n",
      "Epoch: 23 Iteration: 91 : Loss: 0.9637 (0.020 sec)\n",
      "Epoch: 23 Iteration: 96 : Loss: 1.0030 (0.022 sec)\n",
      "Epoch: 23 Iteration: 101 : Loss: 0.9154 (0.018 sec)\n",
      "Epoch: 23 Iteration: 106 : Loss: 0.9992 (0.024 sec)\n",
      "Epoch: 23 Iteration: 111 : Loss: 0.9629 (0.022 sec)\n",
      "Epoch: 23 Iteration: 116 : Loss: 0.9977 (0.023 sec)\n",
      "Epoch: 24 Iteration: 3 : Loss: 0.9539 (0.017 sec)\n",
      "Epoch: 24 Iteration: 8 : Loss: 0.9690 (0.023 sec)\n",
      "Epoch: 24 Iteration: 13 : Loss: 0.9949 (0.021 sec)\n",
      "Epoch: 24 Iteration: 18 : Loss: 1.0055 (0.021 sec)\n",
      "Epoch: 24 Iteration: 23 : Loss: 0.9638 (0.022 sec)\n",
      "Epoch: 24 Iteration: 28 : Loss: 0.9381 (0.023 sec)\n",
      "Epoch: 24 Iteration: 33 : Loss: 1.0275 (0.018 sec)\n",
      "Epoch: 24 Iteration: 38 : Loss: 1.0116 (0.023 sec)\n",
      "Epoch: 24 Iteration: 43 : Loss: 0.9895 (0.026 sec)\n",
      "Epoch: 24 Iteration: 48 : Loss: 0.9069 (0.020 sec)\n",
      "Epoch: 24 Iteration: 53 : Loss: 0.9658 (0.022 sec)\n",
      "Epoch: 24 Iteration: 58 : Loss: 0.9626 (0.019 sec)\n",
      "Epoch: 24 Iteration: 63 : Loss: 0.9344 (0.019 sec)\n",
      "Epoch: 24 Iteration: 68 : Loss: 1.0721 (0.020 sec)\n",
      "Epoch: 24 Iteration: 73 : Loss: 0.9493 (0.022 sec)\n",
      "Epoch: 24 Iteration: 78 : Loss: 0.9515 (0.022 sec)\n",
      "Epoch: 24 Iteration: 83 : Loss: 1.0039 (0.019 sec)\n",
      "Epoch: 24 Iteration: 88 : Loss: 0.9895 (0.019 sec)\n",
      "Epoch: 24 Iteration: 93 : Loss: 0.9765 (0.021 sec)\n",
      "Epoch: 24 Iteration: 98 : Loss: 0.9936 (0.026 sec)\n",
      "Epoch: 24 Iteration: 103 : Loss: 0.9987 (0.023 sec)\n",
      "Epoch: 24 Iteration: 108 : Loss: 1.0568 (0.026 sec)\n",
      "Epoch: 24 Iteration: 113 : Loss: 0.9175 (0.018 sec)\n",
      "Epoch: 24 Iteration: 118 : Loss: 0.9614 (0.020 sec)\n",
      "Epoch: 25 Iteration: 5 : Loss: 0.9542 (0.020 sec)\n",
      "Epoch: 25 Iteration: 10 : Loss: 1.0217 (0.020 sec)\n",
      "Epoch: 25 Iteration: 15 : Loss: 0.9590 (0.021 sec)\n",
      "Epoch: 25 Iteration: 20 : Loss: 1.0233 (0.018 sec)\n",
      "Epoch: 25 Iteration: 25 : Loss: 1.0126 (0.020 sec)\n",
      "Epoch: 25 Iteration: 30 : Loss: 0.9707 (0.022 sec)\n",
      "Epoch: 25 Iteration: 35 : Loss: 0.9642 (0.023 sec)\n",
      "Epoch: 25 Iteration: 40 : Loss: 0.9828 (0.021 sec)\n",
      "Epoch: 25 Iteration: 45 : Loss: 0.9351 (0.018 sec)\n",
      "Epoch: 25 Iteration: 50 : Loss: 0.9899 (0.018 sec)\n",
      "Saving at epoch 25 step: 50\n",
      "Epoch: 25 Iteration: 55 : Loss: 0.9902 (0.018 sec)\n",
      "Epoch: 25 Iteration: 60 : Loss: 1.0022 (0.020 sec)\n",
      "Epoch: 25 Iteration: 65 : Loss: 1.0247 (0.018 sec)\n",
      "Epoch: 25 Iteration: 70 : Loss: 0.9349 (0.018 sec)\n",
      "Epoch: 25 Iteration: 75 : Loss: 0.9787 (0.018 sec)\n",
      "Epoch: 25 Iteration: 80 : Loss: 1.0529 (0.018 sec)\n",
      "Epoch: 25 Iteration: 85 : Loss: 0.9456 (0.018 sec)\n",
      "Epoch: 25 Iteration: 90 : Loss: 0.9272 (0.018 sec)\n",
      "Epoch: 25 Iteration: 95 : Loss: 0.9904 (0.018 sec)\n",
      "Epoch: 25 Iteration: 100 : Loss: 0.9897 (0.018 sec)\n",
      "Epoch: 25 Iteration: 105 : Loss: 0.9855 (0.018 sec)\n",
      "Epoch: 25 Iteration: 110 : Loss: 1.0090 (0.018 sec)\n",
      "Epoch: 25 Iteration: 115 : Loss: 0.9880 (0.018 sec)\n",
      "Epoch: 26 Iteration: 2 : Loss: 1.0068 (0.017 sec)\n",
      "Epoch: 26 Iteration: 7 : Loss: 0.9459 (0.019 sec)\n",
      "Epoch: 26 Iteration: 12 : Loss: 0.9994 (0.021 sec)\n",
      "Epoch: 26 Iteration: 17 : Loss: 1.0443 (0.018 sec)\n",
      "Epoch: 26 Iteration: 22 : Loss: 0.9970 (0.017 sec)\n",
      "Epoch: 26 Iteration: 27 : Loss: 0.9474 (0.022 sec)\n",
      "Epoch: 26 Iteration: 32 : Loss: 0.9293 (0.018 sec)\n",
      "Epoch: 26 Iteration: 37 : Loss: 0.9997 (0.018 sec)\n",
      "Epoch: 26 Iteration: 42 : Loss: 0.9853 (0.023 sec)\n",
      "Epoch: 26 Iteration: 47 : Loss: 1.0123 (0.021 sec)\n",
      "Epoch: 26 Iteration: 52 : Loss: 0.9830 (0.018 sec)\n",
      "Epoch: 26 Iteration: 57 : Loss: 0.9792 (0.020 sec)\n",
      "Epoch: 26 Iteration: 62 : Loss: 0.9706 (0.023 sec)\n",
      "Epoch: 26 Iteration: 67 : Loss: 0.9646 (0.017 sec)\n",
      "Epoch: 26 Iteration: 72 : Loss: 0.9849 (0.018 sec)\n",
      "Epoch: 26 Iteration: 77 : Loss: 0.9485 (0.018 sec)\n",
      "Epoch: 26 Iteration: 82 : Loss: 0.9145 (0.018 sec)\n",
      "Epoch: 26 Iteration: 87 : Loss: 0.9640 (0.018 sec)\n",
      "Epoch: 26 Iteration: 92 : Loss: 1.0151 (0.017 sec)\n",
      "Epoch: 26 Iteration: 97 : Loss: 1.0250 (0.018 sec)\n",
      "Epoch: 26 Iteration: 102 : Loss: 0.9604 (0.018 sec)\n",
      "Epoch: 26 Iteration: 107 : Loss: 0.9085 (0.018 sec)\n",
      "Epoch: 26 Iteration: 112 : Loss: 0.9284 (0.018 sec)\n",
      "Epoch: 26 Iteration: 117 : Loss: 1.0227 (0.023 sec)\n",
      "Epoch: 27 Iteration: 4 : Loss: 0.9984 (0.020 sec)\n",
      "Epoch: 27 Iteration: 9 : Loss: 1.0097 (0.018 sec)\n",
      "Epoch: 27 Iteration: 14 : Loss: 1.0230 (0.018 sec)\n",
      "Epoch: 27 Iteration: 19 : Loss: 1.0191 (0.018 sec)\n",
      "Epoch: 27 Iteration: 24 : Loss: 1.0160 (0.018 sec)\n",
      "Epoch: 27 Iteration: 29 : Loss: 0.9828 (0.018 sec)\n",
      "Epoch: 27 Iteration: 34 : Loss: 0.9927 (0.020 sec)\n",
      "Epoch: 27 Iteration: 39 : Loss: 0.9946 (0.018 sec)\n",
      "Epoch: 27 Iteration: 44 : Loss: 0.9682 (0.023 sec)\n",
      "Epoch: 27 Iteration: 49 : Loss: 0.9914 (0.018 sec)\n",
      "Epoch: 27 Iteration: 54 : Loss: 1.0031 (0.020 sec)\n",
      "Epoch: 27 Iteration: 59 : Loss: 0.9370 (0.026 sec)\n",
      "Epoch: 27 Iteration: 64 : Loss: 0.9844 (0.018 sec)\n",
      "Epoch: 27 Iteration: 69 : Loss: 0.9708 (0.019 sec)\n",
      "Epoch: 27 Iteration: 74 : Loss: 0.9902 (0.019 sec)\n",
      "Epoch: 27 Iteration: 79 : Loss: 0.9449 (0.019 sec)\n",
      "Epoch: 27 Iteration: 84 : Loss: 1.0160 (0.024 sec)\n",
      "Epoch: 27 Iteration: 89 : Loss: 0.9955 (0.018 sec)\n",
      "Epoch: 27 Iteration: 94 : Loss: 0.9318 (0.018 sec)\n",
      "Epoch: 27 Iteration: 99 : Loss: 0.9669 (0.018 sec)\n",
      "Epoch: 27 Iteration: 104 : Loss: 0.9161 (0.021 sec)\n",
      "Epoch: 27 Iteration: 109 : Loss: 1.0041 (0.020 sec)\n",
      "Epoch: 27 Iteration: 114 : Loss: 0.9902 (0.019 sec)\n",
      "Epoch: 28 Iteration: 1 : Loss: 1.0103 (0.018 sec)\n",
      "Epoch: 28 Iteration: 6 : Loss: 0.9925 (0.018 sec)\n",
      "Epoch: 28 Iteration: 11 : Loss: 0.9981 (0.018 sec)\n",
      "Epoch: 28 Iteration: 16 : Loss: 0.9510 (0.019 sec)\n",
      "Epoch: 28 Iteration: 21 : Loss: 0.9591 (0.023 sec)\n",
      "Epoch: 28 Iteration: 26 : Loss: 0.9739 (0.018 sec)\n",
      "Epoch: 28 Iteration: 31 : Loss: 1.0320 (0.018 sec)\n",
      "Epoch: 28 Iteration: 36 : Loss: 0.9842 (0.017 sec)\n",
      "Epoch: 28 Iteration: 41 : Loss: 1.0038 (0.018 sec)\n",
      "Epoch: 28 Iteration: 46 : Loss: 1.0002 (0.018 sec)\n",
      "Epoch: 28 Iteration: 51 : Loss: 1.0415 (0.019 sec)\n",
      "Epoch: 28 Iteration: 56 : Loss: 0.9536 (0.017 sec)\n",
      "Epoch: 28 Iteration: 61 : Loss: 0.9778 (0.019 sec)\n",
      "Epoch: 28 Iteration: 66 : Loss: 0.9580 (0.020 sec)\n",
      "Epoch: 28 Iteration: 71 : Loss: 0.8874 (0.023 sec)\n",
      "Epoch: 28 Iteration: 76 : Loss: 0.9532 (0.022 sec)\n",
      "Epoch: 28 Iteration: 81 : Loss: 1.0082 (0.018 sec)\n",
      "Epoch: 28 Iteration: 86 : Loss: 0.9808 (0.018 sec)\n",
      "Epoch: 28 Iteration: 91 : Loss: 0.9935 (0.018 sec)\n",
      "Epoch: 28 Iteration: 96 : Loss: 0.9977 (0.018 sec)\n",
      "Epoch: 28 Iteration: 101 : Loss: 0.9584 (0.018 sec)\n",
      "Epoch: 28 Iteration: 106 : Loss: 0.9599 (0.018 sec)\n",
      "Epoch: 28 Iteration: 111 : Loss: 1.0044 (0.018 sec)\n",
      "Epoch: 28 Iteration: 116 : Loss: 0.9602 (0.018 sec)\n",
      "Epoch: 29 Iteration: 3 : Loss: 0.9669 (0.017 sec)\n",
      "Epoch: 29 Iteration: 8 : Loss: 0.9938 (0.018 sec)\n",
      "Epoch: 29 Iteration: 13 : Loss: 0.8881 (0.018 sec)\n",
      "Epoch: 29 Iteration: 18 : Loss: 0.9667 (0.017 sec)\n",
      "Epoch: 29 Iteration: 23 : Loss: 0.9396 (0.018 sec)\n",
      "Epoch: 29 Iteration: 28 : Loss: 0.9861 (0.018 sec)\n",
      "Epoch: 29 Iteration: 33 : Loss: 1.0751 (0.021 sec)\n",
      "Epoch: 29 Iteration: 38 : Loss: 0.9687 (0.021 sec)\n",
      "Epoch: 29 Iteration: 43 : Loss: 1.0220 (0.018 sec)\n",
      "Epoch: 29 Iteration: 48 : Loss: 0.9718 (0.021 sec)\n",
      "Epoch: 29 Iteration: 53 : Loss: 1.0017 (0.018 sec)\n",
      "Epoch: 29 Iteration: 58 : Loss: 1.0317 (0.023 sec)\n",
      "Epoch: 29 Iteration: 63 : Loss: 0.9816 (0.023 sec)\n",
      "Epoch: 29 Iteration: 68 : Loss: 1.0319 (0.018 sec)\n",
      "Epoch: 29 Iteration: 73 : Loss: 0.9729 (0.018 sec)\n",
      "Epoch: 29 Iteration: 78 : Loss: 1.0093 (0.020 sec)\n",
      "Saving at epoch 29 step: 78\n",
      "Epoch: 29 Iteration: 83 : Loss: 1.0907 (0.026 sec)\n",
      "Epoch: 29 Iteration: 88 : Loss: 0.9728 (0.024 sec)\n",
      "Epoch: 29 Iteration: 93 : Loss: 0.9536 (0.020 sec)\n",
      "Epoch: 29 Iteration: 98 : Loss: 0.9512 (0.023 sec)\n",
      "Epoch: 29 Iteration: 103 : Loss: 0.9689 (0.018 sec)\n",
      "Epoch: 29 Iteration: 108 : Loss: 1.0128 (0.018 sec)\n",
      "Epoch: 29 Iteration: 113 : Loss: 0.9581 (0.018 sec)\n",
      "Epoch: 29 Iteration: 118 : Loss: 0.9662 (0.024 sec)\n",
      "Epoch: 30 Iteration: 5 : Loss: 1.0893 (0.020 sec)\n",
      "Epoch: 30 Iteration: 10 : Loss: 0.9743 (0.022 sec)\n",
      "Epoch: 30 Iteration: 15 : Loss: 0.9363 (0.021 sec)\n",
      "Epoch: 30 Iteration: 20 : Loss: 1.0290 (0.025 sec)\n",
      "Epoch: 30 Iteration: 25 : Loss: 0.9654 (0.023 sec)\n",
      "Epoch: 30 Iteration: 30 : Loss: 0.9284 (0.017 sec)\n",
      "Epoch: 30 Iteration: 35 : Loss: 1.0543 (0.023 sec)\n",
      "Epoch: 30 Iteration: 40 : Loss: 0.9803 (0.020 sec)\n",
      "Epoch: 30 Iteration: 45 : Loss: 0.9042 (0.022 sec)\n",
      "Epoch: 30 Iteration: 50 : Loss: 1.0412 (0.018 sec)\n",
      "Epoch: 30 Iteration: 55 : Loss: 1.0243 (0.018 sec)\n",
      "Epoch: 30 Iteration: 60 : Loss: 0.9772 (0.022 sec)\n",
      "Epoch: 30 Iteration: 65 : Loss: 1.0286 (0.018 sec)\n",
      "Epoch: 30 Iteration: 70 : Loss: 0.9770 (0.019 sec)\n",
      "Epoch: 30 Iteration: 75 : Loss: 1.0304 (0.022 sec)\n",
      "Epoch: 30 Iteration: 80 : Loss: 1.0066 (0.018 sec)\n",
      "Epoch: 30 Iteration: 85 : Loss: 0.9634 (0.021 sec)\n",
      "Epoch: 30 Iteration: 90 : Loss: 1.0044 (0.018 sec)\n",
      "Epoch: 30 Iteration: 95 : Loss: 0.9965 (0.020 sec)\n",
      "Epoch: 30 Iteration: 100 : Loss: 1.0475 (0.018 sec)\n",
      "Epoch: 30 Iteration: 105 : Loss: 1.0140 (0.017 sec)\n",
      "Epoch: 30 Iteration: 110 : Loss: 0.9362 (0.018 sec)\n",
      "Epoch: 30 Iteration: 115 : Loss: 0.9496 (0.018 sec)\n",
      "Epoch: 31 Iteration: 2 : Loss: 0.9539 (0.018 sec)\n",
      "Epoch: 31 Iteration: 7 : Loss: 1.0115 (0.018 sec)\n",
      "Epoch: 31 Iteration: 12 : Loss: 0.9721 (0.018 sec)\n",
      "Epoch: 31 Iteration: 17 : Loss: 1.0010 (0.022 sec)\n",
      "Epoch: 31 Iteration: 22 : Loss: 0.9939 (0.018 sec)\n",
      "Epoch: 31 Iteration: 27 : Loss: 0.9717 (0.019 sec)\n",
      "Epoch: 31 Iteration: 32 : Loss: 0.9693 (0.018 sec)\n",
      "Epoch: 31 Iteration: 37 : Loss: 0.9631 (0.020 sec)\n",
      "Epoch: 31 Iteration: 42 : Loss: 1.0476 (0.021 sec)\n",
      "Epoch: 31 Iteration: 47 : Loss: 1.0653 (0.019 sec)\n",
      "Epoch: 31 Iteration: 52 : Loss: 0.9782 (0.018 sec)\n",
      "Epoch: 31 Iteration: 57 : Loss: 0.9413 (0.020 sec)\n",
      "Epoch: 31 Iteration: 62 : Loss: 0.9769 (0.021 sec)\n",
      "Epoch: 31 Iteration: 67 : Loss: 0.9583 (0.020 sec)\n",
      "Epoch: 31 Iteration: 72 : Loss: 0.9595 (0.018 sec)\n",
      "Epoch: 31 Iteration: 77 : Loss: 0.9384 (0.019 sec)\n",
      "Epoch: 31 Iteration: 82 : Loss: 1.0526 (0.022 sec)\n",
      "Epoch: 31 Iteration: 87 : Loss: 0.9967 (0.020 sec)\n",
      "Epoch: 31 Iteration: 92 : Loss: 0.9858 (0.018 sec)\n",
      "Epoch: 31 Iteration: 97 : Loss: 0.9278 (0.020 sec)\n",
      "Epoch: 31 Iteration: 102 : Loss: 0.9485 (0.020 sec)\n",
      "Epoch: 31 Iteration: 107 : Loss: 0.9695 (0.019 sec)\n",
      "Epoch: 31 Iteration: 112 : Loss: 0.9822 (0.019 sec)\n",
      "Epoch: 31 Iteration: 117 : Loss: 0.9876 (0.018 sec)\n",
      "Epoch: 32 Iteration: 4 : Loss: 0.9854 (0.017 sec)\n",
      "Epoch: 32 Iteration: 9 : Loss: 0.9323 (0.018 sec)\n",
      "Epoch: 32 Iteration: 14 : Loss: 1.0445 (0.020 sec)\n",
      "Epoch: 32 Iteration: 19 : Loss: 0.9536 (0.021 sec)\n",
      "Epoch: 32 Iteration: 24 : Loss: 0.9848 (0.018 sec)\n",
      "Epoch: 32 Iteration: 29 : Loss: 0.9640 (0.018 sec)\n",
      "Epoch: 32 Iteration: 34 : Loss: 0.9758 (0.018 sec)\n",
      "Epoch: 32 Iteration: 39 : Loss: 1.0193 (0.020 sec)\n",
      "Epoch: 32 Iteration: 44 : Loss: 0.9607 (0.018 sec)\n",
      "Epoch: 32 Iteration: 49 : Loss: 1.0224 (0.018 sec)\n",
      "Epoch: 32 Iteration: 54 : Loss: 0.9821 (0.018 sec)\n",
      "Epoch: 32 Iteration: 59 : Loss: 1.0116 (0.021 sec)\n",
      "Epoch: 32 Iteration: 64 : Loss: 1.0097 (0.018 sec)\n",
      "Epoch: 32 Iteration: 69 : Loss: 0.9431 (0.018 sec)\n",
      "Epoch: 32 Iteration: 74 : Loss: 0.9434 (0.018 sec)\n",
      "Epoch: 32 Iteration: 79 : Loss: 1.0096 (0.019 sec)\n",
      "Epoch: 32 Iteration: 84 : Loss: 0.9648 (0.022 sec)\n",
      "Epoch: 32 Iteration: 89 : Loss: 1.0098 (0.018 sec)\n",
      "Epoch: 32 Iteration: 94 : Loss: 0.9893 (0.020 sec)\n",
      "Epoch: 32 Iteration: 99 : Loss: 0.9538 (0.019 sec)\n",
      "Epoch: 32 Iteration: 104 : Loss: 0.9523 (0.020 sec)\n",
      "Epoch: 32 Iteration: 109 : Loss: 0.9235 (0.018 sec)\n",
      "Epoch: 32 Iteration: 114 : Loss: 1.0117 (0.023 sec)\n",
      "Epoch: 33 Iteration: 1 : Loss: 1.0640 (0.020 sec)\n",
      "Epoch: 33 Iteration: 6 : Loss: 0.9720 (0.020 sec)\n",
      "Epoch: 33 Iteration: 11 : Loss: 0.9834 (0.018 sec)\n",
      "Epoch: 33 Iteration: 16 : Loss: 1.0070 (0.018 sec)\n",
      "Epoch: 33 Iteration: 21 : Loss: 0.9758 (0.018 sec)\n",
      "Epoch: 33 Iteration: 26 : Loss: 0.8953 (0.018 sec)\n",
      "Epoch: 33 Iteration: 31 : Loss: 0.9557 (0.019 sec)\n",
      "Epoch: 33 Iteration: 36 : Loss: 0.9211 (0.018 sec)\n",
      "Epoch: 33 Iteration: 41 : Loss: 0.9607 (0.018 sec)\n",
      "Epoch: 33 Iteration: 46 : Loss: 1.0240 (0.018 sec)\n",
      "Epoch: 33 Iteration: 51 : Loss: 0.9465 (0.018 sec)\n",
      "Epoch: 33 Iteration: 56 : Loss: 0.9990 (0.018 sec)\n",
      "Epoch: 33 Iteration: 61 : Loss: 0.9127 (0.019 sec)\n",
      "Epoch: 33 Iteration: 66 : Loss: 0.9674 (0.018 sec)\n",
      "Epoch: 33 Iteration: 71 : Loss: 0.9627 (0.019 sec)\n",
      "Epoch: 33 Iteration: 76 : Loss: 0.9585 (0.018 sec)\n",
      "Epoch: 33 Iteration: 81 : Loss: 0.9747 (0.018 sec)\n",
      "Epoch: 33 Iteration: 86 : Loss: 0.9895 (0.022 sec)\n",
      "Epoch: 33 Iteration: 91 : Loss: 0.9316 (0.024 sec)\n",
      "Epoch: 33 Iteration: 96 : Loss: 0.9654 (0.018 sec)\n",
      "Epoch: 33 Iteration: 101 : Loss: 0.9641 (0.019 sec)\n",
      "Epoch: 33 Iteration: 106 : Loss: 0.9139 (0.019 sec)\n",
      "Saving at epoch 33 step: 106\n",
      "Epoch: 33 Iteration: 111 : Loss: 0.9463 (0.018 sec)\n",
      "Epoch: 33 Iteration: 116 : Loss: 0.9944 (0.018 sec)\n",
      "Epoch: 34 Iteration: 3 : Loss: 1.0014 (0.018 sec)\n",
      "Epoch: 34 Iteration: 8 : Loss: 1.0543 (0.018 sec)\n",
      "Epoch: 34 Iteration: 13 : Loss: 1.0199 (0.019 sec)\n",
      "Epoch: 34 Iteration: 18 : Loss: 1.0054 (0.018 sec)\n",
      "Epoch: 34 Iteration: 23 : Loss: 0.9426 (0.018 sec)\n",
      "Epoch: 34 Iteration: 28 : Loss: 0.9405 (0.018 sec)\n",
      "Epoch: 34 Iteration: 33 : Loss: 0.9361 (0.018 sec)\n",
      "Epoch: 34 Iteration: 38 : Loss: 1.0199 (0.019 sec)\n",
      "Epoch: 34 Iteration: 43 : Loss: 0.9444 (0.022 sec)\n",
      "Epoch: 34 Iteration: 48 : Loss: 0.9389 (0.019 sec)\n",
      "Epoch: 34 Iteration: 53 : Loss: 0.9465 (0.018 sec)\n",
      "Epoch: 34 Iteration: 58 : Loss: 0.9110 (0.019 sec)\n",
      "Epoch: 34 Iteration: 63 : Loss: 0.9547 (0.022 sec)\n",
      "Epoch: 34 Iteration: 68 : Loss: 0.9345 (0.018 sec)\n",
      "Epoch: 34 Iteration: 73 : Loss: 0.9825 (0.022 sec)\n",
      "Epoch: 34 Iteration: 78 : Loss: 0.9999 (0.018 sec)\n",
      "Epoch: 34 Iteration: 83 : Loss: 0.9551 (0.018 sec)\n",
      "Epoch: 34 Iteration: 88 : Loss: 1.0028 (0.019 sec)\n",
      "Epoch: 34 Iteration: 93 : Loss: 0.9609 (0.020 sec)\n",
      "Epoch: 34 Iteration: 98 : Loss: 0.9903 (0.018 sec)\n",
      "Epoch: 34 Iteration: 103 : Loss: 0.9897 (0.020 sec)\n",
      "Epoch: 34 Iteration: 108 : Loss: 0.9678 (0.018 sec)\n",
      "Epoch: 34 Iteration: 113 : Loss: 0.9900 (0.018 sec)\n",
      "Epoch: 34 Iteration: 118 : Loss: 0.9847 (0.018 sec)\n",
      "Epoch: 35 Iteration: 5 : Loss: 0.9627 (0.023 sec)\n",
      "Epoch: 35 Iteration: 10 : Loss: 1.0024 (0.020 sec)\n",
      "Epoch: 35 Iteration: 15 : Loss: 1.0191 (0.018 sec)\n",
      "Epoch: 35 Iteration: 20 : Loss: 0.9665 (0.024 sec)\n",
      "Epoch: 35 Iteration: 25 : Loss: 0.9817 (0.022 sec)\n",
      "Epoch: 35 Iteration: 30 : Loss: 0.9147 (0.020 sec)\n",
      "Epoch: 35 Iteration: 35 : Loss: 0.9966 (0.018 sec)\n",
      "Epoch: 35 Iteration: 40 : Loss: 0.9681 (0.021 sec)\n",
      "Epoch: 35 Iteration: 45 : Loss: 0.9979 (0.019 sec)\n",
      "Epoch: 35 Iteration: 50 : Loss: 0.9831 (0.022 sec)\n",
      "Epoch: 35 Iteration: 55 : Loss: 1.0475 (0.023 sec)\n",
      "Epoch: 35 Iteration: 60 : Loss: 0.9684 (0.022 sec)\n",
      "Epoch: 35 Iteration: 65 : Loss: 1.0321 (0.018 sec)\n",
      "Epoch: 35 Iteration: 70 : Loss: 0.9899 (0.021 sec)\n",
      "Epoch: 35 Iteration: 75 : Loss: 0.9918 (0.020 sec)\n",
      "Epoch: 35 Iteration: 80 : Loss: 1.0003 (0.018 sec)\n",
      "Epoch: 35 Iteration: 85 : Loss: 1.0388 (0.019 sec)\n",
      "Epoch: 35 Iteration: 90 : Loss: 0.9725 (0.022 sec)\n",
      "Epoch: 35 Iteration: 95 : Loss: 0.9603 (0.021 sec)\n",
      "Epoch: 35 Iteration: 100 : Loss: 0.9505 (0.024 sec)\n",
      "Epoch: 35 Iteration: 105 : Loss: 0.9853 (0.018 sec)\n",
      "Epoch: 35 Iteration: 110 : Loss: 1.0246 (0.024 sec)\n",
      "Epoch: 35 Iteration: 115 : Loss: 1.0205 (0.021 sec)\n",
      "Epoch: 36 Iteration: 2 : Loss: 0.9920 (0.019 sec)\n",
      "Epoch: 36 Iteration: 7 : Loss: 0.9637 (0.021 sec)\n",
      "Epoch: 36 Iteration: 12 : Loss: 0.9726 (0.023 sec)\n",
      "Epoch: 36 Iteration: 17 : Loss: 0.9542 (0.019 sec)\n",
      "Epoch: 36 Iteration: 22 : Loss: 0.9466 (0.018 sec)\n",
      "Epoch: 36 Iteration: 27 : Loss: 1.0041 (0.018 sec)\n",
      "Epoch: 36 Iteration: 32 : Loss: 0.9209 (0.023 sec)\n",
      "Epoch: 36 Iteration: 37 : Loss: 0.9759 (0.018 sec)\n",
      "Epoch: 36 Iteration: 42 : Loss: 1.0068 (0.021 sec)\n",
      "Epoch: 36 Iteration: 47 : Loss: 0.9630 (0.023 sec)\n",
      "Epoch: 36 Iteration: 52 : Loss: 0.9476 (0.023 sec)\n",
      "Epoch: 36 Iteration: 57 : Loss: 0.9593 (0.023 sec)\n",
      "Epoch: 36 Iteration: 62 : Loss: 1.0430 (0.018 sec)\n",
      "Epoch: 36 Iteration: 67 : Loss: 0.9816 (0.017 sec)\n",
      "Epoch: 36 Iteration: 72 : Loss: 0.9908 (0.025 sec)\n",
      "Epoch: 36 Iteration: 77 : Loss: 0.9334 (0.021 sec)\n",
      "Epoch: 36 Iteration: 82 : Loss: 1.0334 (0.020 sec)\n",
      "Epoch: 36 Iteration: 87 : Loss: 0.9939 (0.019 sec)\n",
      "Epoch: 36 Iteration: 92 : Loss: 0.9934 (0.018 sec)\n",
      "Epoch: 36 Iteration: 97 : Loss: 0.9506 (0.019 sec)\n",
      "Epoch: 36 Iteration: 102 : Loss: 0.9944 (0.022 sec)\n",
      "Epoch: 36 Iteration: 107 : Loss: 0.9157 (0.019 sec)\n",
      "Epoch: 36 Iteration: 112 : Loss: 1.0139 (0.023 sec)\n",
      "Epoch: 36 Iteration: 117 : Loss: 1.0599 (0.018 sec)\n",
      "Epoch: 37 Iteration: 4 : Loss: 1.0339 (0.019 sec)\n",
      "Epoch: 37 Iteration: 9 : Loss: 1.0129 (0.018 sec)\n",
      "Epoch: 37 Iteration: 14 : Loss: 0.9917 (0.018 sec)\n",
      "Epoch: 37 Iteration: 19 : Loss: 0.9439 (0.019 sec)\n",
      "Epoch: 37 Iteration: 24 : Loss: 0.9936 (0.019 sec)\n",
      "Epoch: 37 Iteration: 29 : Loss: 0.9443 (0.022 sec)\n",
      "Epoch: 37 Iteration: 34 : Loss: 0.9797 (0.020 sec)\n",
      "Epoch: 37 Iteration: 39 : Loss: 0.9733 (0.019 sec)\n",
      "Epoch: 37 Iteration: 44 : Loss: 1.0366 (0.018 sec)\n",
      "Epoch: 37 Iteration: 49 : Loss: 0.9997 (0.019 sec)\n",
      "Epoch: 37 Iteration: 54 : Loss: 0.9995 (0.021 sec)\n",
      "Epoch: 37 Iteration: 59 : Loss: 0.9390 (0.018 sec)\n",
      "Epoch: 37 Iteration: 64 : Loss: 0.9764 (0.018 sec)\n",
      "Epoch: 37 Iteration: 69 : Loss: 0.9343 (0.022 sec)\n",
      "Epoch: 37 Iteration: 74 : Loss: 0.9303 (0.019 sec)\n",
      "Epoch: 37 Iteration: 79 : Loss: 0.9954 (0.022 sec)\n",
      "Epoch: 37 Iteration: 84 : Loss: 0.9858 (0.018 sec)\n",
      "Epoch: 37 Iteration: 89 : Loss: 1.0081 (0.018 sec)\n",
      "Epoch: 37 Iteration: 94 : Loss: 0.9731 (0.018 sec)\n",
      "Epoch: 37 Iteration: 99 : Loss: 0.9775 (0.019 sec)\n",
      "Epoch: 37 Iteration: 104 : Loss: 1.0187 (0.023 sec)\n",
      "Epoch: 37 Iteration: 109 : Loss: 0.9866 (0.022 sec)\n",
      "Epoch: 37 Iteration: 114 : Loss: 0.9641 (0.023 sec)\n",
      "Epoch: 38 Iteration: 1 : Loss: 1.0027 (0.018 sec)\n",
      "Epoch: 38 Iteration: 6 : Loss: 1.0113 (0.021 sec)\n",
      "Epoch: 38 Iteration: 11 : Loss: 0.9980 (0.018 sec)\n",
      "Epoch: 38 Iteration: 16 : Loss: 0.9797 (0.021 sec)\n",
      "Saving at epoch 38 step: 16\n",
      "Epoch: 38 Iteration: 21 : Loss: 1.0016 (0.018 sec)\n",
      "Epoch: 38 Iteration: 26 : Loss: 0.9617 (0.023 sec)\n",
      "Epoch: 38 Iteration: 31 : Loss: 0.9818 (0.019 sec)\n",
      "Epoch: 38 Iteration: 36 : Loss: 1.0074 (0.019 sec)\n",
      "Epoch: 38 Iteration: 41 : Loss: 0.9802 (0.021 sec)\n",
      "Epoch: 38 Iteration: 46 : Loss: 1.0408 (0.018 sec)\n",
      "Epoch: 38 Iteration: 51 : Loss: 0.9185 (0.019 sec)\n",
      "Epoch: 38 Iteration: 56 : Loss: 0.9924 (0.018 sec)\n",
      "Epoch: 38 Iteration: 61 : Loss: 0.9354 (0.019 sec)\n",
      "Epoch: 38 Iteration: 66 : Loss: 0.9456 (0.018 sec)\n",
      "Epoch: 38 Iteration: 71 : Loss: 0.9787 (0.020 sec)\n",
      "Epoch: 38 Iteration: 76 : Loss: 0.9685 (0.018 sec)\n",
      "Epoch: 38 Iteration: 81 : Loss: 0.9354 (0.018 sec)\n",
      "Epoch: 38 Iteration: 86 : Loss: 0.9701 (0.018 sec)\n",
      "Epoch: 38 Iteration: 91 : Loss: 0.9562 (0.019 sec)\n",
      "Epoch: 38 Iteration: 96 : Loss: 0.9190 (0.018 sec)\n",
      "Epoch: 38 Iteration: 101 : Loss: 0.9561 (0.018 sec)\n",
      "Epoch: 38 Iteration: 106 : Loss: 0.9904 (0.018 sec)\n",
      "Epoch: 38 Iteration: 111 : Loss: 0.9284 (0.018 sec)\n",
      "Epoch: 38 Iteration: 116 : Loss: 0.9691 (0.019 sec)\n",
      "Epoch: 39 Iteration: 3 : Loss: 0.9449 (0.017 sec)\n",
      "Epoch: 39 Iteration: 8 : Loss: 1.0053 (0.018 sec)\n",
      "Epoch: 39 Iteration: 13 : Loss: 1.0291 (0.023 sec)\n",
      "Epoch: 39 Iteration: 18 : Loss: 0.9512 (0.021 sec)\n",
      "Epoch: 39 Iteration: 23 : Loss: 0.9693 (0.025 sec)\n",
      "Epoch: 39 Iteration: 28 : Loss: 0.9208 (0.020 sec)\n",
      "Epoch: 39 Iteration: 33 : Loss: 1.0776 (0.019 sec)\n",
      "Epoch: 39 Iteration: 38 : Loss: 0.9830 (0.018 sec)\n",
      "Epoch: 39 Iteration: 43 : Loss: 0.9629 (0.018 sec)\n",
      "Epoch: 39 Iteration: 48 : Loss: 0.9706 (0.018 sec)\n",
      "Epoch: 39 Iteration: 53 : Loss: 0.9476 (0.020 sec)\n",
      "Epoch: 39 Iteration: 58 : Loss: 0.9575 (0.020 sec)\n",
      "Epoch: 39 Iteration: 63 : Loss: 0.9206 (0.021 sec)\n",
      "Epoch: 39 Iteration: 68 : Loss: 0.9579 (0.021 sec)\n",
      "Epoch: 39 Iteration: 73 : Loss: 0.9602 (0.018 sec)\n",
      "Epoch: 39 Iteration: 78 : Loss: 1.0100 (0.018 sec)\n",
      "Epoch: 39 Iteration: 83 : Loss: 1.0715 (0.019 sec)\n",
      "Epoch: 39 Iteration: 88 : Loss: 0.9403 (0.018 sec)\n",
      "Epoch: 39 Iteration: 93 : Loss: 1.0091 (0.020 sec)\n",
      "Epoch: 39 Iteration: 98 : Loss: 0.9707 (0.020 sec)\n",
      "Epoch: 39 Iteration: 103 : Loss: 1.0958 (0.022 sec)\n",
      "Epoch: 39 Iteration: 108 : Loss: 0.9473 (0.018 sec)\n",
      "Epoch: 39 Iteration: 113 : Loss: 0.9535 (0.022 sec)\n",
      "Epoch: 39 Iteration: 118 : Loss: 0.9855 (0.018 sec)\n",
      "Epoch: 40 Iteration: 5 : Loss: 0.9382 (0.022 sec)\n",
      "Epoch: 40 Iteration: 10 : Loss: 1.0432 (0.020 sec)\n",
      "Epoch: 40 Iteration: 15 : Loss: 0.9234 (0.022 sec)\n",
      "Epoch: 40 Iteration: 20 : Loss: 1.0064 (0.018 sec)\n",
      "Epoch: 40 Iteration: 25 : Loss: 0.9752 (0.018 sec)\n",
      "Epoch: 40 Iteration: 30 : Loss: 1.0110 (0.018 sec)\n",
      "Epoch: 40 Iteration: 35 : Loss: 1.0328 (0.022 sec)\n",
      "Epoch: 40 Iteration: 40 : Loss: 1.0190 (0.019 sec)\n",
      "Epoch: 40 Iteration: 45 : Loss: 1.0051 (0.020 sec)\n",
      "Epoch: 40 Iteration: 50 : Loss: 0.9765 (0.018 sec)\n",
      "Epoch: 40 Iteration: 55 : Loss: 0.9737 (0.022 sec)\n",
      "Epoch: 40 Iteration: 60 : Loss: 0.9811 (0.020 sec)\n",
      "Epoch: 40 Iteration: 65 : Loss: 1.0114 (0.020 sec)\n",
      "Epoch: 40 Iteration: 70 : Loss: 0.9044 (0.023 sec)\n",
      "Epoch: 40 Iteration: 75 : Loss: 0.9486 (0.020 sec)\n",
      "Epoch: 40 Iteration: 80 : Loss: 0.9443 (0.018 sec)\n",
      "Epoch: 40 Iteration: 85 : Loss: 0.9947 (0.019 sec)\n",
      "Epoch: 40 Iteration: 90 : Loss: 1.0381 (0.021 sec)\n",
      "Epoch: 40 Iteration: 95 : Loss: 1.0173 (0.018 sec)\n",
      "Epoch: 40 Iteration: 100 : Loss: 1.0101 (0.020 sec)\n",
      "Epoch: 40 Iteration: 105 : Loss: 0.9736 (0.019 sec)\n",
      "Epoch: 40 Iteration: 110 : Loss: 0.9831 (0.018 sec)\n",
      "Epoch: 40 Iteration: 115 : Loss: 0.9892 (0.018 sec)\n",
      "Epoch: 41 Iteration: 2 : Loss: 0.9723 (0.018 sec)\n",
      "Epoch: 41 Iteration: 7 : Loss: 1.0333 (0.018 sec)\n",
      "Epoch: 41 Iteration: 12 : Loss: 1.0121 (0.019 sec)\n",
      "Epoch: 41 Iteration: 17 : Loss: 1.0131 (0.018 sec)\n",
      "Epoch: 41 Iteration: 22 : Loss: 0.9338 (0.018 sec)\n",
      "Epoch: 41 Iteration: 27 : Loss: 0.9288 (0.018 sec)\n",
      "Epoch: 41 Iteration: 32 : Loss: 1.0215 (0.019 sec)\n",
      "Epoch: 41 Iteration: 37 : Loss: 0.9757 (0.018 sec)\n",
      "Epoch: 41 Iteration: 42 : Loss: 0.9331 (0.022 sec)\n",
      "Epoch: 41 Iteration: 47 : Loss: 1.0129 (0.018 sec)\n",
      "Epoch: 41 Iteration: 52 : Loss: 0.9741 (0.020 sec)\n",
      "Epoch: 41 Iteration: 57 : Loss: 0.9670 (0.018 sec)\n",
      "Epoch: 41 Iteration: 62 : Loss: 1.0154 (0.020 sec)\n",
      "Epoch: 41 Iteration: 67 : Loss: 1.0727 (0.019 sec)\n",
      "Epoch: 41 Iteration: 72 : Loss: 1.0256 (0.021 sec)\n",
      "Epoch: 41 Iteration: 77 : Loss: 0.9601 (0.019 sec)\n",
      "Epoch: 41 Iteration: 82 : Loss: 1.0422 (0.020 sec)\n",
      "Epoch: 41 Iteration: 87 : Loss: 1.0182 (0.020 sec)\n",
      "Epoch: 41 Iteration: 92 : Loss: 0.9281 (0.020 sec)\n",
      "Epoch: 41 Iteration: 97 : Loss: 0.9393 (0.021 sec)\n",
      "Epoch: 41 Iteration: 102 : Loss: 1.0323 (0.018 sec)\n",
      "Epoch: 41 Iteration: 107 : Loss: 0.9986 (0.019 sec)\n",
      "Epoch: 41 Iteration: 112 : Loss: 0.9426 (0.021 sec)\n",
      "Epoch: 41 Iteration: 117 : Loss: 0.9276 (0.023 sec)\n",
      "Epoch: 42 Iteration: 4 : Loss: 0.9719 (0.018 sec)\n",
      "Epoch: 42 Iteration: 9 : Loss: 0.9416 (0.025 sec)\n",
      "Epoch: 42 Iteration: 14 : Loss: 0.9848 (0.023 sec)\n",
      "Epoch: 42 Iteration: 19 : Loss: 0.9680 (0.020 sec)\n",
      "Epoch: 42 Iteration: 24 : Loss: 0.9587 (0.022 sec)\n",
      "Epoch: 42 Iteration: 29 : Loss: 0.9661 (0.018 sec)\n",
      "Epoch: 42 Iteration: 34 : Loss: 0.9864 (0.018 sec)\n",
      "Epoch: 42 Iteration: 39 : Loss: 0.9493 (0.019 sec)\n",
      "Epoch: 42 Iteration: 44 : Loss: 1.0209 (0.018 sec)\n",
      "Saving at epoch 42 step: 44\n",
      "Epoch: 42 Iteration: 49 : Loss: 0.9847 (0.018 sec)\n",
      "Epoch: 42 Iteration: 54 : Loss: 0.9685 (0.022 sec)\n",
      "Epoch: 42 Iteration: 59 : Loss: 0.9943 (0.018 sec)\n",
      "Epoch: 42 Iteration: 64 : Loss: 0.9913 (0.018 sec)\n",
      "Epoch: 42 Iteration: 69 : Loss: 0.9643 (0.018 sec)\n",
      "Epoch: 42 Iteration: 74 : Loss: 0.9752 (0.019 sec)\n",
      "Epoch: 42 Iteration: 79 : Loss: 0.9905 (0.018 sec)\n",
      "Epoch: 42 Iteration: 84 : Loss: 0.9655 (0.019 sec)\n",
      "Epoch: 42 Iteration: 89 : Loss: 1.0221 (0.021 sec)\n",
      "Epoch: 42 Iteration: 94 : Loss: 0.9594 (0.018 sec)\n",
      "Epoch: 42 Iteration: 99 : Loss: 0.9769 (0.018 sec)\n",
      "Epoch: 42 Iteration: 104 : Loss: 0.9996 (0.019 sec)\n",
      "Epoch: 42 Iteration: 109 : Loss: 0.9771 (0.018 sec)\n",
      "Epoch: 42 Iteration: 114 : Loss: 0.9292 (0.018 sec)\n",
      "Epoch: 43 Iteration: 1 : Loss: 1.0359 (0.019 sec)\n",
      "Epoch: 43 Iteration: 6 : Loss: 0.9815 (0.018 sec)\n",
      "Epoch: 43 Iteration: 11 : Loss: 0.9499 (0.019 sec)\n",
      "Epoch: 43 Iteration: 16 : Loss: 0.9474 (0.018 sec)\n",
      "Epoch: 43 Iteration: 21 : Loss: 1.0070 (0.018 sec)\n",
      "Epoch: 43 Iteration: 26 : Loss: 1.0085 (0.019 sec)\n",
      "Epoch: 43 Iteration: 31 : Loss: 1.0012 (0.018 sec)\n",
      "Epoch: 43 Iteration: 36 : Loss: 0.9187 (0.018 sec)\n",
      "Epoch: 43 Iteration: 41 : Loss: 1.0231 (0.018 sec)\n",
      "Epoch: 43 Iteration: 46 : Loss: 0.9735 (0.020 sec)\n",
      "Epoch: 43 Iteration: 51 : Loss: 0.9537 (0.019 sec)\n",
      "Epoch: 43 Iteration: 56 : Loss: 1.0688 (0.018 sec)\n",
      "Epoch: 43 Iteration: 61 : Loss: 1.0260 (0.021 sec)\n",
      "Epoch: 43 Iteration: 66 : Loss: 1.0341 (0.019 sec)\n",
      "Epoch: 43 Iteration: 71 : Loss: 1.0324 (0.018 sec)\n",
      "Epoch: 43 Iteration: 76 : Loss: 1.0710 (0.018 sec)\n",
      "Epoch: 43 Iteration: 81 : Loss: 0.9689 (0.019 sec)\n",
      "Epoch: 43 Iteration: 86 : Loss: 0.9345 (0.018 sec)\n",
      "Epoch: 43 Iteration: 91 : Loss: 0.9727 (0.019 sec)\n",
      "Epoch: 43 Iteration: 96 : Loss: 0.9576 (0.021 sec)\n",
      "Epoch: 43 Iteration: 101 : Loss: 0.9665 (0.021 sec)\n",
      "Epoch: 43 Iteration: 106 : Loss: 0.9424 (0.026 sec)\n",
      "Epoch: 43 Iteration: 111 : Loss: 1.0078 (0.020 sec)\n",
      "Epoch: 43 Iteration: 116 : Loss: 0.9810 (0.022 sec)\n",
      "Epoch: 44 Iteration: 3 : Loss: 0.9761 (0.020 sec)\n",
      "Epoch: 44 Iteration: 8 : Loss: 1.0185 (0.022 sec)\n",
      "Epoch: 44 Iteration: 13 : Loss: 1.0431 (0.019 sec)\n",
      "Epoch: 44 Iteration: 18 : Loss: 1.0106 (0.021 sec)\n",
      "Epoch: 44 Iteration: 23 : Loss: 0.9602 (0.024 sec)\n",
      "Epoch: 44 Iteration: 28 : Loss: 1.0176 (0.020 sec)\n",
      "Epoch: 44 Iteration: 33 : Loss: 0.9150 (0.023 sec)\n",
      "Epoch: 44 Iteration: 38 : Loss: 1.0223 (0.022 sec)\n",
      "Epoch: 44 Iteration: 43 : Loss: 0.9485 (0.024 sec)\n",
      "Epoch: 44 Iteration: 48 : Loss: 0.9565 (0.021 sec)\n",
      "Epoch: 44 Iteration: 53 : Loss: 1.0130 (0.023 sec)\n",
      "Epoch: 44 Iteration: 58 : Loss: 0.9544 (0.018 sec)\n",
      "Epoch: 44 Iteration: 63 : Loss: 0.9915 (0.021 sec)\n",
      "Epoch: 44 Iteration: 68 : Loss: 0.9568 (0.020 sec)\n",
      "Epoch: 44 Iteration: 73 : Loss: 0.9000 (0.023 sec)\n",
      "Epoch: 44 Iteration: 78 : Loss: 0.9997 (0.019 sec)\n",
      "Epoch: 44 Iteration: 83 : Loss: 0.9860 (0.019 sec)\n",
      "Epoch: 44 Iteration: 88 : Loss: 0.9671 (0.024 sec)\n",
      "Epoch: 44 Iteration: 93 : Loss: 0.9594 (0.019 sec)\n",
      "Epoch: 44 Iteration: 98 : Loss: 1.0361 (0.022 sec)\n",
      "Epoch: 44 Iteration: 103 : Loss: 0.9609 (0.022 sec)\n",
      "Epoch: 44 Iteration: 108 : Loss: 0.9378 (0.020 sec)\n",
      "Epoch: 44 Iteration: 113 : Loss: 0.9405 (0.022 sec)\n",
      "Epoch: 44 Iteration: 118 : Loss: 0.9927 (0.020 sec)\n",
      "Epoch: 45 Iteration: 5 : Loss: 0.9758 (0.020 sec)\n",
      "Epoch: 45 Iteration: 10 : Loss: 1.0604 (0.024 sec)\n",
      "Epoch: 45 Iteration: 15 : Loss: 1.0700 (0.019 sec)\n",
      "Epoch: 45 Iteration: 20 : Loss: 0.9696 (0.022 sec)\n",
      "Epoch: 45 Iteration: 25 : Loss: 0.9851 (0.022 sec)\n",
      "Epoch: 45 Iteration: 30 : Loss: 1.0160 (0.019 sec)\n",
      "Epoch: 45 Iteration: 35 : Loss: 0.9790 (0.021 sec)\n",
      "Epoch: 45 Iteration: 40 : Loss: 1.0402 (0.025 sec)\n",
      "Epoch: 45 Iteration: 45 : Loss: 0.9789 (0.025 sec)\n",
      "Epoch: 45 Iteration: 50 : Loss: 0.9714 (0.020 sec)\n",
      "Epoch: 45 Iteration: 55 : Loss: 0.9720 (0.022 sec)\n",
      "Epoch: 45 Iteration: 60 : Loss: 1.0163 (0.024 sec)\n",
      "Epoch: 45 Iteration: 65 : Loss: 0.9890 (0.021 sec)\n",
      "Epoch: 45 Iteration: 70 : Loss: 0.9572 (0.019 sec)\n",
      "Epoch: 45 Iteration: 75 : Loss: 1.0162 (0.020 sec)\n",
      "Epoch: 45 Iteration: 80 : Loss: 0.9961 (0.020 sec)\n",
      "Epoch: 45 Iteration: 85 : Loss: 0.9706 (0.024 sec)\n",
      "Epoch: 45 Iteration: 90 : Loss: 0.9564 (0.021 sec)\n",
      "Epoch: 45 Iteration: 95 : Loss: 0.9601 (0.020 sec)\n",
      "Epoch: 45 Iteration: 100 : Loss: 0.9553 (0.019 sec)\n",
      "Epoch: 45 Iteration: 105 : Loss: 0.9733 (0.020 sec)\n",
      "Epoch: 45 Iteration: 110 : Loss: 1.0217 (0.019 sec)\n",
      "Epoch: 45 Iteration: 115 : Loss: 0.9443 (0.024 sec)\n",
      "Epoch: 46 Iteration: 2 : Loss: 1.0158 (0.021 sec)\n",
      "Epoch: 46 Iteration: 7 : Loss: 1.0248 (0.025 sec)\n",
      "Epoch: 46 Iteration: 12 : Loss: 1.0675 (0.024 sec)\n",
      "Epoch: 46 Iteration: 17 : Loss: 0.9746 (0.021 sec)\n",
      "Epoch: 46 Iteration: 22 : Loss: 0.9790 (0.020 sec)\n",
      "Epoch: 46 Iteration: 27 : Loss: 0.9769 (0.024 sec)\n",
      "Epoch: 46 Iteration: 32 : Loss: 1.0236 (0.020 sec)\n",
      "Epoch: 46 Iteration: 37 : Loss: 0.9008 (0.019 sec)\n",
      "Epoch: 46 Iteration: 42 : Loss: 1.0194 (0.019 sec)\n",
      "Epoch: 46 Iteration: 47 : Loss: 0.9352 (0.019 sec)\n",
      "Epoch: 46 Iteration: 52 : Loss: 0.9786 (0.020 sec)\n",
      "Epoch: 46 Iteration: 57 : Loss: 0.9983 (0.020 sec)\n",
      "Epoch: 46 Iteration: 62 : Loss: 1.0118 (0.021 sec)\n",
      "Epoch: 46 Iteration: 67 : Loss: 1.0422 (0.020 sec)\n",
      "Epoch: 46 Iteration: 72 : Loss: 0.9386 (0.020 sec)\n",
      "Saving at epoch 46 step: 72\n",
      "Epoch: 46 Iteration: 77 : Loss: 0.9616 (0.022 sec)\n",
      "Epoch: 46 Iteration: 82 : Loss: 0.9468 (0.020 sec)\n",
      "Epoch: 46 Iteration: 87 : Loss: 0.9474 (0.021 sec)\n",
      "Epoch: 46 Iteration: 92 : Loss: 0.9909 (0.024 sec)\n",
      "Epoch: 46 Iteration: 97 : Loss: 1.0038 (0.023 sec)\n",
      "Epoch: 46 Iteration: 102 : Loss: 0.9978 (0.022 sec)\n",
      "Epoch: 46 Iteration: 107 : Loss: 0.9560 (0.024 sec)\n",
      "Epoch: 46 Iteration: 112 : Loss: 1.0368 (0.022 sec)\n",
      "Epoch: 46 Iteration: 117 : Loss: 1.0389 (0.019 sec)\n",
      "Epoch: 47 Iteration: 4 : Loss: 1.0099 (0.023 sec)\n",
      "Epoch: 47 Iteration: 9 : Loss: 1.0202 (0.021 sec)\n",
      "Epoch: 47 Iteration: 14 : Loss: 0.9746 (0.023 sec)\n",
      "Epoch: 47 Iteration: 19 : Loss: 1.0175 (0.025 sec)\n",
      "Epoch: 47 Iteration: 24 : Loss: 0.9688 (0.024 sec)\n",
      "Epoch: 47 Iteration: 29 : Loss: 1.0260 (0.022 sec)\n",
      "Epoch: 47 Iteration: 34 : Loss: 0.9830 (0.019 sec)\n",
      "Epoch: 47 Iteration: 39 : Loss: 0.9835 (0.025 sec)\n",
      "Epoch: 47 Iteration: 44 : Loss: 0.9717 (0.022 sec)\n",
      "Epoch: 47 Iteration: 49 : Loss: 0.9555 (0.020 sec)\n",
      "Epoch: 47 Iteration: 54 : Loss: 0.9346 (0.019 sec)\n",
      "Epoch: 47 Iteration: 59 : Loss: 0.9994 (0.022 sec)\n",
      "Epoch: 47 Iteration: 64 : Loss: 0.9590 (0.022 sec)\n",
      "Epoch: 47 Iteration: 69 : Loss: 1.0023 (0.019 sec)\n",
      "Epoch: 47 Iteration: 74 : Loss: 0.9504 (0.019 sec)\n",
      "Epoch: 47 Iteration: 79 : Loss: 1.0111 (0.020 sec)\n",
      "Epoch: 47 Iteration: 84 : Loss: 0.9745 (0.019 sec)\n",
      "Epoch: 47 Iteration: 89 : Loss: 0.9296 (0.022 sec)\n",
      "Epoch: 47 Iteration: 94 : Loss: 0.9703 (0.022 sec)\n",
      "Epoch: 47 Iteration: 99 : Loss: 1.0085 (0.021 sec)\n",
      "Epoch: 47 Iteration: 104 : Loss: 0.9987 (0.020 sec)\n",
      "Epoch: 47 Iteration: 109 : Loss: 1.0397 (0.020 sec)\n",
      "Epoch: 47 Iteration: 114 : Loss: 1.0089 (0.021 sec)\n",
      "Epoch: 48 Iteration: 1 : Loss: 0.9623 (0.022 sec)\n",
      "Epoch: 48 Iteration: 6 : Loss: 0.9465 (0.025 sec)\n",
      "Epoch: 48 Iteration: 11 : Loss: 0.9795 (0.025 sec)\n",
      "Epoch: 48 Iteration: 16 : Loss: 0.9307 (0.021 sec)\n",
      "Epoch: 48 Iteration: 21 : Loss: 0.9785 (0.022 sec)\n",
      "Epoch: 48 Iteration: 26 : Loss: 1.0009 (0.024 sec)\n",
      "Epoch: 48 Iteration: 31 : Loss: 0.9816 (0.021 sec)\n",
      "Epoch: 48 Iteration: 36 : Loss: 0.9591 (0.018 sec)\n",
      "Epoch: 48 Iteration: 41 : Loss: 0.9791 (0.021 sec)\n",
      "Epoch: 48 Iteration: 46 : Loss: 0.9791 (0.022 sec)\n",
      "Epoch: 48 Iteration: 51 : Loss: 0.9146 (0.020 sec)\n",
      "Epoch: 48 Iteration: 56 : Loss: 0.9987 (0.027 sec)\n",
      "Epoch: 48 Iteration: 61 : Loss: 0.9797 (0.022 sec)\n",
      "Epoch: 48 Iteration: 66 : Loss: 1.0078 (0.021 sec)\n",
      "Epoch: 48 Iteration: 71 : Loss: 0.9999 (0.021 sec)\n",
      "Epoch: 48 Iteration: 76 : Loss: 0.9464 (0.022 sec)\n",
      "Epoch: 48 Iteration: 81 : Loss: 1.0300 (0.020 sec)\n",
      "Epoch: 48 Iteration: 86 : Loss: 0.9889 (0.020 sec)\n",
      "Epoch: 48 Iteration: 91 : Loss: 0.9060 (0.019 sec)\n",
      "Epoch: 48 Iteration: 96 : Loss: 0.9921 (0.019 sec)\n",
      "Epoch: 48 Iteration: 101 : Loss: 0.9105 (0.023 sec)\n",
      "Epoch: 48 Iteration: 106 : Loss: 0.9809 (0.020 sec)\n",
      "Epoch: 48 Iteration: 111 : Loss: 0.9939 (0.021 sec)\n",
      "Epoch: 48 Iteration: 116 : Loss: 0.9756 (0.019 sec)\n",
      "Epoch: 49 Iteration: 3 : Loss: 0.9948 (0.018 sec)\n",
      "Epoch: 49 Iteration: 8 : Loss: 0.9585 (0.018 sec)\n",
      "Epoch: 49 Iteration: 13 : Loss: 0.9785 (0.023 sec)\n",
      "Epoch: 49 Iteration: 18 : Loss: 0.9853 (0.019 sec)\n",
      "Epoch: 49 Iteration: 23 : Loss: 0.9149 (0.019 sec)\n",
      "Epoch: 49 Iteration: 28 : Loss: 0.9755 (0.019 sec)\n",
      "Epoch: 49 Iteration: 33 : Loss: 1.0065 (0.024 sec)\n",
      "Epoch: 49 Iteration: 38 : Loss: 0.9754 (0.021 sec)\n",
      "Epoch: 49 Iteration: 43 : Loss: 1.0232 (0.024 sec)\n",
      "Epoch: 49 Iteration: 48 : Loss: 0.9841 (0.021 sec)\n",
      "Epoch: 49 Iteration: 53 : Loss: 1.0164 (0.022 sec)\n",
      "Epoch: 49 Iteration: 58 : Loss: 0.9292 (0.020 sec)\n",
      "Epoch: 49 Iteration: 63 : Loss: 1.0179 (0.022 sec)\n",
      "Epoch: 49 Iteration: 68 : Loss: 1.0740 (0.022 sec)\n",
      "Epoch: 49 Iteration: 73 : Loss: 0.9794 (0.022 sec)\n",
      "Epoch: 49 Iteration: 78 : Loss: 1.0735 (0.020 sec)\n",
      "Epoch: 49 Iteration: 83 : Loss: 0.9706 (0.020 sec)\n",
      "Epoch: 49 Iteration: 88 : Loss: 1.0133 (0.022 sec)\n",
      "Epoch: 49 Iteration: 93 : Loss: 0.9411 (0.018 sec)\n",
      "Epoch: 49 Iteration: 98 : Loss: 0.9998 (0.021 sec)\n",
      "Epoch: 49 Iteration: 103 : Loss: 0.9773 (0.020 sec)\n",
      "Epoch: 49 Iteration: 108 : Loss: 0.9416 (0.019 sec)\n",
      "Epoch: 49 Iteration: 113 : Loss: 0.9518 (0.022 sec)\n",
      "Epoch: 49 Iteration: 118 : Loss: 0.9552 (0.023 sec)\n"
     ]
    }
   ],
   "source": [
    "# Where to save this model.\n",
    "model_path = os.path.join(logs_dir, time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "import tf_utils\n",
    "tf_utils = imp.reload(tf_utils)\n",
    "\n",
    "if ckpt:\n",
    "    restore_from_model = True\n",
    "    print(\"Restore from model!\")\n",
    "else:\n",
    "    restore_from_model = False\n",
    "\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "    summaries = tf.summary.merge_all()                                                       \n",
    "    writer = tf.summary.FileWriter(model_path,\n",
    "        graph=session.graph)                  \n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables()) \n",
    "                                                                                                  \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    if restore_from_model:\n",
    "        saver.restore(session, ckpt.model_checkpoint_path)\n",
    "        \n",
    "    global_step = 0\n",
    "        \n",
    "    for epoch in range(number_of_epochs):\n",
    "        eval_feed_generator = eval_input_fn()\n",
    "        # Shuffle the training input\n",
    "        x_train, y_train = tf_utils.unison_shuffled_copies(x_train, y_train)\n",
    "\n",
    "        for step, feed_dict in enumerate(input_fn()):\n",
    "            global_step += 1\n",
    "            start_time = time.time()\n",
    "\n",
    "            _, temp_loss = session.run([train_op, loss], feed_dict=feed_dict)\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            if global_step % reporting_frequency == 0:\n",
    "                print(\"Epoch: %s Iteration: %s : Loss: %.4f (%.3f sec)\" % \n",
    "                      (epoch, (step + 1), temp_loss, duration))\n",
    "\n",
    "                train_summ, train_mae = session.run([training_summary, training_mae], feed_dict=feed_dict)\n",
    "                writer.add_summary(train_summ, global_step)\n",
    "                writer.add_summary(train_mae, global_step)\n",
    "                _, valid_summ, valid_mae = session.run(\n",
    "                        [loss, validation_summary, validation_mae],\n",
    "                        feed_dict=next(eval_feed_generator))\n",
    "                writer.add_summary(valid_summ, global_step)\n",
    "                writer.add_summary(valid_mae, global_step)\n",
    "\n",
    "                writer.flush()                \n",
    "\n",
    "            if (global_step % checkpoint_frequency == 0) or (global_step == number_of_batches):\n",
    "                print(\"Saving at epoch %s step: %s\" % (epoch, step + 1))\n",
    "                saver.save(session, model_path, global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from logs/bagofwords/2017-06-27-20-46-01-38319\n",
      "Mean Absolute Error Loss over all 51200 observations = 9475.84244141\n"
     ]
    }
   ],
   "source": [
    "# How much data to evaluate\n",
    "#number_of_batches = len(x_train_text)/batch_size\n",
    "number_of_validation_batches = math.floor(len(x_test_text)/batch_size)\n",
    "ckpt = tf.train.get_checkpoint_state(logs_dir)                                     \n",
    "\n",
    "predictions = []\n",
    "# Write TF Model Evaluation Code here. \n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables()) \n",
    "                                                                                                  \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver.restore(session, ckpt.model_checkpoint_path)\n",
    "\n",
    "    total_loss = 0\n",
    "    for step, eval_feed_dict in enumerate(eval_input_fn()):    \n",
    "        valid_loss, mae = session.run(\n",
    "            [loss, mean_absolute_error_salary_scale], feed_dict=eval_feed_dict)\n",
    "        #print(\"Batch: %d Mean: %.4f\" % (step, mae))\n",
    "        total_loss += mae\n",
    "    print (\"Mean Absolute Error Loss over all %s observations = %s\" % ((step + 1) * batch_size, total_loss / (step + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:335: calling LinearRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Couldn't find trained model at /tmp/tmpc4vvis3j.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-923d676c9ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-923d676c9ea3>\u001b[0m in \u001b[0;36mprint_results\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLABEL_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m               func.__module__, arg_name, arg_value, date, instructions)\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    337\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m               func.__module__, arg_name, arg_value, date, instructions)\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    337\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[1;32m    755\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m           as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    758\u001b[0m     return super(LinearRegressor, self).predict(\n\u001b[1;32m    759\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m               func.__module__, arg_name, arg_value, date, instructions)\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    337\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py\u001b[0m in \u001b[0;36mpredict_scores\u001b[0;34m(self, x, input_fn, batch_size, as_iterable)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    793\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_as_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    283\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mfeed_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_infer_model\u001b[0;34m(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       raise NotFittedError(\"Couldn't find trained model at %s.\"\n\u001b[0;32m--> 851\u001b[0;31m                            % self._model_dir)\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Couldn't find trained model at /tmp/tmpc4vvis3j."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def print_results(model):\n",
    "    y_vals = [value for value in model.predict(input_fn=eval_input_fn)]\n",
    "    x_vals = X_test[LABEL_COLUMN]\n",
    "\n",
    "\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "    plt.show()\n",
    "\n",
    "    print(x_vals-y_vals)\n",
    "    #print(sorted([set(y_vals)]))\n",
    "\n",
    "    print(\"Mean absolute error: %s\" % \n",
    "          mean_absolute_error_salary_scale(y_vals, x_vals))\n",
    "    \n",
    "    \n",
    "print_results(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
