{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Core python libraries\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# External libraries.\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import sklearn\n",
    "import tempfile\n",
    "\n",
    "# Tensorflow and related.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For dynamically reolading modules. imp.reload(module_name) \n",
    "import imp\n",
    "\n",
    "# Internal libraries\n",
    "import tf_utils\n",
    "\n",
    "# So you know when this code block finishes.\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171482\n"
     ]
    }
   ],
   "source": [
    "#TODO(Max): make a library that does all this preprocessing\n",
    "data = pandas.read_csv(\"data/train.csv\") # Can read a subset. First nrows of the total.\n",
    "LABEL_COLUMN = \"SalaryNormalized\"\n",
    "\n",
    "TEST_SIZE = .3\n",
    "\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# sklearn.cross_validation has been replaced with model_selection.\n",
    "X_train_index, X_test_index, Y_train, Y_test = sklearn.model_selection.train_test_split(\n",
    "    data.index, data[LABEL_COLUMN], test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Keep train and test as pandas dataframes.\n",
    "X_train = data.iloc[X_train_index]\n",
    "X_test = data.iloc[X_test_index]\n",
    "\n",
    "y_train = numpy.array(X_train[LABEL_COLUMN].astype(numpy.float32))\n",
    "y_test = numpy.array(X_test[LABEL_COLUMN].astype(numpy.float32))\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalizing input values to mean 0, standard deviation 1.\n",
    "train_mean, train_std = y_train.mean(), y_train.std()\n",
    "\n",
    "# Normalize input labels and expectations\n",
    "y_train = tf_utils.normalize_input(y_train, train_mean, train_std)\n",
    "y_test = tf_utils.normalize_input(y_test, train_mean, train_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_column = \"CompleteJobListingStemmed\"\n",
    "\n",
    "x_train_text = X_train[target_column]\n",
    "x_test_text = X_test[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: 120037, 8762\n",
      "x_test shape: 51445, 8762\n",
      "Total distinct words: 8762\n",
      "Number of training rows: 120037\n"
     ]
    }
   ],
   "source": [
    "min_word_frequency = 59\n",
    "\n",
    "sklearn_bow = True # Otherwise we use Tensorflow BOW.\n",
    "\n",
    "if sklearn_bow:\n",
    "    # Gives 7600 unique words with min frequency 75 and stopwords removed.\n",
    "    # 7797 if we leave stopwords in.\n",
    "\n",
    "    count_vect = sklearn.feature_extraction.text.CountVectorizer(\n",
    "        min_df=min_word_frequency, decode_error='ignore')\n",
    "\n",
    "    # Transform BOW test set.\n",
    "    x_train = count_vect.fit_transform(x_train_text)\n",
    "    x_test = count_vect.transform(x_test_text)\n",
    "    n_words = x_train.shape[1]\n",
    "    max_document_length = n_words\n",
    "\n",
    "else:\n",
    "    # Look here for a tutorial https://medium.com/@ilblackdragon/tensorflow-text-classification-615198df9231\n",
    "    # Gives 8712 unique words with min word frequency of 75\n",
    "    vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(\n",
    "        max_document_length, min_frequency=min_word_frequency)\n",
    "    x_train = numpy.array(list(vocab_processor.fit_transform(x_train_text)))\n",
    "    x_test = numpy.array(list(vocab_processor.transform(x_test_text)))\n",
    "    n_words = len(vocab_processor.vocabulary_)\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_train_text])\n",
    "    \n",
    "print(\"x_train shape: %s, %s\" % x_train.shape)\n",
    "print(\"x_test shape: %s, %s\" % x_test.shape)\n",
    "print(\"Total distinct words: %d\" % n_words)\n",
    "print(\"Number of training rows: %d\" % x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define data nput functions. These have to be done here as the \n",
    "# functions take no arguments. Also the dict labels are specific to \n",
    "# the model.\n",
    "max_document_length = n_words\n",
    "\n",
    "def input_fn():\n",
    "    for batch_input, batch_labels in tf_utils.generate_batch(\n",
    "        batch_size, number_of_batches, max_document_length,\n",
    "                                                    x_train, y_train):\n",
    "        yield {x_data: batch_input, y_target: batch_labels}\n",
    "\n",
    "def eval_input_fn():\n",
    "    for batch_input, batch_labels in tf_utils.generate_batch(\n",
    "        batch_size, number_of_validation_batches, max_document_length,\n",
    "                                                    x_test, y_test):\n",
    "        yield {x_data: batch_input, y_target: batch_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "learning_rate = .01\n",
    "\n",
    "l1_regularization_coef = 0.01\n",
    "l2_regularization_coef = 0.01\n",
    "\n",
    "# if not RMSE then MAE.\n",
    "HUBER = False\n",
    "RMSE = False\n",
    "\n",
    "#Implement this by batch.\n",
    "batch_size = 1024\n",
    "\n",
    "\"\"\"\n",
    "def huber_loss(labels, predictions, delta=1.0):\n",
    " residual = tf.abs(predictions - labels)\n",
    " condition = tf.less(residual, delta)\n",
    " small_res = 0.5 * tf.square(residual)\n",
    " large_res = delta * residual - 0.5 * tf.square(delta)\n",
    " return tf.reduce_mean(tf.where(condition, small_res, large_res))\n",
    "\"\"\"\n",
    "with graph.as_default():\n",
    "\n",
    "    with tf.name_scope(\"data\"):\n",
    "        # Initialize data placeholders\n",
    "        x_data = tf.placeholder(shape=[batch_size, max_document_length], dtype=tf.float32)\n",
    "        y_target = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name=\"labels\")\n",
    "    \"\"\"\n",
    "    # Old nasty tf bag of words code.\n",
    "    with tf.name_scope(\"bag_of_words\"):\n",
    "        with tf.device('/cpu:0'):\n",
    "            identity_mat = tf.diag(tf.ones(shape=[n_words]))\n",
    "            # This is also an embedding_lookup_sparse function that would create a sparse tensor.\n",
    "            x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "            # Collapse across the document length dimension. Leaving only the number of tokens.\n",
    "            bag_of_words = tf.reduce_sum(x_embed, 1)\n",
    "\n",
    "            print(\"Woohoo this looks like my bag of words shape :D %s\" % bag_of_words.shape)\n",
    "    \"\"\"\n",
    "    # Create variables for regression\n",
    "    A = tf.Variable(tf.zeros(shape=[n_words, 1]))\n",
    "    b = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "    # A = tf.Variable(tf.random_normal(shape=[vocab_size, 1], stddev=.05))\n",
    "    # Intercept term. A scalar.\n",
    "    # b = tf.Variable(tf.random_normal(shape=[1], stddev=.05))\n",
    "\n",
    "    # Model output\n",
    "    with tf.device('/gpu:0'):\n",
    "\n",
    "        product = tf.matmul(x_data, A)\n",
    "        model_output = tf.add(product, b, name=\"predictions\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "\n",
    "        # TODO(Max) try root mean square error. Should this be merely mean square error?\n",
    "        if HUBER:\n",
    "            loss = huber_loss(y_target, model_output)\n",
    "        elif RMSE:\n",
    "            loss = tf.sqrt(tf.reduce_mean(tf.pow(tf.subtract(y_target, model_output), 2)))\n",
    "        else:\n",
    "            # Mean Absolute Error.\n",
    "            loss = tf.reduce_mean(tf.abs(tf.subtract(y_target, model_output)))\n",
    "\n",
    "        # If we are using regularization.\n",
    "        if l1_regularization_coef > 0 or l2_regularization_coef > 0:\n",
    "            l1_regularizer = tf.contrib.layers.l1_regularizer(scale=l1_regularization_coef)\n",
    "            l2_regularizer = tf.contrib.layers.l2_regularizer(scale=l2_regularization_coef)\n",
    "\n",
    "            weights = tf.trainable_variables() # all vars of your graph\n",
    "            regularization_penalty = tf.add(tf.contrib.layers.apply_regularization(l1_regularizer, weights),\n",
    "                                             tf.contrib.layers.apply_regularization(l2_regularizer, weights))\n",
    "            loss = loss + regularization_penalty # this loss needs to be minimized\n",
    "\n",
    "    with tf.name_scope(\"reporting\"):\n",
    "        # Converts back to original, salary scale.\n",
    "        error_salary_scale = tf.multiply(tf.subtract(y_target, model_output), train_std)\n",
    "\n",
    "        mean_absolute_error_salary_scale = tf.reduce_mean(\n",
    "            tf.abs(error_salary_scale))\n",
    "\n",
    "        # Log for tensorboard\n",
    "        training_summary = tf.summary.scalar('train_loss', loss)\n",
    "        validation_summary = tf.summary.scalar('validation_loss', loss)\n",
    "        # Add mean absolute errors.\n",
    "        training_mae = tf.summary.scalar('train_mae', mean_absolute_error_salary_scale)\n",
    "        validation_mae = tf.summary.scalar('validation_mae', mean_absolute_error_salary_scale)\n",
    "\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # Declare optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "    # This one seems to work better :D\n",
    "    train_op = tf.contrib.layers.optimize_loss(      \n",
    "     loss, tf.contrib.framework.get_global_step(),      \n",
    "     optimizer='Adam'\n",
    "        , learning_rate=learning_rate, clip_gradients=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of\n",
    "number_of_epochs = 20\n",
    "batches_per_epoch = len(x_train_text)/batch_size\n",
    "number_of_batches = math.ceil(len(x_train_text)/batch_size)\n",
    "number_of_validation_batches = number_of_batches\n",
    "\n",
    "logs_dir = \"logs/bagofwords\"\n",
    "\n",
    "checkpoint_frequency = 500\n",
    "\n",
    "reporting_frequency = 3\n",
    "\n",
    "total_loss = 0\n",
    "validation_loss = 0\n",
    "validation_batch_average_window = 100\n",
    "\n",
    "ckpt = None\n",
    "ckpt = tf.train.get_checkpoint_state(logs_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object input_fn at 0x7f4a9ca09a98>\n",
      "Batch 1 Enqueue Duration: 7.1514\n",
      "<generator object input_fn at 0x7f4a9e63a5c8>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-eace65db0800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mthing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menqueue_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch %s Enqueue Duration: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TF Queue Logic\n",
    "\"\"\"\n",
    "QUEUE_LIMIT = 500000\n",
    "\n",
    "# Try me out\n",
    "#batch_size = 256\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    queue = tf.RandomShuffleQueue(\n",
    "        capacity=QUEUE_LIMIT, min_after_dequeue=batch_size,\n",
    "        dtypes=[tf.float32, tf.float32],\n",
    "        shapes = [(n_words,), (1,)],\n",
    "        seed=1999)\n",
    "\n",
    "    with tf.name_scope(\"preprocess_data\"):\n",
    "        with tf.device('/cpu:0'):\n",
    "\n",
    "            # Initialize data placeholders\n",
    "            x_data = tf.placeholder(shape=[batch_size, max_document_length], dtype=tf.int32)\n",
    "            y_target = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name=\"labels\")\n",
    "            #with tf.device('/cpu:0'):\n",
    "            identity_mat = tf.diag(tf.ones(shape=[vocab_size]))\n",
    "            # This is also an embedding_lookup_sparse function that would create a sparse tensor.\n",
    "            x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "            # Collapse across the document length dimension. Leaving only the number of tokens.\n",
    "            example = tf.reduce_sum(x_embed, 1)\n",
    "\n",
    "            enqueue_op = queue.enqueue_many((example, y_target))\n",
    "\n",
    "        # Dequeue our data. Use dequeue_many(batch_size) later.\n",
    "        dequeue_op = queue.dequeue_many(batch_size)\n",
    "\n",
    "# Create 8 threads.\n",
    "#qr = tf.train.QueueRunner(queue, [enqueue_op] * 8)\n",
    "# Launch the graph.\n",
    "with tf.Session(graph=graph) as session:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "\n",
    "#sess = tf.Session()\n",
    "    #enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in range(10): # do to 100 iterations\n",
    "        #if coord.should_stop():\n",
    "        #    break\n",
    "        #print(feed_dict)\n",
    "        start_time = time.time()\n",
    "        feed_dict = input_fn()\n",
    "        #print(feed_dict)\n",
    "        thing = session.run([enqueue_op], feed_dict=next(feed_dict))\n",
    "        duration = time.time() - start_time\n",
    "        print(\"Batch %s Enqueue Duration: %.4f\" % (step +1, duration))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    #enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in range(10): # do to 100 iterations\n",
    "        #if coord.should_stop():\n",
    "        #    break\n",
    "        #print(feed_dict)\n",
    "        data, label = session.run([dequeue_op])\n",
    "        print(data)\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore from model!\n",
      "INFO:tensorflow:Restoring parameters from logs/bagofwords/2017-06-27-20-46-01-38319\n",
      "Epoch: 0 Iteration: 3 : Loss: 0.7819 (0.021 sec)\n",
      "Epoch: 0 Iteration: 6 : Loss: 0.7264 (0.016 sec)\n",
      "Epoch: 0 Iteration: 9 : Loss: 0.7760 (0.017 sec)\n",
      "Epoch: 0 Iteration: 12 : Loss: 0.7690 (0.017 sec)\n",
      "Epoch: 0 Iteration: 15 : Loss: 0.7471 (0.016 sec)\n",
      "Epoch: 0 Iteration: 18 : Loss: 0.7757 (0.017 sec)\n",
      "Epoch: 0 Iteration: 21 : Loss: 0.7512 (0.017 sec)\n",
      "Epoch: 0 Iteration: 24 : Loss: 0.6969 (0.017 sec)\n",
      "Epoch: 0 Iteration: 27 : Loss: 0.7330 (0.016 sec)\n",
      "Epoch: 0 Iteration: 30 : Loss: 0.7528 (0.017 sec)\n",
      "Epoch: 0 Iteration: 33 : Loss: 0.7254 (0.017 sec)\n",
      "Epoch: 0 Iteration: 36 : Loss: 0.6847 (0.016 sec)\n",
      "Epoch: 0 Iteration: 39 : Loss: 0.7290 (0.017 sec)\n",
      "Epoch: 0 Iteration: 42 : Loss: 0.7279 (0.017 sec)\n",
      "Epoch: 0 Iteration: 45 : Loss: 0.7028 (0.017 sec)\n",
      "Epoch: 0 Iteration: 48 : Loss: 0.7574 (0.016 sec)\n",
      "Epoch: 0 Iteration: 51 : Loss: 0.7123 (0.017 sec)\n",
      "Epoch: 0 Iteration: 54 : Loss: 0.7057 (0.017 sec)\n",
      "Epoch: 0 Iteration: 57 : Loss: 0.7093 (0.017 sec)\n",
      "Epoch: 0 Iteration: 60 : Loss: 0.7187 (0.017 sec)\n",
      "Epoch: 0 Iteration: 63 : Loss: 0.7157 (0.017 sec)\n",
      "Epoch: 0 Iteration: 66 : Loss: 0.7455 (0.017 sec)\n",
      "Epoch: 0 Iteration: 69 : Loss: 0.7367 (0.018 sec)\n",
      "Epoch: 0 Iteration: 72 : Loss: 0.7307 (0.017 sec)\n",
      "Epoch: 0 Iteration: 75 : Loss: 0.7235 (0.017 sec)\n",
      "Epoch: 0 Iteration: 78 : Loss: 0.7326 (0.017 sec)\n",
      "Epoch: 0 Iteration: 81 : Loss: 0.7365 (0.016 sec)\n",
      "Epoch: 0 Iteration: 84 : Loss: 0.7600 (0.018 sec)\n",
      "Epoch: 0 Iteration: 87 : Loss: 0.7467 (0.017 sec)\n",
      "Epoch: 0 Iteration: 90 : Loss: 0.7633 (0.017 sec)\n",
      "Epoch: 0 Iteration: 93 : Loss: 0.7559 (0.017 sec)\n",
      "Epoch: 0 Iteration: 96 : Loss: 0.7021 (0.017 sec)\n",
      "Epoch: 0 Iteration: 99 : Loss: 0.6988 (0.018 sec)\n",
      "Epoch: 0 Iteration: 102 : Loss: 0.7366 (0.021 sec)\n",
      "Epoch: 0 Iteration: 105 : Loss: 0.7282 (0.018 sec)\n",
      "Epoch: 0 Iteration: 108 : Loss: 0.7278 (0.019 sec)\n",
      "Epoch: 0 Iteration: 111 : Loss: 0.7829 (0.018 sec)\n",
      "Epoch: 0 Iteration: 114 : Loss: 0.7456 (0.018 sec)\n",
      "Epoch: 0 Iteration: 117 : Loss: 0.7226 (0.017 sec)\n",
      "Saving at epoch 0 step: 118\n",
      "Epoch: 1 Iteration: 2 : Loss: 0.7368 (0.018 sec)\n",
      "Epoch: 1 Iteration: 5 : Loss: 0.7181 (0.020 sec)\n",
      "Epoch: 1 Iteration: 8 : Loss: 0.7205 (0.017 sec)\n",
      "Epoch: 1 Iteration: 11 : Loss: 0.7412 (0.017 sec)\n",
      "Epoch: 1 Iteration: 14 : Loss: 0.7235 (0.017 sec)\n",
      "Epoch: 1 Iteration: 17 : Loss: 0.7324 (0.017 sec)\n",
      "Epoch: 1 Iteration: 20 : Loss: 0.7181 (0.017 sec)\n",
      "Epoch: 1 Iteration: 23 : Loss: 0.7382 (0.018 sec)\n",
      "Epoch: 1 Iteration: 26 : Loss: 0.7218 (0.017 sec)\n",
      "Epoch: 1 Iteration: 29 : Loss: 0.7138 (0.017 sec)\n",
      "Epoch: 1 Iteration: 32 : Loss: 0.7516 (0.020 sec)\n",
      "Epoch: 1 Iteration: 35 : Loss: 0.7458 (0.018 sec)\n",
      "Epoch: 1 Iteration: 38 : Loss: 0.7561 (0.021 sec)\n",
      "Epoch: 1 Iteration: 41 : Loss: 0.8204 (0.018 sec)\n",
      "Epoch: 1 Iteration: 44 : Loss: 0.7615 (0.021 sec)\n",
      "Epoch: 1 Iteration: 47 : Loss: 0.7785 (0.017 sec)\n",
      "Epoch: 1 Iteration: 50 : Loss: 0.7361 (0.017 sec)\n",
      "Epoch: 1 Iteration: 53 : Loss: 0.7286 (0.018 sec)\n",
      "Epoch: 1 Iteration: 56 : Loss: 0.7254 (0.018 sec)\n",
      "Epoch: 1 Iteration: 59 : Loss: 0.7265 (0.019 sec)\n",
      "Epoch: 1 Iteration: 62 : Loss: 0.7320 (0.017 sec)\n",
      "Epoch: 1 Iteration: 65 : Loss: 0.7340 (0.019 sec)\n",
      "Epoch: 1 Iteration: 68 : Loss: 0.7010 (0.017 sec)\n",
      "Epoch: 1 Iteration: 71 : Loss: 0.6873 (0.020 sec)\n",
      "Epoch: 1 Iteration: 74 : Loss: 0.7083 (0.017 sec)\n",
      "Epoch: 1 Iteration: 77 : Loss: 0.7448 (0.017 sec)\n",
      "Epoch: 1 Iteration: 80 : Loss: 0.7287 (0.019 sec)\n",
      "Epoch: 1 Iteration: 83 : Loss: 0.7199 (0.018 sec)\n",
      "Epoch: 1 Iteration: 86 : Loss: 0.6915 (0.017 sec)\n",
      "Epoch: 1 Iteration: 89 : Loss: 0.7245 (0.017 sec)\n",
      "Epoch: 1 Iteration: 92 : Loss: 0.7481 (0.017 sec)\n",
      "Epoch: 1 Iteration: 95 : Loss: 0.7410 (0.019 sec)\n",
      "Epoch: 1 Iteration: 98 : Loss: 0.7703 (0.021 sec)\n",
      "Epoch: 1 Iteration: 101 : Loss: 0.7543 (0.018 sec)\n",
      "Epoch: 1 Iteration: 104 : Loss: 0.7129 (0.020 sec)\n",
      "Epoch: 1 Iteration: 107 : Loss: 0.7576 (0.018 sec)\n",
      "Epoch: 1 Iteration: 110 : Loss: 0.7249 (0.020 sec)\n",
      "Epoch: 1 Iteration: 113 : Loss: 0.7473 (0.018 sec)\n",
      "Epoch: 1 Iteration: 116 : Loss: 0.7447 (0.021 sec)\n",
      "Epoch: 2 Iteration: 1 : Loss: 0.7111 (0.020 sec)\n",
      "Epoch: 2 Iteration: 4 : Loss: 0.7421 (0.025 sec)\n",
      "Epoch: 2 Iteration: 7 : Loss: 0.7722 (0.022 sec)\n",
      "Epoch: 2 Iteration: 10 : Loss: 0.7461 (0.022 sec)\n",
      "Epoch: 2 Iteration: 13 : Loss: 0.7099 (0.019 sec)\n",
      "Epoch: 2 Iteration: 16 : Loss: 0.7350 (0.018 sec)\n",
      "Epoch: 2 Iteration: 19 : Loss: 0.7355 (0.017 sec)\n",
      "Epoch: 2 Iteration: 22 : Loss: 0.7488 (0.019 sec)\n",
      "Epoch: 2 Iteration: 25 : Loss: 0.7597 (0.018 sec)\n",
      "Epoch: 2 Iteration: 28 : Loss: 0.7368 (0.018 sec)\n",
      "Epoch: 2 Iteration: 31 : Loss: 0.7438 (0.018 sec)\n",
      "Epoch: 2 Iteration: 34 : Loss: 0.7134 (0.022 sec)\n",
      "Epoch: 2 Iteration: 37 : Loss: 0.7349 (0.019 sec)\n",
      "Epoch: 2 Iteration: 40 : Loss: 0.7388 (0.018 sec)\n",
      "Epoch: 2 Iteration: 43 : Loss: 0.7693 (0.020 sec)\n",
      "Epoch: 2 Iteration: 46 : Loss: 0.7481 (0.018 sec)\n",
      "Epoch: 2 Iteration: 49 : Loss: 0.7441 (0.017 sec)\n",
      "Epoch: 2 Iteration: 52 : Loss: 0.7715 (0.020 sec)\n",
      "Epoch: 2 Iteration: 55 : Loss: 0.7225 (0.022 sec)\n",
      "Epoch: 2 Iteration: 58 : Loss: 0.7759 (0.021 sec)\n",
      "Epoch: 2 Iteration: 61 : Loss: 0.7370 (0.017 sec)\n",
      "Epoch: 2 Iteration: 64 : Loss: 0.7332 (0.017 sec)\n",
      "Epoch: 2 Iteration: 67 : Loss: 0.7382 (0.019 sec)\n",
      "Epoch: 2 Iteration: 70 : Loss: 0.7363 (0.017 sec)\n",
      "Epoch: 2 Iteration: 73 : Loss: 0.7871 (0.017 sec)\n",
      "Epoch: 2 Iteration: 76 : Loss: 0.7677 (0.020 sec)\n",
      "Epoch: 2 Iteration: 79 : Loss: 0.7049 (0.017 sec)\n",
      "Epoch: 2 Iteration: 82 : Loss: 0.7411 (0.022 sec)\n",
      "Epoch: 2 Iteration: 85 : Loss: 0.7353 (0.020 sec)\n",
      "Epoch: 2 Iteration: 88 : Loss: 0.7065 (0.017 sec)\n",
      "Epoch: 2 Iteration: 91 : Loss: 0.7151 (0.019 sec)\n",
      "Epoch: 2 Iteration: 94 : Loss: 0.7524 (0.018 sec)\n",
      "Epoch: 2 Iteration: 97 : Loss: 0.7185 (0.017 sec)\n",
      "Epoch: 2 Iteration: 100 : Loss: 0.7234 (0.019 sec)\n",
      "Epoch: 2 Iteration: 103 : Loss: 0.7449 (0.017 sec)\n",
      "Epoch: 2 Iteration: 106 : Loss: 0.7476 (0.021 sec)\n",
      "Epoch: 2 Iteration: 109 : Loss: 0.7792 (0.020 sec)\n",
      "Epoch: 2 Iteration: 112 : Loss: 0.6764 (0.022 sec)\n",
      "Epoch: 2 Iteration: 115 : Loss: 0.7674 (0.020 sec)\n",
      "Epoch: 2 Iteration: 118 : Loss: 0.7350 (0.023 sec)\n",
      "Epoch: 3 Iteration: 3 : Loss: 0.7404 (0.018 sec)\n",
      "Epoch: 3 Iteration: 6 : Loss: 0.7625 (0.017 sec)\n",
      "Epoch: 3 Iteration: 9 : Loss: 0.7046 (0.019 sec)\n",
      "Epoch: 3 Iteration: 12 : Loss: 0.7496 (0.017 sec)\n",
      "Epoch: 3 Iteration: 15 : Loss: 0.7352 (0.017 sec)\n",
      "Epoch: 3 Iteration: 18 : Loss: 0.6850 (0.017 sec)\n",
      "Epoch: 3 Iteration: 21 : Loss: 0.7436 (0.020 sec)\n",
      "Epoch: 3 Iteration: 24 : Loss: 0.7440 (0.021 sec)\n",
      "Epoch: 3 Iteration: 27 : Loss: 0.7458 (0.017 sec)\n",
      "Epoch: 3 Iteration: 30 : Loss: 0.7468 (0.021 sec)\n",
      "Epoch: 3 Iteration: 33 : Loss: 0.7927 (0.023 sec)\n",
      "Epoch: 3 Iteration: 36 : Loss: 0.7443 (0.017 sec)\n",
      "Epoch: 3 Iteration: 39 : Loss: 0.7478 (0.017 sec)\n",
      "Epoch: 3 Iteration: 42 : Loss: 0.7203 (0.017 sec)\n",
      "Epoch: 3 Iteration: 45 : Loss: 0.7380 (0.022 sec)\n",
      "Epoch: 3 Iteration: 48 : Loss: 0.7277 (0.019 sec)\n",
      "Epoch: 3 Iteration: 51 : Loss: 0.7574 (0.019 sec)\n",
      "Epoch: 3 Iteration: 54 : Loss: 0.7122 (0.017 sec)\n",
      "Epoch: 3 Iteration: 57 : Loss: 0.7258 (0.017 sec)\n",
      "Epoch: 3 Iteration: 60 : Loss: 0.7409 (0.019 sec)\n",
      "Epoch: 3 Iteration: 63 : Loss: 0.7462 (0.017 sec)\n",
      "Epoch: 3 Iteration: 66 : Loss: 0.7306 (0.017 sec)\n",
      "Epoch: 3 Iteration: 69 : Loss: 0.7661 (0.020 sec)\n",
      "Epoch: 3 Iteration: 72 : Loss: 0.7175 (0.020 sec)\n",
      "Epoch: 3 Iteration: 75 : Loss: 0.7295 (0.017 sec)\n",
      "Epoch: 3 Iteration: 78 : Loss: 0.7327 (0.018 sec)\n",
      "Epoch: 3 Iteration: 81 : Loss: 0.7573 (0.021 sec)\n",
      "Epoch: 3 Iteration: 84 : Loss: 0.7703 (0.017 sec)\n",
      "Epoch: 3 Iteration: 87 : Loss: 0.7517 (0.018 sec)\n",
      "Epoch: 3 Iteration: 90 : Loss: 0.7362 (0.017 sec)\n",
      "Epoch: 3 Iteration: 93 : Loss: 0.7274 (0.017 sec)\n",
      "Epoch: 3 Iteration: 96 : Loss: 0.7290 (0.017 sec)\n",
      "Epoch: 3 Iteration: 99 : Loss: 0.7355 (0.017 sec)\n",
      "Epoch: 3 Iteration: 102 : Loss: 0.7285 (0.017 sec)\n",
      "Epoch: 3 Iteration: 105 : Loss: 0.7212 (0.021 sec)\n",
      "Epoch: 3 Iteration: 108 : Loss: 0.7238 (0.019 sec)\n",
      "Epoch: 3 Iteration: 111 : Loss: 0.7142 (0.022 sec)\n",
      "Epoch: 3 Iteration: 114 : Loss: 0.7314 (0.017 sec)\n",
      "Epoch: 3 Iteration: 117 : Loss: 0.7340 (0.020 sec)\n",
      "Epoch: 4 Iteration: 2 : Loss: 0.7240 (0.022 sec)\n",
      "Epoch: 4 Iteration: 5 : Loss: 0.7432 (0.020 sec)\n",
      "Epoch: 4 Iteration: 8 : Loss: 0.7282 (0.017 sec)\n",
      "Epoch: 4 Iteration: 11 : Loss: 0.7370 (0.017 sec)\n",
      "Epoch: 4 Iteration: 14 : Loss: 0.7377 (0.017 sec)\n",
      "Epoch: 4 Iteration: 17 : Loss: 0.7157 (0.017 sec)\n",
      "Epoch: 4 Iteration: 20 : Loss: 0.7580 (0.016 sec)\n",
      "Epoch: 4 Iteration: 23 : Loss: 0.7467 (0.017 sec)\n",
      "Epoch: 4 Iteration: 26 : Loss: 0.6986 (0.018 sec)\n",
      "Saving at epoch 4 step: 28\n",
      "Epoch: 4 Iteration: 29 : Loss: 0.7213 (0.017 sec)\n",
      "Epoch: 4 Iteration: 32 : Loss: 0.7270 (0.023 sec)\n",
      "Epoch: 4 Iteration: 35 : Loss: 0.7292 (0.017 sec)\n",
      "Epoch: 4 Iteration: 38 : Loss: 0.7376 (0.019 sec)\n",
      "Epoch: 4 Iteration: 41 : Loss: 0.7183 (0.027 sec)\n",
      "Epoch: 4 Iteration: 44 : Loss: 0.7414 (0.022 sec)\n",
      "Epoch: 4 Iteration: 47 : Loss: 0.7408 (0.020 sec)\n",
      "Epoch: 4 Iteration: 50 : Loss: 0.7519 (0.026 sec)\n",
      "Epoch: 4 Iteration: 53 : Loss: 0.7498 (0.018 sec)\n",
      "Epoch: 4 Iteration: 56 : Loss: 0.7445 (0.017 sec)\n",
      "Epoch: 4 Iteration: 59 : Loss: 0.7151 (0.020 sec)\n",
      "Epoch: 4 Iteration: 62 : Loss: 0.7455 (0.017 sec)\n",
      "Epoch: 4 Iteration: 65 : Loss: 0.7498 (0.020 sec)\n",
      "Epoch: 4 Iteration: 68 : Loss: 0.7432 (0.017 sec)\n",
      "Epoch: 4 Iteration: 71 : Loss: 0.7434 (0.022 sec)\n",
      "Epoch: 4 Iteration: 74 : Loss: 0.7437 (0.023 sec)\n",
      "Epoch: 4 Iteration: 77 : Loss: 0.7413 (0.017 sec)\n",
      "Epoch: 4 Iteration: 80 : Loss: 0.7663 (0.019 sec)\n",
      "Epoch: 4 Iteration: 83 : Loss: 0.7529 (0.019 sec)\n",
      "Epoch: 4 Iteration: 86 : Loss: 0.7466 (0.020 sec)\n",
      "Epoch: 4 Iteration: 89 : Loss: 0.7490 (0.024 sec)\n",
      "Epoch: 4 Iteration: 92 : Loss: 0.7615 (0.017 sec)\n",
      "Epoch: 4 Iteration: 95 : Loss: 0.7216 (0.017 sec)\n",
      "Epoch: 4 Iteration: 98 : Loss: 0.7318 (0.017 sec)\n",
      "Epoch: 4 Iteration: 101 : Loss: 0.7263 (0.019 sec)\n",
      "Epoch: 4 Iteration: 104 : Loss: 0.7295 (0.024 sec)\n",
      "Epoch: 4 Iteration: 107 : Loss: 0.7483 (0.018 sec)\n",
      "Epoch: 4 Iteration: 110 : Loss: 0.7099 (0.022 sec)\n",
      "Epoch: 4 Iteration: 113 : Loss: 0.7195 (0.019 sec)\n",
      "Epoch: 4 Iteration: 116 : Loss: 0.7211 (0.020 sec)\n",
      "Epoch: 5 Iteration: 1 : Loss: 0.7576 (0.018 sec)\n",
      "Epoch: 5 Iteration: 4 : Loss: 0.7170 (0.017 sec)\n",
      "Epoch: 5 Iteration: 7 : Loss: 0.7451 (0.023 sec)\n",
      "Epoch: 5 Iteration: 10 : Loss: 0.7254 (0.021 sec)\n",
      "Epoch: 5 Iteration: 13 : Loss: 0.7770 (0.018 sec)\n",
      "Epoch: 5 Iteration: 16 : Loss: 0.6968 (0.017 sec)\n",
      "Epoch: 5 Iteration: 19 : Loss: 0.7098 (0.019 sec)\n",
      "Epoch: 5 Iteration: 22 : Loss: 0.7068 (0.017 sec)\n",
      "Epoch: 5 Iteration: 25 : Loss: 0.7315 (0.017 sec)\n",
      "Epoch: 5 Iteration: 28 : Loss: 0.7277 (0.020 sec)\n",
      "Epoch: 5 Iteration: 31 : Loss: 0.7858 (0.019 sec)\n",
      "Epoch: 5 Iteration: 34 : Loss: 0.7347 (0.021 sec)\n",
      "Epoch: 5 Iteration: 37 : Loss: 0.7521 (0.019 sec)\n",
      "Epoch: 5 Iteration: 40 : Loss: 0.7269 (0.019 sec)\n",
      "Epoch: 5 Iteration: 43 : Loss: 0.7552 (0.020 sec)\n",
      "Epoch: 5 Iteration: 46 : Loss: 0.7659 (0.018 sec)\n",
      "Epoch: 5 Iteration: 49 : Loss: 0.7120 (0.017 sec)\n",
      "Epoch: 5 Iteration: 52 : Loss: 0.7780 (0.017 sec)\n",
      "Epoch: 5 Iteration: 55 : Loss: 0.7003 (0.017 sec)\n",
      "Epoch: 5 Iteration: 58 : Loss: 0.7160 (0.019 sec)\n",
      "Epoch: 5 Iteration: 61 : Loss: 0.7452 (0.019 sec)\n",
      "Epoch: 5 Iteration: 64 : Loss: 0.7393 (0.020 sec)\n",
      "Epoch: 5 Iteration: 67 : Loss: 0.7345 (0.019 sec)\n",
      "Epoch: 5 Iteration: 70 : Loss: 0.7447 (0.020 sec)\n",
      "Epoch: 5 Iteration: 73 : Loss: 0.7242 (0.019 sec)\n",
      "Epoch: 5 Iteration: 76 : Loss: 0.7281 (0.019 sec)\n",
      "Epoch: 5 Iteration: 79 : Loss: 0.7389 (0.020 sec)\n",
      "Epoch: 5 Iteration: 82 : Loss: 0.7328 (0.018 sec)\n",
      "Epoch: 5 Iteration: 85 : Loss: 0.7399 (0.018 sec)\n",
      "Epoch: 5 Iteration: 88 : Loss: 0.7407 (0.018 sec)\n",
      "Epoch: 5 Iteration: 91 : Loss: 0.7235 (0.017 sec)\n",
      "Epoch: 5 Iteration: 94 : Loss: 0.7195 (0.018 sec)\n",
      "Epoch: 5 Iteration: 97 : Loss: 0.6999 (0.017 sec)\n",
      "Epoch: 5 Iteration: 100 : Loss: 0.7301 (0.021 sec)\n",
      "Epoch: 5 Iteration: 103 : Loss: 0.7420 (0.018 sec)\n",
      "Epoch: 5 Iteration: 106 : Loss: 0.7471 (0.018 sec)\n",
      "Epoch: 5 Iteration: 109 : Loss: 0.7130 (0.022 sec)\n",
      "Epoch: 5 Iteration: 112 : Loss: 0.7493 (0.018 sec)\n",
      "Epoch: 5 Iteration: 115 : Loss: 0.7686 (0.017 sec)\n",
      "Epoch: 5 Iteration: 118 : Loss: 0.7628 (0.018 sec)\n",
      "Epoch: 6 Iteration: 3 : Loss: 0.7571 (0.017 sec)\n",
      "Epoch: 6 Iteration: 6 : Loss: 0.7626 (0.020 sec)\n",
      "Epoch: 6 Iteration: 9 : Loss: 0.7622 (0.023 sec)\n",
      "Epoch: 6 Iteration: 12 : Loss: 0.7602 (0.021 sec)\n",
      "Epoch: 6 Iteration: 15 : Loss: 0.7433 (0.020 sec)\n",
      "Epoch: 6 Iteration: 18 : Loss: 0.7138 (0.017 sec)\n",
      "Epoch: 6 Iteration: 21 : Loss: 0.7670 (0.024 sec)\n",
      "Epoch: 6 Iteration: 24 : Loss: 0.7200 (0.020 sec)\n",
      "Epoch: 6 Iteration: 27 : Loss: 0.7527 (0.018 sec)\n",
      "Epoch: 6 Iteration: 30 : Loss: 0.7022 (0.020 sec)\n",
      "Epoch: 6 Iteration: 33 : Loss: 0.7180 (0.022 sec)\n",
      "Epoch: 6 Iteration: 36 : Loss: 0.6973 (0.021 sec)\n",
      "Epoch: 6 Iteration: 39 : Loss: 0.6926 (0.019 sec)\n",
      "Epoch: 6 Iteration: 42 : Loss: 0.7396 (0.022 sec)\n",
      "Epoch: 6 Iteration: 45 : Loss: 0.7565 (0.021 sec)\n",
      "Epoch: 6 Iteration: 48 : Loss: 0.7795 (0.021 sec)\n",
      "Epoch: 6 Iteration: 51 : Loss: 0.7244 (0.019 sec)\n",
      "Epoch: 6 Iteration: 54 : Loss: 0.7576 (0.023 sec)\n",
      "Epoch: 6 Iteration: 57 : Loss: 0.7244 (0.018 sec)\n",
      "Epoch: 6 Iteration: 60 : Loss: 0.6936 (0.017 sec)\n",
      "Epoch: 6 Iteration: 63 : Loss: 0.7371 (0.017 sec)\n",
      "Epoch: 6 Iteration: 66 : Loss: 0.7485 (0.022 sec)\n",
      "Epoch: 6 Iteration: 69 : Loss: 0.6949 (0.020 sec)\n",
      "Epoch: 6 Iteration: 72 : Loss: 0.7584 (0.020 sec)\n",
      "Epoch: 6 Iteration: 75 : Loss: 0.7051 (0.019 sec)\n",
      "Epoch: 6 Iteration: 78 : Loss: 0.7288 (0.023 sec)\n",
      "Epoch: 6 Iteration: 81 : Loss: 0.7269 (0.019 sec)\n",
      "Epoch: 6 Iteration: 84 : Loss: 0.7278 (0.018 sec)\n",
      "Epoch: 6 Iteration: 87 : Loss: 0.7285 (0.021 sec)\n",
      "Epoch: 6 Iteration: 90 : Loss: 0.7257 (0.024 sec)\n",
      "Epoch: 6 Iteration: 93 : Loss: 0.7071 (0.020 sec)\n",
      "Epoch: 6 Iteration: 96 : Loss: 0.7194 (0.017 sec)\n",
      "Epoch: 6 Iteration: 99 : Loss: 0.7004 (0.018 sec)\n",
      "Epoch: 6 Iteration: 102 : Loss: 0.7486 (0.021 sec)\n",
      "Epoch: 6 Iteration: 105 : Loss: 0.7607 (0.019 sec)\n",
      "Epoch: 6 Iteration: 108 : Loss: 0.7604 (0.021 sec)\n",
      "Epoch: 6 Iteration: 111 : Loss: 0.7497 (0.017 sec)\n",
      "Epoch: 6 Iteration: 114 : Loss: 0.7286 (0.018 sec)\n",
      "Epoch: 6 Iteration: 117 : Loss: 0.7450 (0.022 sec)\n",
      "Epoch: 7 Iteration: 2 : Loss: 0.7417 (0.020 sec)\n",
      "Epoch: 7 Iteration: 5 : Loss: 0.7269 (0.022 sec)\n",
      "Epoch: 7 Iteration: 8 : Loss: 0.7132 (0.019 sec)\n",
      "Epoch: 7 Iteration: 11 : Loss: 0.7395 (0.024 sec)\n",
      "Epoch: 7 Iteration: 14 : Loss: 0.7294 (0.023 sec)\n",
      "Epoch: 7 Iteration: 17 : Loss: 0.7161 (0.017 sec)\n",
      "Epoch: 7 Iteration: 20 : Loss: 0.7721 (0.017 sec)\n",
      "Epoch: 7 Iteration: 23 : Loss: 0.7197 (0.017 sec)\n",
      "Epoch: 7 Iteration: 26 : Loss: 0.7036 (0.022 sec)\n",
      "Epoch: 7 Iteration: 29 : Loss: 0.7465 (0.021 sec)\n",
      "Epoch: 7 Iteration: 32 : Loss: 0.7547 (0.026 sec)\n",
      "Epoch: 7 Iteration: 35 : Loss: 0.7217 (0.017 sec)\n",
      "Epoch: 7 Iteration: 38 : Loss: 0.7131 (0.017 sec)\n",
      "Epoch: 7 Iteration: 41 : Loss: 0.7264 (0.017 sec)\n",
      "Epoch: 7 Iteration: 44 : Loss: 0.7526 (0.020 sec)\n",
      "Epoch: 7 Iteration: 47 : Loss: 0.7468 (0.019 sec)\n",
      "Epoch: 7 Iteration: 50 : Loss: 0.7541 (0.018 sec)\n",
      "Epoch: 7 Iteration: 53 : Loss: 0.7458 (0.017 sec)\n",
      "Epoch: 7 Iteration: 56 : Loss: 0.7591 (0.017 sec)\n",
      "Epoch: 7 Iteration: 59 : Loss: 0.7331 (0.018 sec)\n",
      "Epoch: 7 Iteration: 62 : Loss: 0.6858 (0.017 sec)\n",
      "Epoch: 7 Iteration: 65 : Loss: 0.7241 (0.019 sec)\n",
      "Epoch: 7 Iteration: 68 : Loss: 0.7364 (0.017 sec)\n",
      "Epoch: 7 Iteration: 71 : Loss: 0.7236 (0.017 sec)\n",
      "Epoch: 7 Iteration: 74 : Loss: 0.7429 (0.017 sec)\n",
      "Epoch: 7 Iteration: 77 : Loss: 0.7294 (0.017 sec)\n",
      "Epoch: 7 Iteration: 80 : Loss: 0.7154 (0.017 sec)\n",
      "Epoch: 7 Iteration: 83 : Loss: 0.7159 (0.017 sec)\n",
      "Epoch: 7 Iteration: 86 : Loss: 0.7426 (0.017 sec)\n",
      "Epoch: 7 Iteration: 89 : Loss: 0.7280 (0.017 sec)\n",
      "Epoch: 7 Iteration: 92 : Loss: 0.7473 (0.016 sec)\n",
      "Epoch: 7 Iteration: 95 : Loss: 0.7631 (0.017 sec)\n",
      "Epoch: 7 Iteration: 98 : Loss: 0.7301 (0.021 sec)\n",
      "Epoch: 7 Iteration: 101 : Loss: 0.7244 (0.020 sec)\n",
      "Epoch: 7 Iteration: 104 : Loss: 0.7144 (0.019 sec)\n",
      "Epoch: 7 Iteration: 107 : Loss: 0.7662 (0.018 sec)\n",
      "Epoch: 7 Iteration: 110 : Loss: 0.7385 (0.019 sec)\n",
      "Epoch: 7 Iteration: 113 : Loss: 0.7485 (0.020 sec)\n",
      "Epoch: 7 Iteration: 116 : Loss: 0.7591 (0.021 sec)\n",
      "Epoch: 8 Iteration: 1 : Loss: 0.7423 (0.017 sec)\n",
      "Epoch: 8 Iteration: 4 : Loss: 0.7714 (0.018 sec)\n",
      "Epoch: 8 Iteration: 7 : Loss: 0.7261 (0.018 sec)\n",
      "Epoch: 8 Iteration: 10 : Loss: 0.7510 (0.017 sec)\n",
      "Epoch: 8 Iteration: 13 : Loss: 0.7103 (0.017 sec)\n",
      "Epoch: 8 Iteration: 16 : Loss: 0.7106 (0.017 sec)\n",
      "Epoch: 8 Iteration: 19 : Loss: 0.6848 (0.017 sec)\n",
      "Epoch: 8 Iteration: 22 : Loss: 0.7088 (0.017 sec)\n",
      "Epoch: 8 Iteration: 25 : Loss: 0.7249 (0.017 sec)\n",
      "Epoch: 8 Iteration: 28 : Loss: 0.7038 (0.017 sec)\n",
      "Epoch: 8 Iteration: 31 : Loss: 0.6818 (0.018 sec)\n",
      "Epoch: 8 Iteration: 34 : Loss: 0.6464 (0.018 sec)\n",
      "Epoch: 8 Iteration: 37 : Loss: 0.6869 (0.021 sec)\n",
      "Epoch: 8 Iteration: 40 : Loss: 0.6970 (0.017 sec)\n",
      "Epoch: 8 Iteration: 43 : Loss: 0.6960 (0.017 sec)\n",
      "Epoch: 8 Iteration: 46 : Loss: 0.7227 (0.017 sec)\n",
      "Epoch: 8 Iteration: 49 : Loss: 0.7128 (0.017 sec)\n",
      "Epoch: 8 Iteration: 52 : Loss: 0.7086 (0.017 sec)\n",
      "Epoch: 8 Iteration: 55 : Loss: 0.7253 (0.018 sec)\n",
      "Saving at epoch 8 step: 56\n",
      "Epoch: 8 Iteration: 58 : Loss: 0.7364 (0.018 sec)\n",
      "Epoch: 8 Iteration: 61 : Loss: 0.7376 (0.020 sec)\n",
      "Epoch: 8 Iteration: 64 : Loss: 0.6573 (0.018 sec)\n",
      "Epoch: 8 Iteration: 67 : Loss: 0.7546 (0.017 sec)\n",
      "Epoch: 8 Iteration: 70 : Loss: 0.7157 (0.017 sec)\n",
      "Epoch: 8 Iteration: 73 : Loss: 0.7263 (0.017 sec)\n",
      "Epoch: 8 Iteration: 76 : Loss: 0.7073 (0.017 sec)\n",
      "Epoch: 8 Iteration: 79 : Loss: 0.7765 (0.017 sec)\n",
      "Epoch: 8 Iteration: 82 : Loss: 0.7505 (0.027 sec)\n",
      "Epoch: 8 Iteration: 85 : Loss: 0.7189 (0.017 sec)\n",
      "Epoch: 8 Iteration: 88 : Loss: 0.7567 (0.019 sec)\n",
      "Epoch: 8 Iteration: 91 : Loss: 0.7445 (0.017 sec)\n",
      "Epoch: 8 Iteration: 94 : Loss: 0.7211 (0.020 sec)\n",
      "Epoch: 8 Iteration: 97 : Loss: 0.7297 (0.018 sec)\n",
      "Epoch: 8 Iteration: 100 : Loss: 0.7287 (0.019 sec)\n",
      "Epoch: 8 Iteration: 103 : Loss: 0.7103 (0.019 sec)\n",
      "Epoch: 8 Iteration: 106 : Loss: 0.7448 (0.021 sec)\n",
      "Epoch: 8 Iteration: 109 : Loss: 0.7340 (0.017 sec)\n",
      "Epoch: 8 Iteration: 112 : Loss: 0.7683 (0.019 sec)\n",
      "Epoch: 8 Iteration: 115 : Loss: 0.7482 (0.017 sec)\n",
      "Epoch: 8 Iteration: 118 : Loss: 0.7350 (0.017 sec)\n",
      "Epoch: 9 Iteration: 3 : Loss: 0.7490 (0.017 sec)\n",
      "Epoch: 9 Iteration: 6 : Loss: 0.7348 (0.019 sec)\n",
      "Epoch: 9 Iteration: 9 : Loss: 0.7503 (0.017 sec)\n",
      "Epoch: 9 Iteration: 12 : Loss: 0.7717 (0.021 sec)\n",
      "Epoch: 9 Iteration: 15 : Loss: 0.7217 (0.021 sec)\n",
      "Epoch: 9 Iteration: 18 : Loss: 0.7709 (0.017 sec)\n",
      "Epoch: 9 Iteration: 21 : Loss: 0.7470 (0.022 sec)\n",
      "Epoch: 9 Iteration: 24 : Loss: 0.7241 (0.018 sec)\n",
      "Epoch: 9 Iteration: 27 : Loss: 0.7190 (0.018 sec)\n",
      "Epoch: 9 Iteration: 30 : Loss: 0.7134 (0.018 sec)\n",
      "Epoch: 9 Iteration: 33 : Loss: 0.7424 (0.018 sec)\n",
      "Epoch: 9 Iteration: 36 : Loss: 0.7460 (0.019 sec)\n",
      "Epoch: 9 Iteration: 39 : Loss: 0.7133 (0.017 sec)\n",
      "Epoch: 9 Iteration: 42 : Loss: 0.7288 (0.017 sec)\n",
      "Epoch: 9 Iteration: 45 : Loss: 0.7518 (0.019 sec)\n",
      "Epoch: 9 Iteration: 48 : Loss: 0.7454 (0.017 sec)\n",
      "Epoch: 9 Iteration: 51 : Loss: 0.7399 (0.018 sec)\n",
      "Epoch: 9 Iteration: 54 : Loss: 0.7145 (0.017 sec)\n",
      "Epoch: 9 Iteration: 57 : Loss: 0.7140 (0.018 sec)\n",
      "Epoch: 9 Iteration: 60 : Loss: 0.7287 (0.018 sec)\n",
      "Epoch: 9 Iteration: 63 : Loss: 0.7747 (0.018 sec)\n",
      "Epoch: 9 Iteration: 66 : Loss: 0.7428 (0.018 sec)\n",
      "Epoch: 9 Iteration: 69 : Loss: 0.7478 (0.018 sec)\n",
      "Epoch: 9 Iteration: 72 : Loss: 0.7597 (0.017 sec)\n",
      "Epoch: 9 Iteration: 75 : Loss: 0.7621 (0.019 sec)\n",
      "Epoch: 9 Iteration: 78 : Loss: 0.8282 (0.020 sec)\n",
      "Epoch: 9 Iteration: 81 : Loss: 0.7669 (0.016 sec)\n",
      "Epoch: 9 Iteration: 84 : Loss: 0.7466 (0.017 sec)\n",
      "Epoch: 9 Iteration: 87 : Loss: 0.7461 (0.017 sec)\n",
      "Epoch: 9 Iteration: 90 : Loss: 0.7205 (0.018 sec)\n",
      "Epoch: 9 Iteration: 93 : Loss: 0.6910 (0.017 sec)\n",
      "Epoch: 9 Iteration: 96 : Loss: 0.7405 (0.017 sec)\n",
      "Epoch: 9 Iteration: 99 : Loss: 0.7166 (0.017 sec)\n",
      "Epoch: 9 Iteration: 102 : Loss: 0.7517 (0.017 sec)\n",
      "Epoch: 9 Iteration: 105 : Loss: 0.7100 (0.020 sec)\n",
      "Epoch: 9 Iteration: 108 : Loss: 0.7244 (0.018 sec)\n",
      "Epoch: 9 Iteration: 111 : Loss: 0.7814 (0.017 sec)\n",
      "Epoch: 9 Iteration: 114 : Loss: 0.7168 (0.018 sec)\n",
      "Epoch: 9 Iteration: 117 : Loss: 0.7476 (0.017 sec)\n",
      "Epoch: 10 Iteration: 2 : Loss: 0.7458 (0.017 sec)\n",
      "Epoch: 10 Iteration: 5 : Loss: 0.7672 (0.017 sec)\n",
      "Epoch: 10 Iteration: 8 : Loss: 0.7437 (0.017 sec)\n",
      "Epoch: 10 Iteration: 11 : Loss: 0.7792 (0.017 sec)\n",
      "Epoch: 10 Iteration: 14 : Loss: 0.7583 (0.017 sec)\n",
      "Epoch: 10 Iteration: 17 : Loss: 0.7630 (0.019 sec)\n",
      "Epoch: 10 Iteration: 20 : Loss: 0.7335 (0.017 sec)\n",
      "Epoch: 10 Iteration: 23 : Loss: 0.7417 (0.017 sec)\n",
      "Epoch: 10 Iteration: 26 : Loss: 0.7250 (0.017 sec)\n",
      "Epoch: 10 Iteration: 29 : Loss: 0.7733 (0.017 sec)\n",
      "Epoch: 10 Iteration: 32 : Loss: 0.7274 (0.017 sec)\n",
      "Epoch: 10 Iteration: 35 : Loss: 0.7015 (0.017 sec)\n",
      "Epoch: 10 Iteration: 38 : Loss: 0.7449 (0.017 sec)\n",
      "Epoch: 10 Iteration: 41 : Loss: 0.7626 (0.017 sec)\n",
      "Epoch: 10 Iteration: 44 : Loss: 0.7471 (0.017 sec)\n",
      "Epoch: 10 Iteration: 47 : Loss: 0.7194 (0.021 sec)\n",
      "Epoch: 10 Iteration: 50 : Loss: 0.7081 (0.018 sec)\n",
      "Epoch: 10 Iteration: 53 : Loss: 0.7223 (0.017 sec)\n",
      "Epoch: 10 Iteration: 56 : Loss: 0.7221 (0.018 sec)\n",
      "Epoch: 10 Iteration: 59 : Loss: 0.7036 (0.025 sec)\n",
      "Epoch: 10 Iteration: 62 : Loss: 0.7477 (0.017 sec)\n",
      "Epoch: 10 Iteration: 65 : Loss: 0.7575 (0.017 sec)\n",
      "Epoch: 10 Iteration: 68 : Loss: 0.7413 (0.021 sec)\n",
      "Epoch: 10 Iteration: 71 : Loss: 0.7648 (0.018 sec)\n",
      "Epoch: 10 Iteration: 74 : Loss: 0.7711 (0.018 sec)\n",
      "Epoch: 10 Iteration: 77 : Loss: 0.7460 (0.018 sec)\n",
      "Epoch: 10 Iteration: 80 : Loss: 0.7290 (0.017 sec)\n",
      "Epoch: 10 Iteration: 83 : Loss: 0.7231 (0.017 sec)\n",
      "Epoch: 10 Iteration: 86 : Loss: 0.7284 (0.017 sec)\n",
      "Epoch: 10 Iteration: 89 : Loss: 0.7783 (0.017 sec)\n",
      "Epoch: 10 Iteration: 92 : Loss: 0.7486 (0.017 sec)\n",
      "Epoch: 10 Iteration: 95 : Loss: 0.7670 (0.017 sec)\n",
      "Epoch: 10 Iteration: 98 : Loss: 0.7401 (0.017 sec)\n",
      "Epoch: 10 Iteration: 101 : Loss: 0.7131 (0.017 sec)\n",
      "Epoch: 10 Iteration: 104 : Loss: 0.7253 (0.017 sec)\n",
      "Epoch: 10 Iteration: 107 : Loss: 0.7223 (0.017 sec)\n",
      "Epoch: 10 Iteration: 110 : Loss: 0.7623 (0.018 sec)\n",
      "Epoch: 10 Iteration: 113 : Loss: 0.7565 (0.017 sec)\n",
      "Epoch: 10 Iteration: 116 : Loss: 0.7440 (0.019 sec)\n",
      "Epoch: 11 Iteration: 1 : Loss: 0.7337 (0.017 sec)\n",
      "Epoch: 11 Iteration: 4 : Loss: 0.7559 (0.017 sec)\n",
      "Epoch: 11 Iteration: 7 : Loss: 0.7794 (0.021 sec)\n",
      "Epoch: 11 Iteration: 10 : Loss: 0.7744 (0.017 sec)\n",
      "Epoch: 11 Iteration: 13 : Loss: 0.7353 (0.017 sec)\n",
      "Epoch: 11 Iteration: 16 : Loss: 0.7467 (0.017 sec)\n",
      "Epoch: 11 Iteration: 19 : Loss: 0.7464 (0.017 sec)\n",
      "Epoch: 11 Iteration: 22 : Loss: 0.7419 (0.017 sec)\n",
      "Epoch: 11 Iteration: 25 : Loss: 0.7291 (0.017 sec)\n",
      "Epoch: 11 Iteration: 28 : Loss: 0.7128 (0.020 sec)\n",
      "Epoch: 11 Iteration: 31 : Loss: 0.7531 (0.017 sec)\n",
      "Epoch: 11 Iteration: 34 : Loss: 0.7408 (0.017 sec)\n",
      "Epoch: 11 Iteration: 37 : Loss: 0.7611 (0.017 sec)\n",
      "Epoch: 11 Iteration: 40 : Loss: 0.7388 (0.017 sec)\n",
      "Epoch: 11 Iteration: 43 : Loss: 0.7494 (0.017 sec)\n",
      "Epoch: 11 Iteration: 46 : Loss: 0.7377 (0.017 sec)\n",
      "Epoch: 11 Iteration: 49 : Loss: 0.7359 (0.018 sec)\n",
      "Epoch: 11 Iteration: 52 : Loss: 0.7766 (0.018 sec)\n",
      "Epoch: 11 Iteration: 55 : Loss: 0.7337 (0.017 sec)\n",
      "Epoch: 11 Iteration: 58 : Loss: 0.7490 (0.017 sec)\n",
      "Epoch: 11 Iteration: 61 : Loss: 0.7277 (0.017 sec)\n",
      "Epoch: 11 Iteration: 64 : Loss: 0.7720 (0.017 sec)\n",
      "Epoch: 11 Iteration: 67 : Loss: 0.7149 (0.018 sec)\n",
      "Epoch: 11 Iteration: 70 : Loss: 0.7234 (0.017 sec)\n",
      "Epoch: 11 Iteration: 73 : Loss: 0.7503 (0.019 sec)\n",
      "Epoch: 11 Iteration: 76 : Loss: 0.7156 (0.017 sec)\n",
      "Epoch: 11 Iteration: 79 : Loss: 0.7626 (0.017 sec)\n",
      "Epoch: 11 Iteration: 82 : Loss: 0.7286 (0.017 sec)\n",
      "Epoch: 11 Iteration: 85 : Loss: 0.7219 (0.017 sec)\n",
      "Epoch: 11 Iteration: 88 : Loss: 0.7079 (0.018 sec)\n",
      "Epoch: 11 Iteration: 91 : Loss: 0.7347 (0.017 sec)\n",
      "Epoch: 11 Iteration: 94 : Loss: 0.7223 (0.018 sec)\n",
      "Epoch: 11 Iteration: 97 : Loss: 0.7416 (0.017 sec)\n",
      "Epoch: 11 Iteration: 100 : Loss: 0.7055 (0.017 sec)\n",
      "Epoch: 11 Iteration: 103 : Loss: 0.7310 (0.018 sec)\n",
      "Epoch: 11 Iteration: 106 : Loss: 0.7473 (0.021 sec)\n",
      "Epoch: 11 Iteration: 109 : Loss: 0.7433 (0.017 sec)\n",
      "Epoch: 11 Iteration: 112 : Loss: 0.7743 (0.019 sec)\n",
      "Epoch: 11 Iteration: 115 : Loss: 0.7179 (0.017 sec)\n",
      "Epoch: 11 Iteration: 118 : Loss: 0.7280 (0.017 sec)\n",
      "Epoch: 12 Iteration: 3 : Loss: 0.7447 (0.021 sec)\n",
      "Epoch: 12 Iteration: 6 : Loss: 0.7531 (0.019 sec)\n",
      "Epoch: 12 Iteration: 9 : Loss: 0.7415 (0.017 sec)\n",
      "Epoch: 12 Iteration: 12 : Loss: 0.7428 (0.018 sec)\n",
      "Epoch: 12 Iteration: 15 : Loss: 0.7761 (0.019 sec)\n",
      "Epoch: 12 Iteration: 18 : Loss: 0.7379 (0.018 sec)\n",
      "Epoch: 12 Iteration: 21 : Loss: 0.7221 (0.017 sec)\n",
      "Epoch: 12 Iteration: 24 : Loss: 0.7345 (0.017 sec)\n",
      "Epoch: 12 Iteration: 27 : Loss: 0.7239 (0.018 sec)\n",
      "Epoch: 12 Iteration: 30 : Loss: 0.7562 (0.017 sec)\n",
      "Epoch: 12 Iteration: 33 : Loss: 0.7438 (0.017 sec)\n",
      "Epoch: 12 Iteration: 36 : Loss: 0.7519 (0.021 sec)\n",
      "Epoch: 12 Iteration: 39 : Loss: 0.7678 (0.019 sec)\n",
      "Epoch: 12 Iteration: 42 : Loss: 0.7192 (0.018 sec)\n",
      "Epoch: 12 Iteration: 45 : Loss: 0.7223 (0.017 sec)\n",
      "Epoch: 12 Iteration: 48 : Loss: 0.7067 (0.021 sec)\n",
      "Epoch: 12 Iteration: 51 : Loss: 0.7641 (0.019 sec)\n",
      "Epoch: 12 Iteration: 54 : Loss: 0.7331 (0.021 sec)\n",
      "Epoch: 12 Iteration: 57 : Loss: 0.7111 (0.017 sec)\n",
      "Epoch: 12 Iteration: 60 : Loss: 0.7349 (0.018 sec)\n",
      "Epoch: 12 Iteration: 63 : Loss: 0.7365 (0.019 sec)\n",
      "Epoch: 12 Iteration: 66 : Loss: 0.7173 (0.017 sec)\n",
      "Epoch: 12 Iteration: 69 : Loss: 0.7527 (0.018 sec)\n",
      "Epoch: 12 Iteration: 72 : Loss: 0.7664 (0.021 sec)\n",
      "Epoch: 12 Iteration: 75 : Loss: 0.7396 (0.017 sec)\n",
      "Epoch: 12 Iteration: 78 : Loss: 0.7557 (0.017 sec)\n",
      "Epoch: 12 Iteration: 81 : Loss: 0.7509 (0.021 sec)\n",
      "Epoch: 12 Iteration: 84 : Loss: 0.7606 (0.018 sec)\n",
      "Saving at epoch 12 step: 84\n",
      "Epoch: 12 Iteration: 87 : Loss: 0.7046 (0.017 sec)\n",
      "Epoch: 12 Iteration: 90 : Loss: 0.7298 (0.018 sec)\n",
      "Epoch: 12 Iteration: 93 : Loss: 0.7579 (0.018 sec)\n",
      "Epoch: 12 Iteration: 96 : Loss: 0.7392 (0.017 sec)\n",
      "Epoch: 12 Iteration: 99 : Loss: 0.7207 (0.020 sec)\n",
      "Epoch: 12 Iteration: 102 : Loss: 0.7328 (0.017 sec)\n",
      "Epoch: 12 Iteration: 105 : Loss: 0.7668 (0.017 sec)\n",
      "Epoch: 12 Iteration: 108 : Loss: 0.7214 (0.017 sec)\n",
      "Epoch: 12 Iteration: 111 : Loss: 0.7591 (0.021 sec)\n",
      "Epoch: 12 Iteration: 114 : Loss: 0.7612 (0.017 sec)\n",
      "Epoch: 12 Iteration: 117 : Loss: 0.7543 (0.020 sec)\n",
      "Epoch: 13 Iteration: 2 : Loss: 0.7608 (0.018 sec)\n",
      "Epoch: 13 Iteration: 5 : Loss: 0.7161 (0.018 sec)\n",
      "Epoch: 13 Iteration: 8 : Loss: 0.7104 (0.020 sec)\n",
      "Epoch: 13 Iteration: 11 : Loss: 0.7192 (0.018 sec)\n",
      "Epoch: 13 Iteration: 14 : Loss: 0.7174 (0.017 sec)\n",
      "Epoch: 13 Iteration: 17 : Loss: 0.7317 (0.021 sec)\n",
      "Epoch: 13 Iteration: 20 : Loss: 0.7325 (0.017 sec)\n",
      "Epoch: 13 Iteration: 23 : Loss: 0.7463 (0.018 sec)\n",
      "Epoch: 13 Iteration: 26 : Loss: 0.7556 (0.019 sec)\n",
      "Epoch: 13 Iteration: 29 : Loss: 0.7133 (0.017 sec)\n",
      "Epoch: 13 Iteration: 32 : Loss: 0.7751 (0.017 sec)\n",
      "Epoch: 13 Iteration: 35 : Loss: 0.7110 (0.017 sec)\n",
      "Epoch: 13 Iteration: 38 : Loss: 0.7220 (0.018 sec)\n",
      "Epoch: 13 Iteration: 41 : Loss: 0.7218 (0.019 sec)\n",
      "Epoch: 13 Iteration: 44 : Loss: 0.7514 (0.017 sec)\n",
      "Epoch: 13 Iteration: 47 : Loss: 0.7667 (0.017 sec)\n",
      "Epoch: 13 Iteration: 50 : Loss: 0.7522 (0.021 sec)\n",
      "Epoch: 13 Iteration: 53 : Loss: 0.7083 (0.021 sec)\n",
      "Epoch: 13 Iteration: 56 : Loss: 0.7105 (0.021 sec)\n",
      "Epoch: 13 Iteration: 59 : Loss: 0.7249 (0.021 sec)\n",
      "Epoch: 13 Iteration: 62 : Loss: 0.7425 (0.020 sec)\n",
      "Epoch: 13 Iteration: 65 : Loss: 0.7449 (0.024 sec)\n",
      "Epoch: 13 Iteration: 68 : Loss: 0.7504 (0.020 sec)\n",
      "Epoch: 13 Iteration: 71 : Loss: 0.7155 (0.022 sec)\n",
      "Epoch: 13 Iteration: 74 : Loss: 0.7606 (0.019 sec)\n",
      "Epoch: 13 Iteration: 77 : Loss: 0.7962 (0.017 sec)\n",
      "Epoch: 13 Iteration: 80 : Loss: 0.7404 (0.017 sec)\n",
      "Epoch: 13 Iteration: 83 : Loss: 0.7640 (0.018 sec)\n",
      "Epoch: 13 Iteration: 86 : Loss: 0.7107 (0.023 sec)\n",
      "Epoch: 13 Iteration: 89 : Loss: 0.7297 (0.019 sec)\n",
      "Epoch: 13 Iteration: 92 : Loss: 0.7362 (0.021 sec)\n",
      "Epoch: 13 Iteration: 95 : Loss: 0.7417 (0.024 sec)\n",
      "Epoch: 13 Iteration: 98 : Loss: 0.7182 (0.020 sec)\n",
      "Epoch: 13 Iteration: 101 : Loss: 0.7516 (0.018 sec)\n",
      "Epoch: 13 Iteration: 104 : Loss: 0.7533 (0.017 sec)\n",
      "Epoch: 13 Iteration: 107 : Loss: 0.7332 (0.022 sec)\n",
      "Epoch: 13 Iteration: 110 : Loss: 0.7382 (0.020 sec)\n",
      "Epoch: 13 Iteration: 113 : Loss: 0.7557 (0.017 sec)\n",
      "Epoch: 13 Iteration: 116 : Loss: 0.7481 (0.019 sec)\n",
      "Epoch: 14 Iteration: 1 : Loss: 0.7438 (0.019 sec)\n",
      "Epoch: 14 Iteration: 4 : Loss: 0.7522 (0.017 sec)\n",
      "Epoch: 14 Iteration: 7 : Loss: 0.7356 (0.018 sec)\n",
      "Epoch: 14 Iteration: 10 : Loss: 0.7157 (0.019 sec)\n",
      "Epoch: 14 Iteration: 13 : Loss: 0.7100 (0.019 sec)\n",
      "Epoch: 14 Iteration: 16 : Loss: 0.7680 (0.020 sec)\n",
      "Epoch: 14 Iteration: 19 : Loss: 0.7740 (0.019 sec)\n",
      "Epoch: 14 Iteration: 22 : Loss: 0.7282 (0.019 sec)\n",
      "Epoch: 14 Iteration: 25 : Loss: 0.7735 (0.019 sec)\n",
      "Epoch: 14 Iteration: 28 : Loss: 0.7641 (0.021 sec)\n",
      "Epoch: 14 Iteration: 31 : Loss: 0.7464 (0.018 sec)\n",
      "Epoch: 14 Iteration: 34 : Loss: 0.7596 (0.018 sec)\n",
      "Epoch: 14 Iteration: 37 : Loss: 0.7382 (0.022 sec)\n",
      "Epoch: 14 Iteration: 40 : Loss: 0.7654 (0.018 sec)\n",
      "Epoch: 14 Iteration: 43 : Loss: 0.7695 (0.019 sec)\n",
      "Epoch: 14 Iteration: 46 : Loss: 0.7368 (0.022 sec)\n",
      "Epoch: 14 Iteration: 49 : Loss: 0.7630 (0.017 sec)\n",
      "Epoch: 14 Iteration: 52 : Loss: 0.8022 (0.016 sec)\n",
      "Epoch: 14 Iteration: 55 : Loss: 0.7175 (0.017 sec)\n",
      "Epoch: 14 Iteration: 58 : Loss: 0.7174 (0.017 sec)\n",
      "Epoch: 14 Iteration: 61 : Loss: 0.7069 (0.020 sec)\n",
      "Epoch: 14 Iteration: 64 : Loss: 0.7475 (0.025 sec)\n",
      "Epoch: 14 Iteration: 67 : Loss: 0.7483 (0.019 sec)\n",
      "Epoch: 14 Iteration: 70 : Loss: 0.7177 (0.017 sec)\n",
      "Epoch: 14 Iteration: 73 : Loss: 0.7289 (0.021 sec)\n",
      "Epoch: 14 Iteration: 76 : Loss: 0.6966 (0.021 sec)\n",
      "Epoch: 14 Iteration: 79 : Loss: 0.7222 (0.020 sec)\n",
      "Epoch: 14 Iteration: 82 : Loss: 0.7592 (0.017 sec)\n",
      "Epoch: 14 Iteration: 85 : Loss: 0.7668 (0.022 sec)\n",
      "Epoch: 14 Iteration: 88 : Loss: 0.6824 (0.019 sec)\n",
      "Epoch: 14 Iteration: 91 : Loss: 0.7274 (0.017 sec)\n",
      "Epoch: 14 Iteration: 94 : Loss: 0.7437 (0.017 sec)\n",
      "Epoch: 14 Iteration: 97 : Loss: 0.7107 (0.022 sec)\n",
      "Epoch: 14 Iteration: 100 : Loss: 0.7385 (0.018 sec)\n",
      "Epoch: 14 Iteration: 103 : Loss: 0.7766 (0.020 sec)\n",
      "Epoch: 14 Iteration: 106 : Loss: 0.7458 (0.022 sec)\n",
      "Epoch: 14 Iteration: 109 : Loss: 0.7816 (0.018 sec)\n",
      "Epoch: 14 Iteration: 112 : Loss: 0.7843 (0.018 sec)\n",
      "Epoch: 14 Iteration: 115 : Loss: 0.7199 (0.019 sec)\n",
      "Epoch: 14 Iteration: 118 : Loss: 0.7253 (0.020 sec)\n",
      "Epoch: 15 Iteration: 3 : Loss: 0.7523 (0.017 sec)\n",
      "Epoch: 15 Iteration: 6 : Loss: 0.7523 (0.019 sec)\n",
      "Epoch: 15 Iteration: 9 : Loss: 0.7443 (0.020 sec)\n",
      "Epoch: 15 Iteration: 12 : Loss: 0.7324 (0.024 sec)\n",
      "Epoch: 15 Iteration: 15 : Loss: 0.7180 (0.019 sec)\n",
      "Epoch: 15 Iteration: 18 : Loss: 0.7239 (0.017 sec)\n",
      "Epoch: 15 Iteration: 21 : Loss: 0.7237 (0.017 sec)\n",
      "Epoch: 15 Iteration: 24 : Loss: 0.7372 (0.022 sec)\n",
      "Epoch: 15 Iteration: 27 : Loss: 0.7553 (0.018 sec)\n",
      "Epoch: 15 Iteration: 30 : Loss: 0.7301 (0.022 sec)\n",
      "Epoch: 15 Iteration: 33 : Loss: 0.7362 (0.017 sec)\n",
      "Epoch: 15 Iteration: 36 : Loss: 0.7001 (0.017 sec)\n",
      "Epoch: 15 Iteration: 39 : Loss: 0.7653 (0.017 sec)\n",
      "Epoch: 15 Iteration: 42 : Loss: 0.7188 (0.017 sec)\n",
      "Epoch: 15 Iteration: 45 : Loss: 0.7393 (0.022 sec)\n",
      "Epoch: 15 Iteration: 48 : Loss: 0.7670 (0.020 sec)\n",
      "Epoch: 15 Iteration: 51 : Loss: 0.7533 (0.017 sec)\n",
      "Epoch: 15 Iteration: 54 : Loss: 0.7585 (0.017 sec)\n",
      "Epoch: 15 Iteration: 57 : Loss: 0.7619 (0.017 sec)\n",
      "Epoch: 15 Iteration: 60 : Loss: 0.7356 (0.019 sec)\n",
      "Epoch: 15 Iteration: 63 : Loss: 0.7213 (0.018 sec)\n",
      "Epoch: 15 Iteration: 66 : Loss: 0.6871 (0.023 sec)\n",
      "Epoch: 15 Iteration: 69 : Loss: 0.7405 (0.018 sec)\n",
      "Epoch: 15 Iteration: 72 : Loss: 0.7259 (0.017 sec)\n",
      "Epoch: 15 Iteration: 75 : Loss: 0.7286 (0.017 sec)\n",
      "Epoch: 15 Iteration: 78 : Loss: 0.7220 (0.017 sec)\n",
      "Epoch: 15 Iteration: 81 : Loss: 0.7376 (0.018 sec)\n",
      "Epoch: 15 Iteration: 84 : Loss: 0.6859 (0.017 sec)\n",
      "Epoch: 15 Iteration: 87 : Loss: 0.7617 (0.017 sec)\n",
      "Epoch: 15 Iteration: 90 : Loss: 0.7452 (0.017 sec)\n",
      "Epoch: 15 Iteration: 93 : Loss: 0.7518 (0.017 sec)\n",
      "Epoch: 15 Iteration: 96 : Loss: 0.7007 (0.020 sec)\n",
      "Epoch: 15 Iteration: 99 : Loss: 0.7277 (0.018 sec)\n",
      "Epoch: 15 Iteration: 102 : Loss: 0.7635 (0.018 sec)\n",
      "Epoch: 15 Iteration: 105 : Loss: 0.7441 (0.017 sec)\n",
      "Epoch: 15 Iteration: 108 : Loss: 0.7313 (0.017 sec)\n",
      "Epoch: 15 Iteration: 111 : Loss: 0.7182 (0.017 sec)\n",
      "Epoch: 15 Iteration: 114 : Loss: 0.7433 (0.017 sec)\n",
      "Epoch: 15 Iteration: 117 : Loss: 0.7058 (0.017 sec)\n",
      "Epoch: 16 Iteration: 2 : Loss: 0.7617 (0.017 sec)\n",
      "Epoch: 16 Iteration: 5 : Loss: 0.7309 (0.017 sec)\n",
      "Epoch: 16 Iteration: 8 : Loss: 0.7488 (0.017 sec)\n",
      "Epoch: 16 Iteration: 11 : Loss: 0.7538 (0.017 sec)\n",
      "Epoch: 16 Iteration: 14 : Loss: 0.7290 (0.017 sec)\n",
      "Epoch: 16 Iteration: 17 : Loss: 0.7219 (0.017 sec)\n",
      "Epoch: 16 Iteration: 20 : Loss: 0.7580 (0.017 sec)\n",
      "Epoch: 16 Iteration: 23 : Loss: 0.7617 (0.017 sec)\n",
      "Epoch: 16 Iteration: 26 : Loss: 0.7240 (0.017 sec)\n",
      "Epoch: 16 Iteration: 29 : Loss: 0.7517 (0.017 sec)\n",
      "Epoch: 16 Iteration: 32 : Loss: 0.7373 (0.022 sec)\n",
      "Epoch: 16 Iteration: 35 : Loss: 0.7369 (0.017 sec)\n",
      "Epoch: 16 Iteration: 38 : Loss: 0.7198 (0.017 sec)\n",
      "Epoch: 16 Iteration: 41 : Loss: 0.8066 (0.017 sec)\n",
      "Epoch: 16 Iteration: 44 : Loss: 0.7385 (0.022 sec)\n",
      "Epoch: 16 Iteration: 47 : Loss: 0.8009 (0.017 sec)\n",
      "Epoch: 16 Iteration: 50 : Loss: 0.7233 (0.018 sec)\n",
      "Epoch: 16 Iteration: 53 : Loss: 0.7392 (0.017 sec)\n",
      "Epoch: 16 Iteration: 56 : Loss: 0.7651 (0.019 sec)\n",
      "Epoch: 16 Iteration: 59 : Loss: 0.7261 (0.017 sec)\n",
      "Epoch: 16 Iteration: 62 : Loss: 0.7300 (0.018 sec)\n",
      "Epoch: 16 Iteration: 65 : Loss: 0.7278 (0.017 sec)\n",
      "Epoch: 16 Iteration: 68 : Loss: 0.7193 (0.017 sec)\n",
      "Epoch: 16 Iteration: 71 : Loss: 0.7239 (0.018 sec)\n",
      "Epoch: 16 Iteration: 74 : Loss: 0.7456 (0.017 sec)\n",
      "Epoch: 16 Iteration: 77 : Loss: 0.7381 (0.019 sec)\n",
      "Epoch: 16 Iteration: 80 : Loss: 0.7304 (0.017 sec)\n",
      "Epoch: 16 Iteration: 83 : Loss: 0.7419 (0.017 sec)\n",
      "Epoch: 16 Iteration: 86 : Loss: 0.7501 (0.017 sec)\n",
      "Epoch: 16 Iteration: 89 : Loss: 0.7500 (0.017 sec)\n",
      "Epoch: 16 Iteration: 92 : Loss: 0.7312 (0.017 sec)\n",
      "Epoch: 16 Iteration: 95 : Loss: 0.7346 (0.021 sec)\n",
      "Epoch: 16 Iteration: 98 : Loss: 0.7234 (0.020 sec)\n",
      "Epoch: 16 Iteration: 101 : Loss: 0.7080 (0.020 sec)\n",
      "Epoch: 16 Iteration: 104 : Loss: 0.7225 (0.017 sec)\n",
      "Epoch: 16 Iteration: 107 : Loss: 0.7196 (0.017 sec)\n",
      "Epoch: 16 Iteration: 110 : Loss: 0.7089 (0.017 sec)\n",
      "Saving at epoch 16 step: 112\n",
      "Epoch: 16 Iteration: 113 : Loss: 0.6966 (0.017 sec)\n",
      "Epoch: 16 Iteration: 116 : Loss: 0.7371 (0.017 sec)\n",
      "Epoch: 17 Iteration: 1 : Loss: 0.7157 (0.018 sec)\n",
      "Epoch: 17 Iteration: 4 : Loss: 0.7111 (0.017 sec)\n",
      "Epoch: 17 Iteration: 7 : Loss: 0.7273 (0.017 sec)\n",
      "Epoch: 17 Iteration: 10 : Loss: 0.6653 (0.017 sec)\n",
      "Epoch: 17 Iteration: 13 : Loss: 0.7287 (0.017 sec)\n",
      "Epoch: 17 Iteration: 16 : Loss: 0.6962 (0.019 sec)\n",
      "Epoch: 17 Iteration: 19 : Loss: 0.7077 (0.019 sec)\n",
      "Epoch: 17 Iteration: 22 : Loss: 0.6565 (0.018 sec)\n",
      "Epoch: 17 Iteration: 25 : Loss: 0.7012 (0.023 sec)\n",
      "Epoch: 17 Iteration: 28 : Loss: 0.6892 (0.017 sec)\n",
      "Epoch: 17 Iteration: 31 : Loss: 0.6881 (0.019 sec)\n",
      "Epoch: 17 Iteration: 34 : Loss: 0.7293 (0.023 sec)\n",
      "Epoch: 17 Iteration: 37 : Loss: 0.6741 (0.021 sec)\n",
      "Epoch: 17 Iteration: 40 : Loss: 0.7111 (0.018 sec)\n",
      "Epoch: 17 Iteration: 43 : Loss: 0.7468 (0.023 sec)\n",
      "Epoch: 17 Iteration: 46 : Loss: 0.7518 (0.023 sec)\n",
      "Epoch: 17 Iteration: 49 : Loss: 0.7149 (0.018 sec)\n",
      "Epoch: 17 Iteration: 52 : Loss: 0.7417 (0.019 sec)\n",
      "Epoch: 17 Iteration: 55 : Loss: 0.7288 (0.019 sec)\n",
      "Epoch: 17 Iteration: 58 : Loss: 0.7111 (0.017 sec)\n",
      "Epoch: 17 Iteration: 61 : Loss: 0.7231 (0.018 sec)\n",
      "Epoch: 17 Iteration: 64 : Loss: 0.7477 (0.018 sec)\n",
      "Epoch: 17 Iteration: 67 : Loss: 0.7406 (0.020 sec)\n",
      "Epoch: 17 Iteration: 70 : Loss: 0.7359 (0.023 sec)\n",
      "Epoch: 17 Iteration: 73 : Loss: 0.7807 (0.023 sec)\n",
      "Epoch: 17 Iteration: 76 : Loss: 0.8092 (0.020 sec)\n",
      "Epoch: 17 Iteration: 79 : Loss: 0.7647 (0.022 sec)\n",
      "Epoch: 17 Iteration: 82 : Loss: 0.7495 (0.023 sec)\n",
      "Epoch: 17 Iteration: 85 : Loss: 0.7332 (0.019 sec)\n",
      "Epoch: 17 Iteration: 88 : Loss: 0.7492 (0.022 sec)\n",
      "Epoch: 17 Iteration: 91 : Loss: 0.7621 (0.021 sec)\n",
      "Epoch: 17 Iteration: 94 : Loss: 0.7298 (0.020 sec)\n",
      "Epoch: 17 Iteration: 97 : Loss: 0.7190 (0.023 sec)\n",
      "Epoch: 17 Iteration: 100 : Loss: 0.7541 (0.018 sec)\n",
      "Epoch: 17 Iteration: 103 : Loss: 0.7318 (0.021 sec)\n",
      "Epoch: 17 Iteration: 106 : Loss: 0.7664 (0.022 sec)\n",
      "Epoch: 17 Iteration: 109 : Loss: 0.7659 (0.023 sec)\n",
      "Epoch: 17 Iteration: 112 : Loss: 0.7867 (0.017 sec)\n",
      "Epoch: 17 Iteration: 115 : Loss: 0.7328 (0.020 sec)\n",
      "Epoch: 17 Iteration: 118 : Loss: 0.7334 (0.017 sec)\n",
      "Epoch: 18 Iteration: 3 : Loss: 0.7532 (0.017 sec)\n",
      "Epoch: 18 Iteration: 6 : Loss: 0.7362 (0.022 sec)\n",
      "Epoch: 18 Iteration: 9 : Loss: 0.7716 (0.017 sec)\n",
      "Epoch: 18 Iteration: 12 : Loss: 0.7102 (0.023 sec)\n",
      "Epoch: 18 Iteration: 15 : Loss: 0.7216 (0.019 sec)\n",
      "Epoch: 18 Iteration: 18 : Loss: 0.7371 (0.017 sec)\n",
      "Epoch: 18 Iteration: 21 : Loss: 0.7419 (0.017 sec)\n",
      "Epoch: 18 Iteration: 24 : Loss: 0.7410 (0.017 sec)\n",
      "Epoch: 18 Iteration: 27 : Loss: 0.7457 (0.017 sec)\n",
      "Epoch: 18 Iteration: 30 : Loss: 0.7314 (0.017 sec)\n",
      "Epoch: 18 Iteration: 33 : Loss: 0.7300 (0.017 sec)\n",
      "Epoch: 18 Iteration: 36 : Loss: 0.7269 (0.017 sec)\n",
      "Epoch: 18 Iteration: 39 : Loss: 0.7841 (0.017 sec)\n",
      "Epoch: 18 Iteration: 42 : Loss: 0.7328 (0.017 sec)\n",
      "Epoch: 18 Iteration: 45 : Loss: 0.7538 (0.017 sec)\n",
      "Epoch: 18 Iteration: 48 : Loss: 0.7564 (0.017 sec)\n",
      "Epoch: 18 Iteration: 51 : Loss: 0.6929 (0.020 sec)\n",
      "Epoch: 18 Iteration: 54 : Loss: 0.7187 (0.021 sec)\n",
      "Epoch: 18 Iteration: 57 : Loss: 0.7387 (0.017 sec)\n",
      "Epoch: 18 Iteration: 60 : Loss: 0.7146 (0.017 sec)\n",
      "Epoch: 18 Iteration: 63 : Loss: 0.7249 (0.021 sec)\n",
      "Epoch: 18 Iteration: 66 : Loss: 0.7408 (0.019 sec)\n",
      "Epoch: 18 Iteration: 69 : Loss: 0.7492 (0.017 sec)\n",
      "Epoch: 18 Iteration: 72 : Loss: 0.7589 (0.018 sec)\n",
      "Epoch: 18 Iteration: 75 : Loss: 0.7108 (0.019 sec)\n",
      "Epoch: 18 Iteration: 78 : Loss: 0.7307 (0.017 sec)\n",
      "Epoch: 18 Iteration: 81 : Loss: 0.7765 (0.018 sec)\n",
      "Epoch: 18 Iteration: 84 : Loss: 0.7308 (0.020 sec)\n",
      "Epoch: 18 Iteration: 87 : Loss: 0.7470 (0.019 sec)\n",
      "Epoch: 18 Iteration: 90 : Loss: 0.7137 (0.023 sec)\n",
      "Epoch: 18 Iteration: 93 : Loss: 0.6952 (0.017 sec)\n",
      "Epoch: 18 Iteration: 96 : Loss: 0.7439 (0.022 sec)\n",
      "Epoch: 18 Iteration: 99 : Loss: 0.7169 (0.024 sec)\n",
      "Epoch: 18 Iteration: 102 : Loss: 0.7366 (0.017 sec)\n",
      "Epoch: 18 Iteration: 105 : Loss: 0.7682 (0.020 sec)\n",
      "Epoch: 18 Iteration: 108 : Loss: 0.7333 (0.017 sec)\n",
      "Epoch: 18 Iteration: 111 : Loss: 0.7591 (0.018 sec)\n",
      "Epoch: 18 Iteration: 114 : Loss: 0.7413 (0.017 sec)\n",
      "Epoch: 18 Iteration: 117 : Loss: 0.7483 (0.017 sec)\n",
      "Epoch: 19 Iteration: 2 : Loss: 0.7530 (0.017 sec)\n",
      "Epoch: 19 Iteration: 5 : Loss: 0.7363 (0.022 sec)\n",
      "Epoch: 19 Iteration: 8 : Loss: 0.7813 (0.024 sec)\n",
      "Epoch: 19 Iteration: 11 : Loss: 0.7159 (0.021 sec)\n",
      "Epoch: 19 Iteration: 14 : Loss: 0.7409 (0.018 sec)\n",
      "Epoch: 19 Iteration: 17 : Loss: 0.7771 (0.020 sec)\n",
      "Epoch: 19 Iteration: 20 : Loss: 0.7393 (0.020 sec)\n",
      "Epoch: 19 Iteration: 23 : Loss: 0.7730 (0.021 sec)\n",
      "Epoch: 19 Iteration: 26 : Loss: 0.7260 (0.021 sec)\n",
      "Epoch: 19 Iteration: 29 : Loss: 0.7357 (0.021 sec)\n",
      "Epoch: 19 Iteration: 32 : Loss: 0.7594 (0.018 sec)\n",
      "Epoch: 19 Iteration: 35 : Loss: 0.7262 (0.024 sec)\n",
      "Epoch: 19 Iteration: 38 : Loss: 0.7518 (0.020 sec)\n",
      "Epoch: 19 Iteration: 41 : Loss: 0.7688 (0.023 sec)\n",
      "Epoch: 19 Iteration: 44 : Loss: 0.7050 (0.017 sec)\n",
      "Epoch: 19 Iteration: 47 : Loss: 0.7157 (0.022 sec)\n",
      "Epoch: 19 Iteration: 50 : Loss: 0.7394 (0.021 sec)\n",
      "Epoch: 19 Iteration: 53 : Loss: 0.7554 (0.017 sec)\n",
      "Epoch: 19 Iteration: 56 : Loss: 0.7484 (0.021 sec)\n",
      "Epoch: 19 Iteration: 59 : Loss: 0.7339 (0.017 sec)\n",
      "Epoch: 19 Iteration: 62 : Loss: 0.7448 (0.020 sec)\n",
      "Epoch: 19 Iteration: 65 : Loss: 0.7565 (0.022 sec)\n",
      "Epoch: 19 Iteration: 68 : Loss: 0.7486 (0.017 sec)\n",
      "Epoch: 19 Iteration: 71 : Loss: 0.6976 (0.019 sec)\n",
      "Epoch: 19 Iteration: 74 : Loss: 0.7337 (0.017 sec)\n",
      "Epoch: 19 Iteration: 77 : Loss: 0.7614 (0.019 sec)\n",
      "Epoch: 19 Iteration: 80 : Loss: 0.7221 (0.018 sec)\n",
      "Epoch: 19 Iteration: 83 : Loss: 0.7466 (0.021 sec)\n",
      "Epoch: 19 Iteration: 86 : Loss: 0.7270 (0.023 sec)\n",
      "Epoch: 19 Iteration: 89 : Loss: 0.7173 (0.021 sec)\n",
      "Epoch: 19 Iteration: 92 : Loss: 0.7209 (0.019 sec)\n",
      "Epoch: 19 Iteration: 95 : Loss: 0.7481 (0.018 sec)\n",
      "Epoch: 19 Iteration: 98 : Loss: 0.7437 (0.017 sec)\n",
      "Epoch: 19 Iteration: 101 : Loss: 0.7330 (0.019 sec)\n",
      "Epoch: 19 Iteration: 104 : Loss: 0.7427 (0.022 sec)\n",
      "Epoch: 19 Iteration: 107 : Loss: 0.7115 (0.021 sec)\n",
      "Epoch: 19 Iteration: 110 : Loss: 0.7446 (0.021 sec)\n",
      "Epoch: 19 Iteration: 113 : Loss: 0.7269 (0.023 sec)\n",
      "Epoch: 19 Iteration: 116 : Loss: 0.7105 (0.018 sec)\n"
     ]
    }
   ],
   "source": [
    "# Where to save this model.\n",
    "model_path = os.path.join(logs_dir, time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "import tf_utils\n",
    "tf_utils = imp.reload(tf_utils)\n",
    "\n",
    "if ckpt:\n",
    "    restore_from_model = True\n",
    "    print(\"Restore from model!\")\n",
    "else:\n",
    "    restore_from_model = False\n",
    "\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "    summaries = tf.summary.merge_all()                                                       \n",
    "    writer = tf.summary.FileWriter(model_path,\n",
    "        graph=session.graph)                  \n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables()) \n",
    "                                                                                                  \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    if restore_from_model:\n",
    "        saver.restore(session, ckpt.model_checkpoint_path)\n",
    "        \n",
    "    global_step = 0\n",
    "        \n",
    "    for epoch in range(number_of_epochs):\n",
    "        eval_feed_generator = eval_input_fn()\n",
    "        # Shuffle the training input\n",
    "        x_train, y_train = tf_utils.unison_shuffled_copies(x_train, y_train)\n",
    "\n",
    "        for step, feed_dict in enumerate(input_fn()):\n",
    "            global_step += 1\n",
    "            start_time = time.time()\n",
    "\n",
    "            _, temp_loss = session.run([train_op, loss], feed_dict=feed_dict)\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            if global_step % reporting_frequency == 0:\n",
    "                print(\"Epoch: %s Iteration: %s : Loss: %.4f (%.3f sec)\" % \n",
    "                      (epoch, (step + 1), temp_loss, duration))\n",
    "\n",
    "                train_summ, train_mae = session.run([training_summary, training_mae], feed_dict=feed_dict)\n",
    "                writer.add_summary(train_summ, global_step)\n",
    "                writer.add_summary(train_mae, global_step)\n",
    "                _, valid_summ, valid_mae = session.run(\n",
    "                        [loss, validation_summary, validation_mae],\n",
    "                        feed_dict=next(eval_feed_generator))\n",
    "                writer.add_summary(valid_summ, global_step)\n",
    "                writer.add_summary(valid_mae, global_step)\n",
    "\n",
    "                writer.flush()                \n",
    "\n",
    "            if (global_step % checkpoint_frequency == 0) or (global_step == number_of_batches):\n",
    "                print(\"Saving at epoch %s step: %s\" % (epoch, step + 1))\n",
    "                saver.save(session, model_path, global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from logs/bagofwords/2017-06-28-19-01-52-40319\n",
      "Mean Absolute Error Loss over all 51200 observations = 9339.59578125\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "# number_of_validation_batches is used above in the eval_input_fn\n",
    "number_of_validation_batches = math.floor(len(x_test_text)/batch_size)\n",
    "# Load checkpointed model.\n",
    "ckpt = tf.train.get_checkpoint_state(logs_dir)                                     \n",
    "\n",
    "# Write TF Model Evaluation Code here. \n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables()) \n",
    "                                                                                                  \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    prediction_array_list = []\n",
    "\n",
    "    total_loss = 0\n",
    "    for step, eval_feed_dict in enumerate(eval_input_fn()):    \n",
    "        valid_loss, mae, model_predictions = session.run(\n",
    "            [loss, mean_absolute_error_salary_scale, model_output], feed_dict=eval_feed_dict)\n",
    "        #print(\"Batch: %d Mean: %.4f\" % (step, mae))\n",
    "        total_loss += mae\n",
    "        prediction_array_list.append(model_predictions)\n",
    "    print (\"Mean Absolute Error Loss over all %s observations = %s\" % ((step + 1) * batch_size, total_loss / (step + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200 (51200,)\n",
      "[ 0.89645004 -0.66550416  3.22435188 ..., -0.29010177  0.89645004\n",
      "  0.95295256]\n"
     ]
    }
   ],
   "source": [
    "def flatten_predictions(predictions):\n",
    "    return numpy.concatenate(predictions)\n",
    "\n",
    "predictions = flatten_predictions(prediction_array_list)\n",
    "\n",
    "n_predictions = predictions.shape[0]\n",
    "\n",
    "actuals = y_test[0:n_predictions]\n",
    "\n",
    "print(n_predictions, actuals.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb40a7eef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41440365 -1.14755058  2.74230552 ...,  2.3354876  -0.51788706\n",
      "  -0.85690188]\n",
      " [ 1.37059236 -0.1913619   3.6984942  ...,  3.29167628  0.43830159\n",
      "   0.09928676]\n",
      " [ 0.58996278 -0.97199142  2.91786456 ...,  2.51104665 -0.34232792\n",
      "  -0.68134272]\n",
      " ..., \n",
      " [ 0.9635421  -0.5984121   3.29144382 ...,  2.88462591  0.03125139\n",
      "  -0.30776343]\n",
      " [ 0.63640022 -0.92555392  2.96430206 ...,  2.55748415 -0.29589045\n",
      "  -0.63490528]\n",
      " [ 1.41444039 -0.14751387  3.74234223 ...,  3.33552432  0.48214963\n",
      "   0.1431348 ]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def print_results(x_vals, y_vals):\n",
    "\n",
    "    plt.scatter(x_vals, y_vals, alpha=.1)\n",
    "    plt.show()\n",
    "\n",
    "    print(x_vals-y_vals)\n",
    "    #print(sorted([set(y_vals)]))\n",
    "\n",
    "print_results(actuals, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
